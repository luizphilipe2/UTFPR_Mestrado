
@ARTICLE{Zhan2021,
author={Zhan, H. and Sheng, V.S. and Lin, W.-M.},
title={Reinforcement learning-based register renaming policy for simultaneous multithreading CPUs[Formula presented]},
journal={Expert Systems with Applications},
year={2021},
volume={186},
doi={10.1016/j.eswa.2021.115717},
art_number={115717},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112332236&doi=10.1016%2fj.eswa.2021.115717&partnerID=40&md5=d04c0b5dbedba21b170f814ecbfca583},
affiliation={Department of Computer Science, Texas Tech University, Lubbock, TX  79409-3104, United States; Department of Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, TX  78249, United States},
abstract={Simultaneous multithreading (SMT) improves the performance of superscalar CPUs by exploiting thread-level parallelism with shared entries for better utilization of resources. A key issue for this out-of-order execution is that the occupancy latency of a physical rename register can be undesirably long due to many program execution-dependent factors that result in performance degradation. Such an issue becomes even more problematic in an SMT environment in which these registers are shared among concurrently running threads. Smartly managing this critical shared resource to ensure that slower threads do not block faster threads’ execution is essential to the advancement of SMT performance. In this paper, an actor–critic style reinforcement learning (RL) algorithm is proposed to dynamically assigning an upper-bound (cap) of the rename registers any thread is allowed to use according to the threads’ real-time demand. In particular, a critic network projects the current Issue Queues (IQ) usage, register file usage, and the cap value to a reward; an actor network is trained to project the current IQ usage and register file usage to the optimal real-time cap value via ascending the instructions per cycle (IPC) gradient within the trajectory distribution. The proposed method differs from the state-of-the-art (Wang and Lin, 2018) as the cap for the rename registers for each thread is adjusted in real-time according to the policy and state transition from self-play. The proposed method shows an improvement in IPC up to 162.8% in a 4-threaded system, 154.8% in a 6-threaded system and up to 101.7% in an 8-threaded system. The code is now available open source at https://github.com/98k-bot/RL-based-SMT-Register-Renaming-Policy. © 2021 Elsevier Ltd},
author_keywords={Actor–critic;  Machine learning;  Reinforcement learning;  Simultaneous multithreading},
document_type={Article},
source={Scopus},
}

@ARTICLE{Mathew20214522,
author={Mathew, A.N. and Rohini, V. and Paulose, J.},
title={NLP-based personal learning assistant for school education},
journal={International Journal of Electrical and Computer Engineering},
year={2021},
volume={11},
number={5},
pages={4522-4530},
doi={10.11591/ijece.v11i5.pp4522-4530},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107272854&doi=10.11591%2fijece.v11i5.pp4522-4530&partnerID=40&md5=764508c4a3ce0bf31deab1eb52fa501c},
affiliation={Department of Computer Science, CHRIST (Deemed to Be University), India},
abstract={Computer-based knowledge and computation systems are becoming major sources of leverage for multiple industry segments. Hence, educational systems and learning processes across the world are on the cusp of a major digital transformation. This paper seeks to explore the concept of an artificial intelligence and natural language processing (NLP) based intelligent tutoring system (ITS) in the context of computer education in primary and secondary schools. One of the components of an ITS is a learning assistant, which can enable students to seek assistance as and when they need, wherever they are. As part of this research, a pilot prototype chatbot was developed, to serve as a learning assistant for the subject Scratch (Scratch is a graphical utility used to teach school children the concepts of programming). By the use of an open source natural language understanding (NLU) or NLP library, and a slack-based UI, student queries were input to the chatbot, to get the sought explanation as the answer. Through a two-stage testing process, the chat-bot's NLP extraction and information retrieval performance were evaluated. The testing results showed that the ontology modelling for such a learning assistant was done relatively accurately, and shows its potential to be pursued as a cloud-based solution in future. © 2021 Institute of Advanced Engineering and Science. All rights reserved.},
author_keywords={Intelligent tutoring system chatbot;  Natural language processing;  Rasa;  Scratch},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yu2021,
author={Yu, S. and Chen, Y. and Zaidi, H.},
title={AVA: A Financial Service Chatbot Based on Deep Bidirectional Transformers},
journal={Frontiers in Applied Mathematics and Statistics},
year={2021},
volume={7},
doi={10.3389/fams.2021.604842},
art_number={604842},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114669628&doi=10.3389%2ffams.2021.604842&partnerID=40&md5=d1767f3fce90f53458e1a8b37c02cdc2},
affiliation={The Vanguard Group, Malvern, PA, United States},
abstract={We develop a chatbot using deep bidirectional transformer (BERT) models to handle client questions in financial investment customer service. The bot can recognize 381 intents, decides when to say I don’t know, and escalate escalation/uncertain questions to human operators. Our main novel contribution is the discussion about the uncertainty measure for BERT, where three different approaches are systematically compared with real problems. We investigated two uncertainty metrics, information entropy and variance of dropout sampling, in BERT, followed by mixed-integer programming to optimize decision thresholds. Another novel contribution is the usage of BERT as a language model in automatic spelling correction. Inputs with accidental spelling errors can significantly decrease intent classification performance. The proposed approach combines probabilities from masked language model and word edit distances to find the best corrections for misspelled words. The chatbot and the entire conversational AI system are developed using open-source tools and deployed within our company’s intranet. The proposed approach can be useful for industries seeking similar in-house solutions in their specific business domains. We share all our code and a sample chatbot built on a public data set on GitHub. © Copyright © 2021 Yu, Chen and Zaidi.},
author_keywords={bayesian learning;  BERT;  chabot;  intent classification;  rasa},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Norambuena202125,
author={Norambuena, I.N. and Bergel, A.},
title={Building a bot for automatic expert retrieval on discord},
journal={MaLTESQuE 2021 - Proceedings of the 5th International Workshop on Machine Learning Techniques for Software Quality Evolution, co-located with ESEC/FSE 2021},
year={2021},
pages={25-30},
doi={10.1145/3472674.3473982},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113829614&doi=10.1145%2f3472674.3473982&partnerID=40&md5=edcee00578ec4a57632bfb2967796b83},
affiliation={ISCLab, Department of Computer Science (DCC), University of Chile, Chile},
abstract={It is common for software practitioners to look for experts on online chat platforms, such as Discord. However, finding them is a complex activity that requires a deep knowledge of the open source community. As a consequence, newcomers and casual participants may not be able to adequately find experts willing to discuss a particular topic. Our paper describes a bot that provides a ranked list of Discord users that are experts in a particular set of topics. Our bot uses simple heuristics to model expertise, such as a word occurrence table and word embeddings. Our bot shows that at least half of the retrieved users are indeed experts. © 2021 ACM.},
author_keywords={Bot;  Discord;  Expert Retrieval Systems;  Software;  Word Embeddings},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gonzalez2021398,
author={Gonzalez, L.A.},
title={Investigating the Benefits of Applying Artificial Intelligence Techniques to Enhance Learning Experiences in Capstone Courses},
journal={ICER 2021 - Proceedings of the 17th ACM Conference on International Computing Education Research},
year={2021},
pages={398-400},
doi={10.1145/3446871.3469770},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113647885&doi=10.1145%2f3446871.3469770&partnerID=40&md5=63b32caf2476ddd1c69838a8348d010c},
affiliation={Computer Science Department, Pontificia Universidad Católica de Chile, Santiago, Chile},
abstract={This research seeks to improve the learning experiences in Software Engineering Programs using Virtual Assistants based on Artificial Intelligence (AI) models. Students of Software Engineering Capstone Courses face real world situations and challenges that grant them valuable experiences for their professional preparation. However, since this knowledge is acquired through real-life exposure projects, it is difficult to transmit it among different generations of students. In consequence, all the gained knowledge, experiences, and computer codes developed are lost and cannot be reused outside the project context when they finish their assignment at the end of the semester. To address this challenge, this thesis considers the development of AI based virtual assistants applied in higher education, in a form of a lesson learned system, a recommender system integrated with a chatbot, to help students, solve problems similar to those they face in the different stages of their software project development by recommending previous lessons learned. The innovative contribution lies in the implementation of the described techniques from the state-of-art artificial intelligence field in an educational platform with the goal to leverage the experience gained during years of the teaching a Capstone Course in Software Engineering to new student generations who might benefit from this universal knowledge gained previously, in order to assist software engineering students to enhance their learning experience. © 2021 Owner/Author.},
author_keywords={collective knowledge;  lessons learned;  recommender systems;  Software Engineering teaching},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Weber2021,
author={Weber, I.},
title={Low-code from frontend to backend: Connecting conversational user interfaces to backend services via a low-code IoT platform},
journal={ACM International Conference Proceeding Series},
year={2021},
doi={10.1145/3469595.3469632},
art_number={37},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112252706&doi=10.1145%2f3469595.3469632&partnerID=40&md5=64f86f7d079cc253c7105bb6eac1dcfd},
affiliation={Kempten University of Applied Sciences, Kempten, Germany},
abstract={Current chatbot development platforms and frameworks facilitate setting up the language and dialog part of chatbots, while connecting it to backend services and business functions requires substantial manual coding effort and programming skills. This paper proposes an approach to overcome this situation. It proposes an architecture with a chatbot as frontend using an IoT (Internet of Things) platform as a middleware for connections to backend services. Specifically, it elaborates and demonstrates how to combine a chatbot developed on the open source development platform Rasa with the open source platform Node-RED, allowing low-code or no-code development of a transactional conversational user interface from frontend to backend. © 2021 ACM.},
author_keywords={API;  conversational user interfaces;  end-user programming;  integration pattern;  IoT;  low-code;  Node-RED;  Open Source;  Rasa chatbot;  system architecture},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2021,
title={Proceedings - 2021 IEEE/ACM 3rd International Workshop on Bots in Software Engineering, BotSE 2021},
journal={Proceedings - 2021 IEEE/ACM 3rd International Workshop on Bots in Software Engineering, BotSE 2021},
year={2021},
page_count={53},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113162955&partnerID=40&md5=0b3d75d00739c38cb01528c2770810e6},
abstract={The proceedings contain 9 papers. The topics discussed include: designing a bot for efficient distribution of service requests; testing challenges for NLP-intensive bots; SAW-BOT: proposing fixes for static analysis warnings with GitHub suggestions; do bots modify the workflow of GitHub teams?; bots don’t mind waiting, do they? comparing the interaction with automatically and manually created pull requests; nudging students toward better software engineering behaviors; iContractBot: a chatbot for smart contracts’ specification and code generation; identifying bot activity in GitHub pull request and issue comments; and towards a question answering assistant for software development using a transformer-based language model.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Saadat20211,
author={Saadat, S. and Colmenares, N. and Sukthankar, G.},
title={Do Bots Modify the Workflow of GitHub Teams?},
journal={Proceedings - 2021 IEEE/ACM 3rd International Workshop on Bots in Software Engineering, BotSE 2021},
year={2021},
pages={1-5},
doi={10.1109/BotSE52550.2021.00008},
art_number={9474411},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112866830&doi=10.1109%2fBotSE52550.2021.00008&partnerID=40&md5=fee8974d3a1ffe258fe9bfcb8210e29b},
affiliation={University of Central Florida, Department of Computer Science, Orlando, FL, United States},
abstract={The ever-increasing complexity of modern software engineering projects makes the usage of automated assistants imperative. Bots can be used to complete repetitive tasks during development and testing, as well as promoting communication between team members through issue reporting and documentation. Although the ultimate aim of these automated assistants is to speed taskwork completion, their inclusion into GitHub repositories may affect teamwork as well. This paper studies the question of how bots modify the team workflow. We examined the event sequences of repositories with bots and without bots using a contrast motif discovery method to detect subsequences that are more prevalent in one set of event sequences vs. the other. Our study reveals that teams with bots are more likely to intersperse comments throughout their coding activities, while not actually being more prolific commenters. © 2021 IEEE.},
author_keywords={bot classification;  sequential pattern mining;  social coding platforms;  teamwork},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Brown202111,
author={Brown, C. and Parnin, C.},
title={Nudging Students Toward Better Software Engineering Behaviors},
journal={Proceedings - 2021 IEEE/ACM 3rd International Workshop on Bots in Software Engineering, BotSE 2021},
year={2021},
pages={11-15},
doi={10.1109/BotSE52550.2021.00010},
art_number={9474399},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112864708&doi=10.1109%2fBotSE52550.2021.00010&partnerID=40&md5=41ba87aa15d6a869bccd9a669004b916},
affiliation={North Carolina State University, Department of Computer Science, Raleigh, NC, United States},
abstract={Student experiences in large undergraduate Computer Science courses are increasingly impacted by automated systems. Bots, or agents of software automation, are useful for efficiently grading and generating feedback. Current efforts at automation in CS education focus on supporting instructional tasks, but do not address student struggles due to poor behaviors, such as procrastination. In this paper, we explore using bots to improve the software engineering behaviors of students using developer recommendation choice architectures, a framework incorporating behavioral science concepts in recommendations to improve the actions of programmers. We implemented this framework in class-bot, a novel system designed to nudge students to make better choices while working on programming assignments. This work presents a preliminary evaluation integrating this tool in an introductory programming course. Our results show that class-bot is beneficial for improving student development behaviors increasing code quality and productivity. © 2021 IEEE.},
author_keywords={automated issues;  automation;  bots;  developer behavior;  software engineering education},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wyrich20216,
author={Wyrich, M. and Ghit, R. and Haller, T. and Muller, C.},
title={Bots Don't Mind Waiting, Do They? Comparing the Interaction with Automatically and Manually Created Pull Requests},
journal={Proceedings - 2021 IEEE/ACM 3rd International Workshop on Bots in Software Engineering, BotSE 2021},
year={2021},
pages={6-10},
doi={10.1109/BotSE52550.2021.00009},
art_number={9474402},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112864352&doi=10.1109%2fBotSE52550.2021.00009&partnerID=40&md5=224feeceea984e7188b44e0817ebb0da},
affiliation={Institute of Software Engineering, University of Stuttgart, Stuttgart, Germany},
abstract={As a maintainer of an open source software project, you are usually happy about contributions in the form of pull requests that bring the project a step forward. Past studies have shown that when reviewing a pull request, not only its content is taken into account, but also, for example, the social characteristics of the contributor. Whether a contribution is accepted and how long this takes therefore depends not only on the content of the contribution. What we only have indications for so far, however, is that pull requests from bots may be prioritized lower, even if the bots are explicitly deployed by the development team and are considered useful. One goal of the bot research and development community is to design helpful bots to effectively support software development in a variety of ways. To get closer to this goal, in this GitHub mining study, we examine the measurable differences in how maintainers interact with manually created pull requests from humans compared to those created automatically by bots. About one third of all pull requests on GitHub currently come from bots. While pull requests from humans are accepted and merged in 72.53% of all cases, this applies to only 37.38% of bot pull requests. Furthermore, it takes significantly longer for a bot pull request to be interacted with and for it to be merged, even though they contain fewer changes on average than human pull requests. These results suggest that bots have yet to realize their full potential. © 2021 IEEE.},
author_keywords={github mining study;  human-agent interaction;  open source;  pull request;  software bot},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Risdianto2021,
author={Risdianto, A.C. and Chang, E.-C.},
title={OctoBot: An open-source orchestration system for a wide range network activity generation},
journal={IEEE INFOCOM 2021 - IEEE Conference on Computer Communications Workshops, INFOCOM WKSHPS 2021},
year={2021},
doi={10.1109/INFOCOMWKSHPS51825.2021.9484537},
art_number={9484537},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113292184&doi=10.1109%2fINFOCOMWKSHPS51825.2021.9484537&partnerID=40&md5=fcb813b1b7723f3acc58b25b6c754751},
affiliation={National University of Singapore (NUS), School of Computing119007, Singapore},
abstract={Experimentation in a large-scale testbed environment requires a large amount of emulated traffic to ensure realistic scenario execution and better experiment results. A large number of human-generated network activities can emulate traffic from real network users. Deploying and producing a single activity from an individual user is simple, but emulating and automating it from multiple users with a wide range of activities is challenging. We designed a containerized human agent (i.e., bot) to generate a single activity. Thus, a large number of bots can be deployed and controlled by a single orchestration system. Due to the complexity and wide-range usage of container orchestration systems, we need to develop a simpler system that leverages widely-used open-source container orchestrator. So, researchers and scientists can easily use it to define and execute activity requirements with a few command lines or a single specification file. This work shows the implementation of an orchestration system with several unique bots and their deployment in a production testbed environment. Several activity use cases are also presented to verify their functionality to support large-scale experimentation. © 2021 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Alfadel2021254,
author={Alfadel, M. and Costa, D.E. and Shihab, E. and Mkhallalati, M.},
title={On the use of dependabot security pull requests},
journal={Proceedings - 2021 IEEE/ACM 18th International Conference on Mining Software Repositories, MSR 2021},
year={2021},
pages={254-265},
doi={10.1109/MSR52588.2021.00037},
art_number={9463148},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113701509&doi=10.1109%2fMSR52588.2021.00037&partnerID=40&md5=244481a28ef128df3eadfd4ede10284f},
affiliation={Concordia University, Data-driven Analysis of Software (DAS) Lab, Montreal, Canada},
abstract={Vulnerable dependencies are a major problem in modern software development. As software projects depend on multiple external dependencies, developers struggle to constantly track and check for corresponding security vulnerabilities that affect their project dependencies. To help mitigate this issue, Dependabot has been created, a bot that issues pull-requests to automatically update vulnerable dependencies. However, little is known about the degree to which developers adopt Dependabot to help them update vulnerable dependencies.In this paper, we investigate 2, 904 JavaScript open-source GitHub projects that subscribed to Dependabot. Our results show that the vast majority (65.42%) of the created security-related pull-requests are accepted, often merged within a day. Through manual analysis, we identify 7 main reasons for Dependabot security pull-requests not being merged, mostly related to concurrent modifications of the affected dependencies rather than Dependabot failures. Interestingly, only 3.2% of the manually examined pull-requests suffered from build breakages. Finally, we model the time it takes to merge a Dependabot security pull-request using characteristics from projects, the fixed vulnerabilities and issued pull requests. Our model reveals 5 significant features to explain merge times, e.g., projects with relevant experience with Dependabot security pull-requests are most likely associated with rapid merges. Surprisingly, the severity of the dependency vulnerability and the potential risk of breaking changes are not strongly associated with the merge time. To the best of our knowledge, this study is the first to evaluate how developers receive Dependabot's security contributions. Our findings indicate that Dependabot provides an effective platform for increasing awareness of dependency vulnerabilities and helps developers mitigate vulnerability threats in JavaScript projects. © 2021 IEEE.},
author_keywords={Dependabot;  Dependency;  Pull request;  Security vulnerability},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lee2021,
author={Lee, H. and Kang, J. and Yeo, J.},
title={Medical specialty recommendations by an artificial intelligence chatbot on a smartphone: Development and deployment},
journal={Journal of Medical Internet Research},
year={2021},
volume={23},
number={5},
doi={10.2196/27460},
art_number={e27460},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105493363&doi=10.2196%2f27460&partnerID=40&md5=5597675b709f3bb82f76207a34f9a76c},
affiliation={Department of Clinical Korean Medicine, Graduate School, Kyung Hee University, Seoul, South Korea; Department of Computer Science, Yonsei University, Seoul, South Korea; School of Computer Science and Engineering, Pusan National University, Busan, South Korea},
abstract={Background: The COVID-19 pandemic has limited daily activities and even contact between patients and primary care providers. This makes it more difficult to provide adequate primary care services, which include connecting patients to an appropriate medical specialist. A smartphone-compatible artificial intelligence (AI) chatbot that classifies patients'symptoms and recommends the appropriate medical specialty could provide a valuable solution. Objective: In order to establish a contactless method of recommending the appropriate medical specialty, this study aimed to construct a deep learning-based natural language processing (NLP) pipeline and to develop an AI chatbot that can be used on a smartphone. Methods: We collected 118,008 sentences containing information on symptoms with labels (medical specialty), conducted data cleansing, and finally constructed a pipeline of 51,134 sentences for this study. Several deep learning models, including 4 different long short-term memory (LSTM) models with or without attention and with or without a pretrained FastText embedding layer, as well as bidirectional encoder representations from transformers for NLP, were trained and validated using a randomly selected test data set. The performance of the models was evaluated on the basis of the precision, recall, F1-score, and area under the receiver operating characteristic curve (AUC). An AI chatbot was also designed to make it easy for patients to use this specialty recommendation system. We used an open-source framework called "Alpha" to develop our AI chatbot. This takes the form of a web-based app with a frontend chat interface capable of conversing in text and a backend cloud-based server application to handle data collection, process the data with a deep learning model, and offer the medical specialty recommendation in a responsive web that is compatible with both desktops and smartphones. Results: The bidirectional encoder representations from transformers model yielded the best performance, with an AUC of 0.964 and F1-score of 0.768, followed by LSTM model with embedding vectors, with an AUC of 0.965 and F1-score of 0.739. Considering the limitations of computing resources and the wide availability of smartphones, the LSTM model with embedding vectors trained on our data set was adopted for our AI chatbot service. We also deployed an Alpha version of the AI chatbot to be executed on both desktops and smartphones. Conclusions: With the increasing need for telemedicine during the current COVID-19 pandemic, an AI chatbot with a deep learning-based NLP model that can recommend a medical specialty to patients through their smartphones would be exceedingly useful. This chatbot allows patients to identify the proper medical specialist in a rapid and contactless manner, based on their symptoms, thus potentially supporting both patients and primary care providers. © 2021 Journal of Medical Internet Research. All rights reserved.},
author_keywords={Artificial intelligence;  Chatbot;  COVID-19;  Deep learning;  Deployment;  Development;  Machine learning;  Medical specialty;  Natural language processing;  Recommendation;  Smartphone},
document_type={Article},
source={Scopus},
}

@ARTICLE{Golzadeh2021,
author={Golzadeh, M. and Decan, A. and Legay, D. and Mens, T.},
title={A ground-truth dataset and classification model for detecting bots in GitHub issue and PR comments},
journal={Journal of Systems and Software},
year={2021},
volume={175},
doi={10.1016/j.jss.2021.110911},
art_number={110911},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099784243&doi=10.1016%2fj.jss.2021.110911&partnerID=40&md5=15097e5f702a5c909b7e9d08e865259e},
affiliation={Software Engineering Lab, University of Mons, Avenue Maistriau 15, Mons, 7000, Belgium},
abstract={Bots are frequently used in Github repositories to automate repetitive activities that are part of the distributed software development process. They communicate with human actors through comments. While detecting their presence is important for many reasons, no large and representative ground-truth dataset is available, nor are classification models to detect and validate bots on the basis of such a dataset. This paper proposes a ground-truth dataset, based on a manual analysis with high interrater agreement, of pull request and issue comments in 5,000 distinct Github accounts of which 527 have been identified as bots. Using this dataset we propose an automated classification model to detect bots, taking as main features the number of empty and non-empty comments of each account, the number of comment patterns, and the inequality between comments within comment patterns. We obtained a very high weighted average precision, recall and F1-score of 0.98 on a test set containing 40% of the data. We integrated the classification model into an open source command-line tool to allow practitioners to detect which accounts in a given Github repository actually correspond to bots. © 2021 Elsevier Inc.},
author_keywords={Bot identification;  Classification model;  Distributed software development;  GitHub repositories;  Text similarity},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gwon2021318,
author={Gwon, H.-M. and Seo, Y.-S.},
title={Towards a Redundant Response Avoidance for Intelligent Chatbot},
journal={Journal of Information Processing Systems},
year={2021},
volume={17},
number={2},
pages={318-333},
doi={10.3745/JIPS.04.0213},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106649207&doi=10.3745%2fJIPS.04.0213&partnerID=40&md5=954ff5505e9416780498ed184802f573},
affiliation={Dept. of Computer Science, Hanyang University, Seoul, South Korea; Dept. of Computer Engineering, Yeungnam University, Gyeongsan},
abstract={Smartphones are one of the most widely used mobile devices allowing users to communicate with each other. With the development of mobile apps, many companies now provide various services for their customers by studying interactive systems in the form of mobile messengers for business marketing and commercial promotion. Such interactive systems are called “chatbots.” In this paper, we propose a method of avoiding the redundant responses of chatbots, according to the utterances entered by the user. In addition, the redundant patterns of chatbot responses are classified into three categories for the first time. In order to verify the proposed method, a chatbot is implemented using Telegram, an open source messenger. By comparing the proposed method with an existent method for each pattern, it is confirmed that the proposed method significantly improves the redundancy avoidance rate. Furthermore, response performance and variation analysis of the proposed method are investigated in our experiment. © 2021 KIPS. All Rights Reserved.},
author_keywords={Chatbot;  Human-Computer Interaction;  Interactive System;  Redundancy Avoidance;  Telegram},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Ren2021275,
author={Ren, R. and Castro, J.W. and Acuña, S.T.},
title={A family of experiments for evaluating the usability of a collaborative modelling chatbot},
journal={Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE},
year={2021},
volume={2021-July},
pages={275-280},
doi={10.18293/SEKE2021-043},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114277853&doi=10.18293%2fSEKE2021-043&partnerID=40&md5=4a3085600651915f02ff4e20782f201c},
affiliation={Dep. Ing. Informática, Univ. Autónoma de Madrid, Madrid, Spain; Dep. Ing. Informática y Ciencias de la Computación, Universidad de Atacama, Copiapó, Chile},
abstract={Recent natural language processing developments have facilitated the adoption of chatbots in typically collaborative software engineering tasks. Families of experiments can overcome limitations in terms of the sample size of individual experiments. To experimentally evaluate the usability of a chatbot for collaborative modelling (i.e., SOCIO) and tackle some of the typical shortcomings of individual experiments, we conducted a family of three experiments to evaluate the usability of SOCIO against the Creately online collaborative tool. Results show that the participants were more satisfied with the chatbot than with the online collaborative tool and that they also created class diagrams faster using the chatbot. We conclude that chatbots may be helpful for creating class diagrams. © 2021 Knowledge Systems Institute Graduate School. All rights reserved.},
author_keywords={Chatbots;  Family of experiments;  Modelling;  Usability},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Briel2021,
author={Briel, A.},
title={Toward an eclectic and malleable multiagent educational assistant},
journal={Computer Applications in Engineering Education},
year={2021},
doi={10.1002/cae.22449},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113897829&doi=10.1002%2fcae.22449&partnerID=40&md5=d89523c3f51323caf673f2cb3d503f0e},
affiliation={Georgia Institute of Technology, Atlanta, GA, United States},
abstract={Conversational agents are systems capable of processing and responding to human language. They have evolved over the years from a means to pass the Turing Test to chatbots that fulfill a utilitarian purpose. Closed-domain chatbots are specialized in a specific knowledge base and are often used in an attempt to assist users in an educational context. Existing open-source, educational assistant chatbots are narrow in immediate functionality, thus limiting the content and services that can be provided to students and educators. To address this limitation, a novel multiagent framework is proposed, providing diverse capabilities and component flexibility to better meet varied educational requirements. The version presented in this experiment can not only answer questions in different styles but is also able to provide content summaries and links. The solution is tested by presenting participants with a lesson containing information related to coronavirus disease 2019 (COVID-19), followed by engagement with the chatbot system, a subsequent evaluation of its responses, and a quiz to quantify its pedagogical efficacy. COVID-19 was chosen as the knowledge base due to its current relevance in society. The chatbot framework's knowledge base is comprised of two data sets containing facts related to the virus, one which is used to provide longer, frequently asked questions-type responses, and another used to provide short answers. The resulting participant evaluations indicate a preference for more informative responses in the experimental context and showcase the benefit of the framework's malleability in not only fulfilling but discovering varying needs in educational assistance. © 2021 Wiley Periodicals LLC},
author_keywords={chatbot;  COVID-19;  educational Assistant;  natural Language Processing;  transformers},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Nagy20211767,
author={Nagy, R. and Kucherenko, T. and Moell, B. and Pereira, A. and Kjellström, H. and Bernardet, U.},
title={A framework for integrating gesture generation models into interactive conversational agents},
journal={Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
year={2021},
volume={3},
pages={1767-1769},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112311041&partnerID=40&md5=ab68b692df554ad9437e7a8b45c0c867},
affiliation={KTH, Stockholm, Sweden; Aston University, Birmingham, United Kingdom},
abstract={Embodied conversational agents (ECAs) benefit from non-verbal behavior for natural and efficient interaction with users. Gesticulation - hand and arm movements accompanying speech - is an essential part of non-verbal behavior. Gesture generation models have been developed for several decades: starting with rule-based and ending with mainly data-driven methods. To date, recent end to- end gesture generation methods have not been evaluated in a real-time interaction with users. We present a proof-of-concept framework, which is intended to facilitate evaluation of modern gesture generation models in interaction. We demonstrate an extensible open-source framework that contains three components: 1) a 3D interactive agent; 2) a chatbot backend; 3) a gesticulating system. Each component can be replaced, making the proposed framework applicable for investigating the effect of different gesturing models in real-time interactions with different communication modalities, chatbot backends, or different agent appearances. The code and video are available at the project page https://nagyrajmund.github.io/project/gesturebot. © 2021 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.},
author_keywords={Conversational embodied agents;  Non-verbal behavior synthesis},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Arias-Durán2021486,
author={Arias-Durán, S. and Sanisaca-Muñoz, J. and Bravo-Buri, S. and Robles-Bykbaev, V.},
title={Intervention Platform for Children with Intellectual Disability: Chatbots and IBM Watson Services in the Ecuadorian Context},
journal={Lecture Notes in Networks and Systems},
year={2021},
volume={275},
pages={486-494},
doi={10.1007/978-3-030-80091-8_57},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112137572&doi=10.1007%2f978-3-030-80091-8_57&partnerID=40&md5=aaf87da356b4c527a2cf3f9481c0620a},
affiliation={GI-IATa, Cátedra UNESCO Tecnologías de apoyo para la inclusión Educativa, Universidad Politécnica Salesiana, Cuenca, Ecuador},
abstract={Some of the latest studies conducted by the World Health Organization (WHO) claim that approximately 10 percent of the world’s children and young people (200 million) have a sensory, intellectual, or mental health impairment. This situation is complex because 80% of them live in developing countries. In Ecuador, the picture has become critical with the health emergency due to the COVID-19. In the same way, it is essential mentioning that children with disabilities are much more vulnerable to COVID-19. For these reasons, in this paper, we present the first development stage of an open-source platform to help specialists in the intervention of children with intellectual disabilities. The platform uses chatbots to support and provide an appropriate guide for children’s parents/caregivers, and at the same time uses the free intelligent services provided by the IBM Watson. To determine the real feasibility of implementing we tested the platform with real users, their parents, and at the same time, applied a survey with 30 professionals of special education. The achieved results are encouraging and show that the platform can be used by therapists and professionals that lost their works due to the pandemic. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
author_keywords={Chatbot;  Children with intellectual disability;  COVID-19;  Educational inclusion;  IBM Watson},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{daSilveiraColissi202131,
author={da Silveira Colissi, M. and Vieira, R. and Mascardi, V. and Bordini, R.H.},
title={A Chatbot that Uses a Multi-agent Organization to Support Collaborative Learning},
journal={Communications in Computer and Information Science},
year={2021},
volume={1421},
pages={31-38},
doi={10.1007/978-3-030-78645-8_4},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112075007&doi=10.1007%2f978-3-030-78645-8_4&partnerID=40&md5=59b2ae79e511d8863e74d880c0812e9e},
affiliation={School of Technology, Pontifical Catholic University of Rio Grande do Sul, Av. Ipiranga, 6681, Porto Alegre, RS, Brazil; CIDEHUS, University of Évora, Palácio do Vimioso Largo do Marquês de Marialva, no. 8, Évora, Portugal; Department of Informatics, Engineering, Robotics and Systems Engineering, University of Genova, Via Dodecaneso, 35, Genova, GE  16146, Italy},
abstract={This work investigates and apply the use of a multi-agent system to assist in the coordination of group tasks, specifically in educational environments, in which the interaction occurs indirectly, that is, asynchronously. The system has a web interface integrated with a chatbot for more natural interaction. The chatbot communicates with the multi-agent system that is responsible for the organization of the group, that is, it contains information about the tasks and members of the groups, in addition to restrictions that can be imposed according to the organization of the group, and it is also able to return the requested information in natural language through the chatbot. This approach was validated in a practical undergraduate course of software engineering. The students assessed the functionalities and usability of the system while working in groups in order to develop software collaboratively. Our system was used to assist students in a real project. With this assessment, it was found that the system was able to support the development of the group tasks, ensuring quick and consistent responses to the student’s request. © 2021, Springer Nature Switzerland AG.},
author_keywords={Chatbot;  Dialogflow;  Group coordination;  JaCaMo;  Multi-agent system},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Choi2021459,
author={Choi, Y.L. and Kim, J.-W.},
title={Development of a moral ai agent for recognition of hazardous or violent situations at home and providing appropriate response},
journal={Journal of Institute of Control, Robotics and Systems},
year={2021},
volume={27},
number={7},
pages={459-467},
doi={10.5302/J.ICROS.2021.21.0028},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110576841&doi=10.5302%2fJ.ICROS.2021.21.0028&partnerID=40&md5=6dd1b5989bd43c76ff8e2363fce8b80a},
affiliation={Department of Electronic Engineering, Dong-a University, South Korea},
abstract={This paper introduces an AI agent that can recognize any hazardous or violent situation that may occur at a user’s home and notifies the user about the risk in advance before the consequential accident occurs. The AI agent analyzes a current situation based on the 5W1H principle to determine whether the user is in a dangerous, immoral, or illegal situation at home, according to the user’s age group. This AI agent has been developed by adding a new abnormal behavior code into the existing behavioral classification code to provide appropriate advice or response in the case of an abnormal situation. This agent is implemented using the open source cognitive agent architecture, chatbot engine, and database management system. The abnormal situation-recognition performance of the developed agent was validated through textual conversations between the agent and kids. © ICROS 2021.},
author_keywords={AI ethics;  Chatbot;  Cognitive agent;  Context awareness},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Tauqeer202119,
author={Tauqeer, F. and Raza, M.K. and Yin, M.S. and Hassan, S.-U. and Haddawy, P. and Pomarlan, M. and Tuarob, S.},
title={Dental tutorbot: Exploitation of dental textbooks for automated learning},
journal={CEUR Workshop Proceedings},
year={2021},
volume={2895},
pages={19-26},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109613998&partnerID=40&md5=624a851c9aa28a6069905c02835202b8},
affiliation={Information Technology University, 346-B, Ferozepur Road, Lahore, Pakistan; Faculty of ICT, Mahidol University, Nakhon Pathom, Thailand; Faculty of Linguistics, University of Bremen, Germany},
abstract={Active learning has been shown to provide benefits over traditional didactic approaches to teaching and learning. These benefits are particularly important in fields in which students must master large amounts of information and effectively operationalize it, as in medicine and dentistry. While online learning platforms have the potential to provide students with active learning without taxing scarce faculty resources, a recognized challenge in producing such systems is the engineering of the domain knowledge needed for engaging interaction. In this paper we address this problem by developing an open-source chatbot-based tutoring system trained on dental textbooks in the area of endodontics, one of the most challenging areas of dentistry. Dental TutorBot is built using Rasa for modular training purposes. It asks short questions from students and evaluates their answers. If the student cannot answer a question, the system provides a hint, rather than immediately giving the student the answer. In this way, it coaches the student to find the answer and thus helps them to understand the connections between concepts while creating a more intellectually stimulating learning experience. Copyright © 2021 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
author_keywords={GPT-2;  Hint Generation;  QA Pairs;  Rasa TutorBot;  Smart Interactive Learning},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hwang2021,
author={Hwang, M.-H. and Shin, J. and Seo, H. and Im, J.-S. and Cho, H.},
title={KoRASA: Pipeline Optimization for Open-Source Korean Natural Language Understanding Framework Based on Deep Learning},
journal={Mobile Information Systems},
year={2021},
volume={2021},
doi={10.1155/2021/9987462},
art_number={9987462},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109454266&doi=10.1155%2f2021%2f9987462&partnerID=40&md5=078b1841f01873641b5177375c882739},
affiliation={Digital Solution Laboratory, Korea Electric Power Research Institute (KEPRI), Daejeon, South Korea},
abstract={Since the emergence of deep learning-based chatbots for knowledge services, numerous research and development projects have been conducted in various industries. A high demand for chatbots has drastically increased the global market size; however, the limited functional scalability of open-domain chatbots is a challenge to their application to industries. Moreover, as most chatbot frameworks employ English, it is necessary to create chatbots customized for other languages. To address this problem, this paper proposes KoRASA as a pipeline-optimization method, which uses a deep learning-based open-source chatbot framework to understand the Korean language. KoRASA is a closed-domain chatbot that is applicable across a wide range of industries in Korea. KoRASA's operation consists of four stages: tokenization, featurization, intent classification, and entity extraction. The accuracy and F1-score of KoRASA were measured based on datasets taken from common tasks carried out in most industrial fields. The algorithm for intent classification and entity extraction was optimized. The accuracy and F1-score were 98.2% and 98.4% for intent classification and 97.4% and 94.7% for entity extraction, respectively. Furthermore, these results are better than those achieved by existing models. Accordingly, KoRASA can be applied to various industries, including mobile services based on closed-domain chatbots using Korean, robotic process automation (RPA), edge computing, and Internet of Energy (IoE) services. © 2021 Myeong-Ha Hwang et al.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Cucurnia202132,
author={Cucurnia, D. and Rozanov, N. and Sucameli, I. and Ciuffoletti, A. and Simi, M.},
title={MATILDA: Multi-annotator multi-language interactive light-weight dialogue annotator},
journal={EACL 2021 - 16th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the System Demonstrations},
year={2021},
pages={32-39},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107276733&partnerID=40&md5=7e051fe9d0bca352aecea367b6f4b2c7},
affiliation={Department of Computer Science, University of Pisa, Pisa, Italy; Wluper Ltd., London, United Kingdom},
abstract={Dialogue Systems are becoming ubiquitous in various forms and shapes, from virtual assistants (like Siri, Alexa and various chat-bots) to customer support systems embedded within websites. Recent publications and advancements with natural language modelling have opened up NLP (and its more advanced applications like conversational AI) to a wider audience. Unfortunately, the lack of labelled data within this field remains a significant barrier and so we have developed MATILDA (the first multi-annotator, multi-language dialogue annotation tool) as an initial contribution to help the community overcome this barrier. MATILDA is a tool for creating high-quality corpora via a user-friendly interface so as to facilitate the annotation of dialogues, resolve inter-annotator disagreement and manage multiple users at scale. We have evaluated the tool on ease of use, annotation speed and inter-annotation resolution for both experts and novices and can confidently conclude that MATILDA offers a novel, streamlined, end-to-end solution to dialogue annotation and is intuitive enough to use, even for a non-technical audience. The tool is completely open-sourced at https://github.com/wluper/matilda and is easily adaptable to any language. We are also providing a complementary tutorial video. © 2021 Association for Computational Linguistics},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Abdellatif2021,
author={Abdellatif, A. and Badran, K. and Costa, D. and Shihab, E.},
title={A Comparison of Natural Language Understanding Platforms for Chatbots in Software Engineering},
journal={IEEE Transactions on Software Engineering},
year={2021},
doi={10.1109/TSE.2021.3078384},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105866929&doi=10.1109%2fTSE.2021.3078384&partnerID=40&md5=6a8fc16e3035c74edb06f9f944f9d69e},
affiliation={Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: ahmad.abdellatif87@gmail.com); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: badrankhaled97@gmail.com); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: diegoelias1@gmail.com); Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, H3G 1M8 (e-mail: emadshihab@gmail.com)},
abstract={Chatbots are envisioned to dramatically change the future of Software Engineering, allowing practitioners to chat and inquire about their software projects and interact with different services using natural language. At the heart of every chatbot is a Natural Language Understanding (NLU) component that enables the chatbot to understand natural language input. Recently, many NLU platforms were provided to serve as an off-the-shelf NLU component for chatbots, however, selecting the best NLU for Software Engineering chatbots remains an open challenge. Therefore, in this paper, we evaluate four of the most commonly used NLUs, namely IBM Watson, Google Dialogflow, Rasa, and Microsoft LUIS to shed light on which NLU should be used in Software Engineering based chatbots. Specifically, we examine the NLUs' performance in classifying intents, confidence scores stability, and extracting entities. To evaluate the NLUs, we use two datasets that reflect two common tasks performed by Software Engineering practitioners, 1) the task of chatting with the chatbot to ask questions about software repositories 2) the task of asking development questions on Q&amp;A forums (e.g., Stack Overflow). According to our findings, IBM Watson is the best performing NLU when considering the three aspects (intents classification, confidence scores, and entity extraction). However, the results from each individual aspect show that, in intents classification, IBM Watson performs the best with an F1-measure&gt;84%, but in confidence scores, Rasa comes on top with a median confidence score higher than 0.91. Our results also show that all NLUs, except for Dialogflow, generally provide trustable confidence scores. For entity extraction, Microsoft LUIS and IBM Watson outperform other NLUs in the two SE tasks. Our results provide guidance to software engineering practitioners when deciding which NLU to use in their chatbots. IEEE},
author_keywords={Empirical Software Engineering;  Natural Language Understanding Platforms;  Software Chatbots},
document_type={Article},
source={Scopus},
}

@ARTICLE{Davies2021209,
author={Davies, J.N. and Verovko, M. and Verovko, O. and Solomakha, I.},
title={Personalization of e-learning process using ai-powered chatbot integration},
journal={Advances in Intelligent Systems and Computing},
year={2021},
volume={1265 AISC},
pages={209-216},
doi={10.1007/978-3-030-58124-4_20},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091186208&doi=10.1007%2f978-3-030-58124-4_20&partnerID=40&md5=0de7c101d03d4ced87337896408e88da},
affiliation={CARDS Glyndŵr University, Wrexham, United Kingdom; AgileVision sp. z o.o., Krakow, Poland; Chernihiv National University of Technology, Chernihiv, Ukraine},
abstract={Personalized learning path is considered as one of the most effective way to archive the best outcomes from the eLearning process. The introduction of artificial intelligence (AI) and machine learning (ML) into the educational process is one of the most important trends of modern eLearning since it can provide flexibility of learning and can performing adaptation of the learning process based on the personal needs of each user. AI technologies are positioned as the best solution for the analysis of each learner’s personal requirements and for generating a corresponding learning path with personalized educational content. One of the possible outcomes of introducing AI and ML into the eLearning process is the usage of AI-powered chatbots. Chatbots could significantly simplify the learning process by providing learners with the resources they are looking for which have previously been tailored for their learning personal characteristics. The integration of chatbots provides answers corresponding to the personal requirements of each learner into the eLearning system and could cover the gap in real-time consulting, which is not available with offline courses. Development of a chatbot is a trivial task for modern software engineering. However the determination of a chatbot behavior and its source dictionary is a complex task that requires development and implementation of additional analytic algorithms and models. This paper describes an approach for the design and development of a chatbot for an eLearning system with the personalization of consulting materials in-line with the learner’s personal needs. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.},
author_keywords={Adoptive learning;  Amazon Lex;  Amazon services;  Artificial intelligence (AI);  Chatbots;  E-Learning;  Machine learning (ML);  Personalized learning},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Melo20203165,
author={Melo, G. and Law, E. and Alencar, P. and Cowan, D.},
title={Understanding User Understanding: What do Developers Expect from a Cognitive Assistant?},
journal={Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020},
year={2020},
pages={3165-3172},
doi={10.1109/BigData50022.2020.9378140},
art_number={9378140},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103853696&doi=10.1109%2fBigData50022.2020.9378140&partnerID=40&md5=4814828d8fb6695b87b5c3007cd2a546},
affiliation={University of Waterloo, David R. Cheriton School of Computer Science, Waterloo, Canada},
abstract={Software development is a complex endeavor that depends on a wide variety of contextual factors involving a large amount of distributed information such as technology-related tasks, software operating environments and stakeholder requirements. Most of this context is implicit and captured in the developers' minds (tacit) or distributed through volumes of documentation. Developers have to maintain mental models of this variety of tasks and information as they produce the software. As a result, context can be easily lost or forgotten and developers often use adhoc approaches while finishing the project. We present in this paper the preliminary results of a study that aims at analyzing qualitatively whether supporting software developers with a chatbot during task execution can improve the overall development experience. The chatbot can assist the developers in executing different tasks based on implicit contextual information. We propose an implementation to explore the viability of using textual chatbots to assist developers automatically and proactively with software development project activities that recur. We believe that understanding the interaction of developers with the systems supported by chatbots is key to improving the developer experience and advancing software engineering practices by providing needed timely support for developers. © 2020 IEEE.},
author_keywords={context;  developer experience;  software development;  software engineering;  software projects},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ong2020381,
author={Ong, Y.F. and Madhavi, M. and Chan, K.},
title={OpenNLU: Open-source Web-interface NLU Toolkit for Development of Conversational Agent},
journal={2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, APSIPA ASC 2020 - Proceedings},
year={2020},
pages={381-385},
art_number={9306398},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100917006&partnerID=40&md5=afbe660d24d95156a780c4497de236d7},
affiliation={National University of Singapore, Department of Electrical and Computer Engineering, Singapore; ST Engineering Land Systems Ltd, Singapore},
abstract={The Natural Language Understanding (NLU) module in a conversational agent interprets and understands the user's query. As the application scenario evolves, there is a need to periodically update the knowledge database that supports the agent by adapting or re-training the NLU model. Such periodic updates could be time-consuming to the developers and system administrator since it requires manual efforts. In this paper, we present the OpenNLU toolkit, a user-friendly interface for building and updating the knowledge database, and evaluating NLU module. This paper describes in detail the architecture, important features and design of the web-based tool, as well as the backend features which are supported by popular Rasa NLU toolkit, and deep learning libraries such as Tensorflow, and PyTorch. This paper also demonstrates the training and evaluation processes on in-house datasets alongside other benchmarking datasets (ATIS and Snips) to exemplify the usage of OpenNLU toolkit as to validate proof of concepts. The open-source OpenNLU toolkit is available to the research community1.1https://github.com/oyfml/opennlu © 2020 APSIPA.},
author_keywords={Administrative interface;  BERT language model;  Intent Classification;  Natural Language Understanding;  Slot tagging},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{YuHing2020,
author={Yu Hing, S. and Chi Hung, C. and Kam Fat, L. and Jonathan},
title={Smart Elderly Care Robot},
journal={2020 2nd IEEE International Workshop on System Biology and Biomedical Systems, SBBS 2020},
year={2020},
doi={10.1109/SBBS50483.2020.9314943},
art_number={9314943},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100257569&doi=10.1109%2fSBBS50483.2020.9314943&partnerID=40&md5=b3d7d75a3758d82b271e3798e7b1d410},
affiliation={Hong Kong Institute of Vocational Education (Shatin), Department of Engineering, Hong Kong, Hong Kong; Engineering Discipline Planning Office, Vocational Training Council, Hong Kong, Hong Kong},
abstract={This paper describes the implementation of a low cost service robot to help the elderly to improve their quality of life. It includes different technologies such as Simultaneous Localization and Mapping (SLAM), Open Source Computer Vision Library (OpenCV) and ChatterBot (a machine learning, conversational dialog engine for creating chat bots) to develop intelligence for autonomous control of the robot itself and easy-To-use interfaces for the elderly. The robot equipped with a 2D low cost laser sensor and SLAM technology would be able to build a map in an unknown area and navigate the mapped area after mapping. The ChatterBot provides the learning and conversational dialog engine which provides user-friendly interaction and feedbacks as a robotic companion to the elderly. The OpenCV is mainly used to perform the face detection, face tracking and motion detection tasks. A mobile application software (App) with streaming service is also developed to allow elderly's close relatives to monitor the health status and condition of the elderly. © 2020 IEEE.},
author_keywords={Arduino;  Artificial Intelligence;  ChatterBot;  Face Recognition;  OpenCV;  Radar;  Raspberryi Pi;  Robot;  Simultaneous Localization and Mapping},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Andinia2020220,
author={Andinia, A. and Isnainiyah, I.N.},
title={Design of Learning Application using Trivia Method based on Google Assistant for Vision Impairment Disability},
journal={Proceedings - 2nd International Conference on Informatics, Multimedia, Cyber, and Information System, ICIMCIS 2020},
year={2020},
pages={220-225},
doi={10.1109/ICIMCIS51567.2020.9354326},
art_number={9354326},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102197983&doi=10.1109%2fICIMCIS51567.2020.9354326&partnerID=40&md5=e939ec1ac99c3286f6f2cf0be79105b5},
affiliation={Universitas Pembangunan Nasional Veteran Jakarta, Information Systems Department, Jakarta, Indonesia},
abstract={This mobile based application called Natasha Bot is a virtual learning media aimed at people with disabilities especially blind people. Natasha Bot contains questions about subjects in schools designed for elementary school students in grade 6 in the form of guessing or trivia. The system and infrastructure supporting learning activities for people with disabilities that have been facilitated by the government are still lacking. Some problems have arisen such as the inconvenience of students with disabilities in the learning environment because they feel different. Teachers in inclusive schools also have not been equipped with special skills or techniques for people with disabilities. The Natasha Bot application comes as an innovation that utilizes open source technology from Google. It is designed to make students with disabilities, especially the blind, feel comfortable in learning activities. Natasha Bot offers voice features as a two-way communication between the student and Bot. This research uses the design thinking method. To create Natasha Bot as a virtual friend as well as a learning media. Natasha Bot comes with Artificial Intelligence technology and is designed using the Google Assistant framework with the method of trivia or guessing. Natasha Bot is expected to help advance the world of education, especially for people with disabilities on visual impairments with a more teachable and psychological approach. © 2020 IEEE.},
author_keywords={artificial intelligence;  blindness;  disability;  Google Assistant;  virtual learning},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Simud2020,
author={Simud, T. and Ruengittinun, S. and Surasvadi, N. and Sanglerdsinlapachai, N. and Plangprasopchok, A.},
title={A Conversational Agent for Database Query: A Use Case for Thai People Map and Analytics Platform},
journal={Proceedings - 2020 15th International Joint Symposium on Artificial Intelligence and Natural Language Processing, iSAI-NLP 2020},
year={2020},
doi={10.1109/iSAI-NLP51646.2020.9376833},
art_number={9376833},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103739785&doi=10.1109%2fiSAI-NLP51646.2020.9376833&partnerID=40&md5=d7781662b01c04d65f3547afef8e8aae},
affiliation={Kasetsart University, Faculty of Science, Department of Computer Science, Bangkok, Thailand; National Electronics and Computer Technology Center, Pathum Thani, Thailand},
abstract={Since 2018, Thai People Map and Analytics Platform (TPMAP) has been developed with the aims of supporting government officials and policy makers with integrated household and community data to analyze strategic plans, implement policies and decisions to alleviate poverty. However, to acquire complex information from the platform, non-technical users with no database background have to ask a programmer or a data scientist to query data for them. Such a process is time-consuming and might result in inaccurate information retrieved due to miscommunication between non-technical and technical users. In this paper, we have developed a Thai conversational agent on top of TPMAP to support self-service data analytics on complex queries. Users can simply use natural language to fetch information from our chatbot and the query results are presented to users in easy-to-use formats such as statistics and charts. The proposed conversational agent retrieves and transforms natural language queries into query representations with relevant entities, query intentions, and output formats of the query. We employ Rasa, an open-source conversational AI engine, for agent development. The results show that our system yields Fl-score of 0.9747 for intent classification and 0.7163 for entity extraction. The obtained intents and entities are then used for query target information from a graph database. Finally, our system achieves end-to-end performance with accuracies ranging from 57.5%-80.0%, depending on query message complexity. The generated answers are then returned to users through a messaging channel. © 2020 IEEE.},
author_keywords={Chatbot;  Conversational agent;  Data analytics;  Data visualization;  Poverty alleviation},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wessel20201674,
author={Wessel, M.},
title={Enhancing developers' support on pull requests activities with software bots},
journal={ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year={2020},
pages={1674-1677},
doi={10.1145/3368089.3418539},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097203950&doi=10.1145%2f3368089.3418539&partnerID=40&md5=71f3b02fe1da3bdbc774fc76fe192341},
affiliation={University of São Paulo, São Paulo, Brazil},
abstract={Software bots are employed to support developers' activities, serving as conduits between developers and other tools. Due to their focus on task automation, bots have become particularly relevant for Open Source Software (OSS) projects hosted on GitHub. While bots are adopted to save development cost, time, and effort, the bots' presence can be disruptive to the community. My research goal is two-fold: (i) identify problems caused by bots that interact in pull requests, and (ii) help bot designers enhance existing bots. Toward this end, we are interviewing maintainers, contributors, and bot developers to understand the problems in the human-bot interaction and how they affect the collaboration in a project. Afterward, we will employ Design Fiction to capture the developers' vision of bots' capabilities, in order to define guidelines for the design of bots on social coding platforms, and derive requirements for a meta-bot to deal with the problems. This work contributes more broadly to the design and use of software bots to enhance developers' collaboration and interaction. © 2020 ACM.},
author_keywords={GitHub Bots;  Open-source Software;  Software Bots},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Erlenhov2020445,
author={Erlenhov, L. and Neto, F.G.D.O. and Leitner, P.},
title={An empirical study of bots in software development: Characteristics and challenges from a practitioner's perspective},
journal={ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year={2020},
pages={445-455},
doi={10.1145/3368089.3409680},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097155537&doi=10.1145%2f3368089.3409680&partnerID=40&md5=47c4d85666c0eb17f400da7cd1954f1c},
affiliation={Software Engineering Division, Chalmers | University of Gothenburg, Gothenburg, Sweden},
abstract={Software engineering bots - automated tools that handle tedious tasks - are increasingly used by industrial and open source projects to improve developer productivity. Current research in this area is held back by a lack of consensus of what software engineering bots (DevBots) actually are, what characteristics distinguish them from other tools, and what benefits and challenges are associated with DevBot usage. In this paper we report on a mixed-method empirical study of DevBot usage in industrial practice. We report on findings from interviewing 21 and surveying a total of 111 developers. We identify three different personas among DevBot users (focusing on autonomy, chat interfaces, and "smartness"), each with different definitions of what a DevBot is, why developers use them, and what they struggle with.We conclude that future DevBot research should situate their work within our framework, to clearly identify what type of bot the work targets, and what advantages practitioners can expect. Further, we find that there currently is a lack of general purpose "smart"bots that go beyond simple automation tools or chat interfaces. This is problematic, as we have seen that such bots, if available, can have a transformative effect on the projects that use them. © 2020 ACM.},
author_keywords={Empirical study;  Software bot;  Software engineering},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gamage2020161,
author={Gamage, B. and Pushpananda, R. and Weerasinghe, R.},
title={The impact of using pre-trained word embeddings in sinhala chatbots},
journal={20th International Conference on Advances in ICT for Emerging Regions, ICTer 2020 - Proceedings},
year={2020},
pages={161-165},
doi={10.1109/ICTer51097.2020.9325440},
art_number={9325440},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100483687&doi=10.1109%2fICTer51097.2020.9325440&partnerID=40&md5=30958cd9cd16bc1464115501df52fd5a},
affiliation={University of Colombo School of Computing, Language Technology Research Laboratory, Colombo, Sri Lanka},
abstract={Providing conversational interfaces to IT services enable more people to access them conveniently. For maximum benefit, such interfaces need to be in the native language of the users in a community. Popularly known as chatbots, one of their critical tasks is to accurately identify the user's intention from their natural language input. This paper describes an attempt at improving this accuracy in an implementation based on the open source RASA stack, by using Sinhala word embeddings. This approach shows improvement in both intent detection as well as the confidence in the detected intents. © 2020 IEEE.},
author_keywords={Chatbot;  RASA;  Sinhala language;  Word embeddings},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lin202039,
author={Lin, S.-H. and Run, R.-S. and Yan, J.-Y.},
title={Chatbot application in laboratory equipment management and e-assistant},
journal={Proceedings - 2020 International Symposium on Computer, Consumer and Control, IS3C 2020},
year={2020},
pages={39-42},
doi={10.1109/IS3C50286.2020.00017},
art_number={9394105},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104838620&doi=10.1109%2fIS3C50286.2020.00017&partnerID=40&md5=1a50cc9d5bf4164d594892fde562a181},
affiliation={Dept. Electronic Engineering National United University, Miaoli, Taiwan; Freelancer, Taiwan},
abstract={For most of school employee usually meet a difficult task about manage a lot of equipment. For instance, recording their status, malfunction and repair history. The purpose of this study was to design a small chatbot system to help these people works easily. Due to technological advances in communication and Artificial Intelligence, user not only can access the chatbot service in everywhere but for Natural Language Understanding helps, chatbot can handle complex requests through simple natural language in Chinese. Compare with the traditional management approach, that was full of paper work and reaction against with malfunction condition inefficient, Database can help to collect and track their status. By review the older equipment records, researchers found those cause of the malfunction and repair steps for those same type of equipment were similarly. It also can be found by analyzed the database of this system. Hence, the system not only shows and records the equipment usages status but also provides a quickly and flexible troubleshooting according to analyzed their malfunction and repair history. We also planned to open source this system's architecture to help those people who needs to process the objects status such as books in Library, the equipment status and products quality in manufactory processing. © 2020 IEEE},
author_keywords={Chatbot;  Human-computer interaction;  Natural language understanding},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bagchi2020329,
author={Bagchi, M.},
title={Conceptualising a library chatbot using open source conversational artificial intelligence},
journal={DESIDOC Journal of Library and Information Technology},
year={2020},
volume={40},
number={6},
pages={329-333},
doi={10.14429/djlit.40.6.15611},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097538785&doi=10.14429%2fdjlit.40.6.15611&partnerID=40&md5=1be12e11c69b7a67d1657313ff7695f3},
affiliation={Department of Information Engineering and Computer Science (DISI), University of Trento, Italy},
abstract={Conversational software, or chatbots in popular parlance, have been considered a potential game changer for people-centric institutions for some time now. In sync with the trend, various libraries and knowledge resource centres have also adopted chatbots within their technological fold, with an aim to provide improved services to patrons. The only bottleneck towards such implementation has been the dearth of open source conversational software platforms. The purpose of the paper is to conceptualise a novel library chatbot using a recently developed, artificial intelligence-powered open source conversational software platform named Rasa, and to propose its potential adoption by libraries. The paper introduces the essence of chatbot technology and their present-day application in libraries. The paper also illustrates the technical underpinnings of Rasa Stack that can be leveraged to develop a library chatbot, and reflects on the potential future research in this direction. © 2020, DESIDOC.},
author_keywords={Chatbot;  Conversational AI;  Conversational software;  Dialogue management;  Human computer interaction;  Information retrieval;  Natural language processing;  Rasa OpenStack},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Wessel2020457,
author={Wessel, M. and Serebrenik, A. and Wiese, I. and Steinmacher, I. and Gerosa, M.A.},
title={What to Expect from Code Review Bots on GitHub?: A Survey with OSS Maintainers},
journal={ACM International Conference Proceeding Series},
year={2020},
pages={457-462},
doi={10.1145/3422392.3422459},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099338284&doi=10.1145%2f3422392.3422459&partnerID=40&md5=b79c2a4940e129dc0338d51e434068e4},
affiliation={University of São Paulo, Brazil; Eindhoven University of Technology, Netherlands; Universidade Tecnologica Federal Do Parana, Brazil; Northern Arizona University, United States},
abstract={Software bots are used by Open Source Software (OSS) projects to streamline the code review process. Interfacing between developers and automated services, code review bots report continuous integration failures, code quality checks, and code coverage. However, the impact of such bots on maintenance tasks is still neglected. In this paper, we study how project maintainers experience code review bots. We surveyed 127 maintainers and asked about their expectations and perception of changes incurred by code review bots. Our findings reveal that the most frequent expectations include enhancing the feedback bots provide to developers, reducing the maintenance burden for developers, and enforcing code coverage. While maintainers report that bots satisfied their expectations, they also perceived unexpected effects, such as communication noise and newcomers' dropout. Based on these results, we provide a series of implications for bot developers, as well as insights for future research. © 2020 ACM.},
author_keywords={code review;  open source software;  pull-based model;  software bots},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wessel2020183,
author={Wessel, M.},
title={Leveraging software bots to enhance developers' collaboration in online programming communities},
journal={Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW},
year={2020},
pages={183-188},
doi={10.1145/3406865.3418368},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095134913&doi=10.1145%2f3406865.3418368&partnerID=40&md5=30846af2acc0543b29de8b5f7cf195e7},
affiliation={University of São Paulo, São Paulo, Brazil},
abstract={Software bots are applications that are integrated into human communication channels, serving as an interface between users and other tools. Due to their focus on task automation, bots have become particularly relevant for Open Source Software (OSS) projects hosted on GitHub. While bots are adopted to save developers' costs, time, and effort, the interaction of these bots can be disruptive to the community. My research goal is two-fold: (i) identify problems caused by bots that interact in pull requests, and (ii) help bot designers to enhance existing bots, thereby improving the partnership with contributors and maintainers. Toward this end, we are interviewing developers to understand what are the problems on the human-bot interaction and how they affect human collaboration. Afterwards, we will employ Design Fiction to capture the developers' vision of bots' capabilities, in order to define guidelines for the design of bots on social coding platforms, and derive requirements for a meta-bot to deal with the problems. This work contributes more broadly to the design and use of software bots to enhance developers' collaboration and interaction. © 2020 Owner/Author.},
author_keywords={Github bots;  Open source software;  Software bots;  Software engineering},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Saini2020136,
author={Saini, R.},
title={Artificial intelligence empowered domain modelling bot},
journal={Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020 - Companion Proceedings},
year={2020},
pages={136-141},
doi={10.1145/3417990.3419486},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096754730&doi=10.1145%2f3417990.3419486&partnerID=40&md5=ccdeb66ef7e2741cbe0a9e6047c16510},
affiliation={McGill University, Montreál, QC, Canada},
abstract={With the increasing adoption of Model-Based Software Engineering (MBSE) to handle the complexity of modern software systems in industry and inclusion of modelling topics in academic curricula, it is no longer a question of whether to use MBSE but how to use it. Acquiring modelling skills to properly build and use models with the help of modelling formalisms are non-trivial learning objectives, which novice modellers struggle to achieve for several reasons. For example, it is difficult for novice modellers to learn to use their abstraction abilities. Also, due to high student-teacher ratios in a typical classroom setting, novice modellers may not receive personalized and timely feedback on their modelling decisions. These issues hinder the novice modellers in improving their modelling skills. Furthermore, a lack of modelling skills among modellers inhibits the adoption and practice of modelling in industry. Therefore, an automated and intelligent solution is required to help modellers and other practitioners in improving their modelling skills. This doctoral research builds an automated and intelligent solution for one modelling formalism - domain models, in an avatar of a domain modelling bot. The bot automatically extracts domain models from problem descriptions written in natural language and generates intelligent recommendations, particularly for teaching modelling literacy to novice modellers. For this domain modelling bot, we leverage the capabilities of various Artificial Intelligence techniques such as Natural Language Processing and Machine Learning. © 2020 ACM.},
author_keywords={Artificial intelligence (AI);  Bot;  Domain model;  Machine learning (ML);  Natural language (NL);  Natural language processing (NLP)},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Straub2020531,
author={Straub, J.},
title={Software Engineering: The First Line of Defense for Cybersecurity},
journal={Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS},
year={2020},
volume={2020-October},
pages={531-536},
doi={10.1109/ICSESS49938.2020.9237715},
art_number={9237715},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096158961&doi=10.1109%2fICSESS49938.2020.9237715&partnerID=40&md5=dd3400ae0617b68fa60d5a94be934759},
affiliation={Institute for Cyber Security Education and Research, North Dakota State University, Fargo, ND, United States},
abstract={Cybersecurity has become an area of critical concern due to an ever-growing number of security breaches. Some of these breaches compromise personal information, exposing individuals and firms to potential identity theft, fraud and other maladies. Other attacks seek to gain control of systems for use in attacking as part of bot nets and other indirect attack techniques. Yet other attacks target cyber-physical systems whose compromise could potentially lead to the injury or death of individuals relying on or nearby the equipment. This paper considers the role of software engineering in preventing cyberattacks and discusses the types of software engineering failures that translate into vulnerabilities that can be attacked. Prospective solutions and areas of needed future research are discussed. © 2020 IEEE.},
author_keywords={bugs;  cybersecurity;  defense;  development techniques;  software engineering;  testing},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Leno2020153,
author={Leno, V. and Augusto, A. and Dumas, M. and La Rosa, M. and Maggi, F.M. and Polyvyanyy, A.},
title={Identifying candidate routines for robotic process automation from unsegmented ui logs},
journal={Proceedings - 2020 2nd International Conference on Process Mining, ICPM 2020},
year={2020},
pages={153-160},
doi={10.1109/ICPM49681.2020.00031},
art_number={9229975},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096557828&doi=10.1109%2fICPM49681.2020.00031&partnerID=40&md5=ea961674e888a557d73b88d72881ff2f},
affiliation={University of Melbourne, Australia; University of Tartu, Estonia; Free University of Bozen-Bolzano, Italy},
abstract={Robotic Process Automation (RPA) is a technology to develop software bots that automate repetitive sequences of interactions between users and software applications (a.k. a. routines). To take full advantage of this technology, organizations need to identify and to scope their routines. This is a challenging endeavor in large organizations, as routines are usually not concentrated in a handful of processes, but rather scattered across the process landscape. Accordingly, the identification of routines from User Interaction (UI) logs has received significant attention. Existing approaches to this problem assume that the UI log is segmented, meaning that it consists of traces of a task that is presupposed to contain one or more routines. However, a UI log usually takes the form of a single unsegmented sequence of events. This paper presents an approach to discover candidate routines from unsegmented UI logs in the presence of noise, i.e. events within or between routine instances that do not belong to any routine. The approach is implemented as an open-source tool and evaluated using synthetic and real-life UI logs. © 2020 IEEE.},
author_keywords={Robotic process automation;  robotic process mining;  user interaction log},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Burtsev202018,
author={Burtsev, M. and Logacheva, V.},
title={Conversational intelligence challenge: Accelerating research with crowd science and open source},
journal={AI Magazine},
year={2020},
volume={41},
number={3},
pages={18-27},
doi={10.1609/AIMAG.V41I3.5324},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092759087&doi=10.1609%2fAIMAG.V41I3.5324&partnerID=40&md5=5e10d0313baebd9309120c7741dce392},
affiliation={Neural Networks and Deep Learning Laboratory, Moscow Institute of Physics and Technology, Moscow, Russian Federation; Center for Computational and Data-Intensive Science and Engineering, Skolkovo Institute of Science and Technology, Moscow, Russian Federation},
abstract={Development of conversational systems is one of the most challenging tasks in natural language processing, and it is especially hard in the case of open-domain dialogue. The main factors that hinder progress in this area are lack of training data and difficulty of automatic evaluation. Thus, to reliably evaluate the quality of such models, one needs to resort to time-consuming and expensive human evaluation. We tackle these problems by organizing the Conversational Intelligence Challenge (ConvAI) — open competition of dialogue systems. Our goals are threefold: to work out a good design for human evaluation of open-domain dialogue, to grow open-source code base for conversational systems, and to harvest and publish new datasets. Over the course of ConvAI1 and ConvAI2 competitions, we developed a framework for evaluation of chatbots in messaging platforms and used it to evaluate over 30 dialogue systems in two conversational tasks — discussion of short text snippets from Wikipedia and personalized small talk. These large-scale evaluation experiments were performed by recruiting volunteers as well as paid workers. As a result, we succeeded in collecting a dataset of around 5,000 long meaningful human-to-bot dialogues and got many insights into the organization of human evaluation. This dataset can be used to train an automatic evaluation model or to improve the quality of dialogue systems. Our analysis of ConvAI1 and ConvAI2 competitions shows that the future work in this area should be centered around the more active participation of volunteers in the assessment of dialogue systems. To achieve that, we plan to make the evaluation setup more engaging. Copyright © 2020, Association for the Advancement of Artificial Intelligence. All rights reserved.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{FiddinAlIslami2020557,
author={Fiddin Al Islami, M.T. and Ridho Barakbah, A. and Harsono, T.},
title={Interactive applied graph chatbot with semantic recognition},
journal={IES 2020 - International Electronics Symposium: The Role of Autonomous and Intelligent Systems for Human Life and Comfort},
year={2020},
pages={557-564},
doi={10.1109/IES50839.2020.9231678},
art_number={9231678},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096781741&doi=10.1109%2fIES50839.2020.9231678&partnerID=40&md5=9abd180d5751daf5f5aa7b42b3d35d50},
affiliation={Politeknik Elektronika Negeri Surabaya, Department of Information and Computer Engineering, Surabaya, Indonesia},
abstract={Companies and small medium businesses (UMKM) need to interact with customers to increase their customer retention rate. One of the ways is to use chatbot. Aside from being cost-effective, this method is also very effective and very easy for companies to use. To make an easy and effective chatbot requires a combination of two scientific fields, artificial intelligence and software engineering. This study has the following features. 1) Affective sentiment analysis, this feature is inspired by Russel's Circumplex Model. Adjective words will be mapped in a matrix with values based on the Russell Circumplex Model. This model will pay attention on the adjective words, polarity, and affection degree of a sentence. 2) Conjunction sentiment analysis, consider of free way of interaction nowdays, a sentiment analysis system need to determine the sentiment value in multilevel sentences. This multilevel sentence has one or more conjunctions. This conjunction sentiment system will break sentences based on conjunction. The fractional sentence will be processed by affective sentiment analysis. The system then considers the nature of the conjunction to determine the sentiment of the whole sentence. 3) Graph Chatbot, this feature is used to make it easy for companies to modify and generate their bots. This bot will interact with customers like humans, based on a graph chat map that has been created. Chatbot graphs were developed using javascript library Vue js to make it easier to manipulate the visual graph. The system produces satisfying accuracy. Graph chatbot can handle procedural conversations very well. The flow of conversation in accordance with the graph that has been defined. Graph chatbot has 100% accuracy and successfully responds to all user conversations. The sentiment method has 63% accuracy. © 2020 IEEE.},
author_keywords={affective conjunction sentiment;  circumplex model.;  interactive graph chatbot;  retention rate},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wessel20201,
author={Wessel, M. and Serebrenik, A. and Wiese, I. and Steinmacher, I. and Gerosa, M.A.},
title={Effects of Adopting Code Review Bots on Pull Requests to OSS Projects},
journal={Proceedings - 2020 IEEE International Conference on Software Maintenance and Evolution, ICSME 2020},
year={2020},
pages={1-11},
doi={10.1109/ICSME46990.2020.00011},
art_number={9240622},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096665299&doi=10.1109%2fICSME46990.2020.00011&partnerID=40&md5=8889c0dd0aa075cdac467f16bf372f49},
affiliation={University of São Paulo, Brazil; Eindhoven University of Technology, Netherlands; Universidade Tecnológica Federal Do Paraná, Campo Mourão, Brazil; Northern Arizona University, United States},
abstract={Software bots, which are widely adopted by Open Source Software (OSS) projects, support developers on several activities, including code review. However, as with any new technology adoption, bots may impact group dynamics. Since understanding and anticipating such effects is important for planning and management, we investigate how several activity indicators change after the adoption of a code review bot. We employed a regression discontinuity design on 1,194 software projects from GitHub. Our results indicate that the adoption of code review bots increases the number of monthly merged pull requests, decreases monthly non-merged pull requests, and decreases communication among developers. Practitioners and maintainers may leverage our results to understand, or even predict, bot effects on their projects' social interactions. © 2020 IEEE.},
author_keywords={Code Review;  GitHub Bots;  Open Source Software;  Software Bots;  Software Engineering},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Abulaish202052,
author={Abulaish, M. and Fazil, M.},
title={Socialbots: Impacts, Threat-Dimensions, and Defense Challenges},
journal={IEEE Technology and Society Magazine},
year={2020},
volume={39},
number={3},
pages={52-61},
doi={10.1109/MTS.2020.3012327},
art_number={9199336},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092110363&doi=10.1109%2fMTS.2020.3012327&partnerID=40&md5=e213b75596c046c5d0563e3298d85876},
affiliation={South Asian University, Department of Computer Science, Akbar Bhawan Chanakyapuri, New Delhi, Delhi, 110021, India; Jamia Millia Islamia, Department of Computer Science, New Delhi, Delhi, India},
abstract={Online Social Networks (OSNs) are the modern communication media at the peak of Internet technology that facilitate users' ability to connect with friends and celebrities, and to disseminate breaking news and updates on real-life events. Connections and interactions among OSN users generate a massive amount of data containing a rich collection of knowledge that could be useful to various realworld data modeling and predictive analytics problems like open-source intelligence, business intelligence, event prediction, and product recommendations. On the Web, adversaries explore and target products and services for misuse and vulnerabilities, and OSNs are no exception. Their large user base, easy-to-use functionality, and open nature further attract antisocial elements to these OSNs. In OSNs, cybercrimes and illicit activities are generally committed using various forms of fake profiles, such as clone profiles, and bots. © 1982-2012 IEEE.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Deepika20201196,
author={Deepika, K. and Tilekya, V. and Mamatha, J. and Subetha, T.},
title={Jollity Chatbot- A contextual AI Assistant},
journal={Proceedings of the 3rd International Conference on Smart Systems and Inventive Technology, ICSSIT 2020},
year={2020},
pages={1196-1200},
doi={10.1109/ICSSIT48917.2020.9214076},
art_number={9214076},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094847216&doi=10.1109%2fICSSIT48917.2020.9214076&partnerID=40&md5=8511746c245c86a2fb24edb714f8579f},
affiliation={BVRIT Hyderabad College of Engineering for Women, Dept of It, Hyderabad, India},
abstract={Chatbot is a software application that can stimulate a conversation via text, instead of direct contact with a live human through messaging applications, websites and mobile applications. Chatbot applications help to make interactions between people and services by enhancing the customer experience. Chatbot is widely used in the areas of food ordering, ecommerce and transportation, etc. Practically it is not possible to find a permanent companion to make us happy all the time. Hence, this paper has planned to design a jollity chatbot to talk with the human users and make sure that it entertains and give suggestion and motivation in tough times. The jollity chatbot is implemented in Rasa, an open -source conversational AI framework and it is easy to customize. The proposed method has added 12 intents with each more than 8 text examples constituting a total of 100 input samples in nlu.md and their response in domain.yml. The flow of interactions is given in stories.md. The jollity chatbot is deployed in Telegram using ngrok and the server URL details and the access token are given in the credentials.yml. The system is experimented with various evaluation measures like accuracy of the intents, accuracy of the stories and the confusion matrix to shows that the proposed jollity chatbot system is more robust and can identify the user intents appropriately. © 2020 IEEE.},
author_keywords={Chatbot;  Contextual AI Assistant;  Rasa;  Rasa Core;  Rasa NLU},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lee20203121,
author={Lee, C.-S. and Wang, M.-H. and Tsai, Y.-L. and Ko, L.-W. and Tsai, B.-Y. and Hung, P.-H. and Lin, L.-A. and Kubota, N.},
title={Intelligent agent for real-world applications on robotic edutainment and humanized co-learning},
journal={Journal of Ambient Intelligence and Humanized Computing},
year={2020},
volume={11},
number={8},
pages={3121-3139},
doi={10.1007/s12652-019-01454-4},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073990198&doi=10.1007%2fs12652-019-01454-4&partnerID=40&md5=e03dbc727e4230b14b78fadb378ce341},
affiliation={Department of Computer Science and Information Engineering, National University of Tainan, Tainan, Taiwan; Institute of Bioinformatics and Systems Biology, National Chiao Tung University, Hsinchu, Taiwan; Department of Education, National University of Tainan, Tainan, Taiwan; Taiwan Go Association, Taipei, Taiwan; Graduate School of Systems Design, Tokyo Metropolitan University, Tokyo, Japan},
abstract={Dynamic assessment with an intelligent agent can differentiate the capabilities and proficiency of students. It can therefore be advocated as an interactive approach to conduct assessments on students in learning systems. Facebook AI Research proposed ELF OpenGo, an open-source reimplementation of the AlphaZero algorithm. They also developed Darkforest, which displays the competence and skills of high-level amateur Go players. To enable these open-source AI bots to assist humans at different levels in learning Go, this paper proposes an intelligent agent for real-world applications in robotic edutainment and humanized co-learning. To achieve this, we successfully constructed an OpenGo Darkforest (OGD) cloud platform using these AI bots and further combined the brain computer interface with the OGD cloud platform to observe the relationship between the brainwaves and win rates of human Go players. The intelligent agent also converted human brainwaves into physiological indices and reflected these in the robot to express human feelings or emotions in real-time. For future educational applications, this paper also presents intelligent robot teachers learning together with students in Taiwan and Japan. More than 200 students have been co-learning with intelligent robot teachers in Tainan, Kaohsiung, Taipei, and Tokyo from 2018 to 2019. The learning performance and feedback from students and teachers has been extremely positive, especially from remedial students. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.},
author_keywords={Brain–computer-interface;  Dynamic assessment;  Humanized co-learning;  Intelligent agent;  Robot edutainment},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Palaniswamy2020954,
author={Palaniswamy, T. and Al-Ghamdi, R. and Banabilah, A. and Kuddah, M. and Attiah, N.},
title={Chatbot-based Smart Locker Communication System},
journal={Proceedings of the 2nd International Conference on Inventive Research in Computing Applications, ICIRCA 2020},
year={2020},
pages={954-959},
doi={10.1109/ICIRCA48905.2020.9183102},
art_number={9183102},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092028266&doi=10.1109%2fICIRCA48905.2020.9183102&partnerID=40&md5=51f8ede9dce74696cbeeb5b411899fe8},
affiliation={King Abdulaziz University, Faculty of Engineering, Department of ECE, Saudi Arabia},
abstract={Nowadays, education organizations have become huge and divergent. Finding resources and tools that are related to the subjects is challenging for students. Therefore, a website work as a communication medium between students, alumni and faculties will help to solve the problem by letting them stay in touch whenever they need anything related to their major. To develop a Help Spot system, latest technology and components such as Beaglebone, Smart Door Latch, Logitech Webcam are used in the proposed work. This design was found to satisfy the objectives and solve the problem in the shortest time period. Based on the requirements, three alternatives design are generated as solutions to the problem. The first and second alternatives use three-tier architecture and fortify. The third alternative is the best solution which consists of a website, mobile application, and a QR code-based locker to provide a self-delivery option. Moreover, the website is adaptable for different screen size. Automatic monitoring, guaranteed malware removal and open source programming languages are deployed along with several features such as chatbot. © 2020 IEEE.},
author_keywords={communication;  lockers;  mobile application;  QR code;  website},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Dey2020209,
author={Dey, T. and Mousavi, S. and Ponce, E. and Fry, T. and Vasilescu, B. and Filippova, A. and Mockus, A.},
title={Detecting and Characterizing Bots that Commit Code},
journal={Proceedings - 2020 IEEE/ACM 17th International Conference on Mining Software Repositories, MSR 2020},
year={2020},
pages={209-219},
doi={10.1145/3379597.3387478},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093690882&doi=10.1145%2f3379597.3387478&partnerID=40&md5=93ad989e3c48c39afe290dbc84bfa487},
affiliation={University of Tennessee, Knoxville, United States; Carnegie Mellon University, Pittsburgh, United States; Github, San Francisco, United States},
abstract={Background: Some developer activity traditionally performed manually, such as making code commits, opening, managing, or closing issues is increasingly subject to automation in many OSS projects. Specifically, such activity is often performed by tools that react to events or run at specific times. We refer to such automation tools as bots and, in many software mining scenarios related to developer productivity or code quality, it is desirable to identify bots in order to separate their actions from actions of individuals. Aim: Find an automated way of identifying bots and code committed by these bots, and to characterize the types of bots based on their activity patterns. Method and Result: We propose BIMAN, a systematic approach to detect bots using author names, commit messages, files modified by the commit, and projects associated with the commits. For our test data, the value for AUC-ROC was 0.9. We also characterized these bots based on the time patterns of their code commits and the types of files modified, and found that they primarily work with documentation files and web pages, and these files are most prevalent in HTML and JavaScript ecosystems. We have compiled a shareable dataset containing detailed information about 461 bots we found (all of which have more than 1000 commits) and 13,762,430 commits they created. © 2020 ACM.},
author_keywords={automated commits;  bots;  ensemble model;  random forest;  social coding platforms;  software engineering},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2020,
title={Proceedings - 2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops, ICSEW 2020},
journal={Proceedings - 2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops, ICSEW 2020},
year={2020},
page_count={815},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093122799&partnerID=40&md5=53a35b520637f5a121ddda531961f7b2},
abstract={The proceedings contain 151 papers. The topics discussed include: selective symbolic type-guided checkpointing and restoration for autonomous vehicle repair; flake it 'till you make it: using automated repair to induce and fix latent test flakiness; refining fitness functions in test-based program repair; program repairing history as git repository; interactive patch generation and suggestion; impact of similarity on repairing small programs: a case study on Quixbugs benchmark; automatic repair of OWASP top 10 security vulnerabilities: a survey; bot or not? detecting bots in Github pull request activity based on comment similarity; challenges and guidelines on designing test cases for test bots; conversational bot for newcomers onboarding to open source projects; the inconvenient side of software bots on pull requests; and sorry to bother you again: developer recommendation choice architectures for designing effective bots.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Brown202056,
author={Brown, C. and Parnin, C.},
title={Sorry to Bother You Again: Developer Recommendation Choice Architectures for Designing Effective Bots},
journal={Proceedings - 2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops, ICSEW 2020},
year={2020},
pages={56-60},
doi={10.1145/3387940.3391506},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093083849&doi=10.1145%2f3387940.3391506&partnerID=40&md5=be02bdedf0eb48a60c84766327ac6f6c},
affiliation={North Carolina State University, Raleigh, NC, United States},
abstract={Software robots, or bots, are useful for automating a wide variety of programming and software development tasks. Despite the advantages of using bots throughout the software engineering process, research shows that developers often face challenges interacting with these systems. To improve automated developer recommendations from bots, this work introduces developer recommendation choice architectures. Choice architecture is a behavioral science concept that suggests the presentation of options impacts the decisions humans make. To evaluate the impact of framing recommendations for software engineers, we examine the impact of one choice architecture, actionability, for improving the design of bot recommendations. We present the results of a preliminary study evaluating this choice architecture in a bot and provide implications for integrating choice architecture into the design of future software engineering bots. © 2020 ACM.},
author_keywords={choice architecture;  developer behavior;  recommendations;  software engineering},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Dominic202046,
author={Dominic, J. and Houser, J. and Steinmacher, I. and Ritter, C. and Rodeghero, P.},
title={Conversational Bot for Newcomers Onboarding to Open Source Projects},
journal={Proceedings - 2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops, ICSEW 2020},
year={2020},
pages={46-50},
doi={10.1145/3387940.3391534},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093082343&doi=10.1145%2f3387940.3391534&partnerID=40&md5=dce8d7d29beebf8080b98eac6b0fc493},
affiliation={Clemson University, Clemson, SC, United States; University of Northern Arizona, Flagstaff, AZ, United States},
abstract={This paper targets the problems newcomers face when onboarding to open source projects and the low retention rate of newcomers. Open source software projects are becoming increasingly more popular. Many major companies have started building open source software. Unfortunately, many newcomers only commit once to an open source project before moving on to another project. Even worse, many novices struggle with joining open source communities and end up leaving quickly, sometimes before their first successful contribution. In this paper, we propose a conversational bot that would recommend projects to newcomers and assist in the onboarding to the open source community. The bot would be able to provide helpful resources, such as Stack Overflow related content. It would also be able to recommend human mentors. We believe that this bot would improve newcomers' experience by providing support not only during their first contribution, but by acting as an agent to engage them to the project. © 2020 ACM.},
author_keywords={bot;  newcomer;  onboarding;  open source software},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wessel202051,
author={Wessel, M. and Steinmacher, I.},
title={The Inconvenient Side of Software Bots on Pull Requests},
journal={Proceedings - 2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops, ICSEW 2020},
year={2020},
pages={51-55},
doi={10.1145/3387940.3391504},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093080394&doi=10.1145%2f3387940.3391504&partnerID=40&md5=2b7490ad899417bbeb5c4b9312768ed6},
affiliation={University of Sao Paulo, Sao Paulo, Brazil; Northern Arizona University, Flagstaff, United States},
abstract={Software bots are applications that integrate their work with humans' tasks, serving as conduits between users and other tools. Due to their ability to automate tasks, bots have been widely adopted by Open Source Software (OSS) projects hosted on GitHub. Commonly, OSS projects use bots to automate a variety of routine tasks to save time from maintainers and contributors. Although bots can be useful for supporting maintainers' work, sometimes their comments are seen as spams, and are quickly ignored by contributors. In fact, the way that these bots interact on pull requests can be disruptive and perceived as unwelcoming. In this paper, we propose the concept of a meta-bot to deal with current problems on the human-bot interaction on pull requests. Besides providing additional value to this interaction, meta-bot will reduce interruptions and help maintainers and contributors stay aware of important information. © 2020 ACM.},
author_keywords={bots;  meta-bot;  open source software;  pull-based model;  software bots},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2020,
title={Proceedings - 2020 IEEE/ACM International Conference on Software and System Processes, ICSSP 2020},
journal={Proceedings - 2020 IEEE/ACM International Conference on Software and System Processes, ICSSP 2020},
year={2020},
page_count={203},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092471438&partnerID=40&md5=38a6b8e8eeb54c3071c970a04f037d74},
abstract={The proceedings contain 21 papers. The topics discussed include: do instance-level review diagrams support validation processes of cyber-physical system specifications; generating use case scenarios from user stories; process implications of executable domain models for microservices development; charting coordination needs in large-scale agile organizations with boundary objects and methodological islands; determining context factors for hybrid development methods with trained models; why do software teams deviate from scrum? reasons and implications; process inspection support: an industrial case study; onboarding bot for newcomers to software engineering; experimentation for business-to-business mission-critical systems: a case study; action-based recommendation in pull-request development; and emerging and changing tasks in the development process for machine learning systems.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Dominic202091,
author={Dominic, J. and Ritter, C. and Rodeghero, P.},
title={Onboarding bot for newcomers to software engineering},
journal={Proceedings - 2020 IEEE/ACM International Conference on Software and System Processes, ICSSP 2020},
year={2020},
pages={91-94},
doi={10.1145/3379177.3388901},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092462077&doi=10.1145%2f3379177.3388901&partnerID=40&md5=fb01f796df697aff2812072de812a6cc},
affiliation={Clemson University, Clemson, United States},
abstract={Software development teams dedicate considerable resources to training newcomers. Newcomers are new developers to a software project. The software onboarding process is more complicated than onboarding into other organizations. It is much more challenging and time-consuming. The role of a mentor in onboarding newcomers in software engineering is well understood. However, the disruptions to the work of an experienced developer can reduce the quality of their work and job satisfaction. We propose a conversational bot that can help onboard newcomers to a software project instead of an experienced programmer. The bot will act as a mentor for the newcomer, thus putting less stress on experienced programmers. The bot will also be able to scan outside sources, such as stack overflow, for solutions to issues a newcomer may face. The newcomer will be able to interact with the bot using natural language. We will use this bot to assess improvements to code quality in future studies. © 2020 ACM.},
author_keywords={bot;  newcomer;  onboarding;  open source software},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Prasetyo2020436,
author={Prasetyo, P.K. and Achananuparp, P. and Lim, E.-P.},
title={Foodbot: A goal-oriented just-in-time healthy eating interventions chatbot},
journal={ACM International Conference Proceeding Series},
year={2020},
pages={436-439},
doi={10.1145/3421937.3421960},
art_number={3421960},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100741299&doi=10.1145%2f3421937.3421960&partnerID=40&md5=9a02903f306779216944529bfd6186ab},
affiliation={Singapore Management University, Singapore},
abstract={Recent research has identified a few design flaws in popular mobile health (mHealth) applications for promoting healthy eating lifestyle, such as mobile food journals. These include tediousness of manual food logging, inadequate food database coverage, and a lack of healthy dietary goal setting. To address these issues, we present Foodbot, a chatbot-based mHealth application for goal-oriented just-in-time (JIT) healthy eating interventions. Powered by a large-scale food knowledge graph, Foodbot utilizes automatic speech recognition and mobile messaging interface to record food intake. Moreover, Foodbot allows users to set goals and guides their behavior toward the goals via JIT notification prompts, interactive dialogues, and personalized recommendation. Altogether, the Foodbot framework demonstrates the use of open-source data, tools, and platforms to build a practical mHealth solution for supporting healthy eating lifestyle in the general population. © 2020 ACM.},
author_keywords={Chatbot;  Diet;  Food journal;  Food recommendation;  Goal-setting;  Just-in-time intervention;  Knowledge graph;  MHealth;  Self-tracking},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Niculescu202029,
author={Niculescu, A.I. and Kukanov, I. and Wadhwa, B.},
title={DigiMo-towards developing an emotional intelligent chatbot in Singapore},
journal={ACM International Conference Proceeding Series},
year={2020},
pages={29-32},
doi={10.1145/3391203.3391210},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091401402&doi=10.1145%2f3391203.3391210&partnerID=40&md5=81b2182f79c8ad81a84a37cf51fdb33d},
affiliation={Institute for Infocomm Research Singapore, Singapore; National University of Singapore Singapore, Singapore},
abstract={The paper is a work in progress report on the development of DigiMo, a chatbot with emotional intelligence. The chatbot development is based on a data collection and annotations of real dialogues between local Singaporeans expressing genuine emotions. The models were trained with cakechat, an open source sequence-to-sequence deep neural network. Perplexity measurements from automatic testing, as well as feedback from 6 expert evaluators confirmed the chatbot answers have high accuracy. © 2020 ACM.},
author_keywords={chatbot;  data annotation;  deep learning;  emotion;  expert evaluation;  Natural language interaction},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Liu2020,
author={Liu, D. and Smith, M.J. and Veeramachaneni, K.},
title={Understanding user-bot interactions for small-scale automation in open-source development},
journal={Conference on Human Factors in Computing Systems - Proceedings},
year={2020},
doi={10.1145/3334480.3382998},
art_number={3382998},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090201177&doi=10.1145%2f3334480.3382998&partnerID=40&md5=6a6b818ba45fcba3860221a00b945be0},
affiliation={Massachusetts Institute of Technology, Cambridge, MA, United States},
abstract={Small-scale automation tools, or "bots," have been widely deployed in open-source software development to support manual project maintenance tasks. Though interactions between these bots and human developers can have significant effects on user experience, previous research has instead mostly focused on project outcomes. We reviewed existing small-scale bots in wide use on GitHub. After an in-depth qualitative and quantitative evaluation, we compiled several important design principles for human-bot interaction in this context. Following the requirements, we further propose a workflow to support bot developers. © 2020 Owner/Author.},
author_keywords={HCI design and evaluation methods;  Human-centered computing;  Software and its engineering;  Software creation and management},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Okanović2020120,
author={Okanović, D. and Beck, S. and Merz, L. and Zorn, C. and Merino, L. and Van Hoorn, A. and Beck, F.},
title={Can a chatbot support software engineers with load testing? approach and experiences},
journal={ICPE 2020 - Proceedings of the ACM/SPEC International Conference on Performance Engineering},
year={2020},
pages={120-129},
doi={10.1145/3358960.3375792},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085954717&doi=10.1145%2f3358960.3375792&partnerID=40&md5=5539286821ac8d4d4baffc2712895ec0},
affiliation={Novatec Consulting GmbH, Leinfelden-Echterdingen, Germany; University of Stuttgart, Stuttgart, Germany; University of Duisburg-Essen, Essen, Germany},
abstract={Even though load testing is an established technique to assess load-related quality properties of software systems, it is applied only seldom and with questionable results. Indeed, configuring, executing, and interpreting results of a load test require high effort and expertise. Since chatbots have shown promising results for interactively supporting complex tasks in various domains (including software engineering), we hypothesize that chatbots can provide developers suitable support for load testing. In this paper, we present PerformoBot, our chatbot for configuring and running load tests. In a natural language conversation, PerformoBot guides developers through the process of properly specifying the parameters of a load test, which is then automatically executed by PerformoBot using a state-of-the-art load testing tool. After the execution, PerformoBot provides developers a report that answers the respective concern. We report on results of a user study that involved 47 participants, in which we assessed our tool's acceptance and effectiveness. We found that participants in the study, particularly those with a lower level of expertise in performance engineering, had a mostly positive view of PerformoBot. © 2020 ACM.},
author_keywords={Chatbots;  Reporting;  Software performance},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ren2020260,
author={Ren, R. and Castro, J.W. and Santos, A. and Pérez-Soler, S. and Acuña, S.T. and De Lara, J.},
title={Collaborative Modelling: Chatbots or On-Line Tools? An Experimental Study},
journal={ACM International Conference Proceeding Series},
year={2020},
pages={260-269},
doi={10.1145/3383219.3383246},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090858478&doi=10.1145%2f3383219.3383246&partnerID=40&md5=19d7409564b203f70db3997e5c0d3add},
affiliation={Universidad Autónoma de Madrid, Madrid, Spain; Universidad de Atacama, Copiapó, Chile; University of Oulu, Oulu, Finland},
abstract={Modelling is a fundamental activity in software engineering, which is often performed in collaboration. For this purpose, on-line tools running on the cloud are frequently used. However, recent advances in Natural Language Processing have fostered the emergence of chatbots, which are increasingly used for all sorts of software engineering tasks, including modelling. To evaluate to what extent chatbots are suitable for collaborative modelling, we conducted an experimental study with 54 participants, to evaluate the usability of a modelling chatbot called SOCIO, comparing it with the on-line tool Creately. We employed a within-subjects cross-over design of 2 sequences and 2 periods. Usability was determined by attributes of efficiency, effectiveness, satisfaction and quality of the results. We found that SOCIO saved time and reduced communication effort over Creately. SOCIO satisfied users to a greater extent than Creately, while in effectiveness results were similar. With respect to diagram quality, SOCIO outperformed Creately in terms of precision, while solutions with Creately had better recall and perceived success. However, in terms of accuracy and error scores, both tools were similar. © 2020 ACM.},
author_keywords={Chatbots;  Collaborative modelling;  Effectiveness;  Efficiency;  Quality;  Satisfaction;  Usability},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Dwitam2020890,
author={Dwitam, F. and Rusli, A.},
title={User stories collection via interactive chatbot to support requirements gathering},
journal={Telkomnika (Telecommunication Computing Electronics and Control)},
year={2020},
volume={18},
number={2},
pages={890-898},
doi={10.12928/TELKOMNIKA.V18I2.14866},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084148243&doi=10.12928%2fTELKOMNIKA.V18I2.14866&partnerID=40&md5=7d9f3ea0cef5f87f3f77b2f333d49da7},
affiliation={Department of Informatics, Universitas Multimedia Nusantara, Indonesia},
abstract={Nowadays, software products have become an essential part of human life. To build software, developers must have a good understanding of the requirements of the software. However, software developers tend to jumpstart system construction without having a clear and detailed understanding of the requirements. The user story concept is one of the practices of the requirements elicitation. This paper aims to present the work conducted to develop an Android chatbot application to support the requirements elicitation activity in software engineering, making the work less time-consuming and structured even for users not accustomed to requirements engineering. The chatbot uses Nazief & Adriani stemming algorithm to pre-process the natural language it receives from the users and artificial mark-up language (AIML) as the knowledge base to process the bot's responses. A preliminary acceptance test based on the technology acceptance model results in an 83.03% score for users' behavioral intention to use. © 2020, Universitas Ahmad Dahlan.},
author_keywords={AIML;  Chatbot;  Nazief and adriani algorithm;  Requirements elicitation;  User stories},
document_type={Article},
source={Scopus},
}

@ARTICLE{Hall2020,
author={Hall, B.A. and Fisher, J.},
title={Constructing and Analyzing Computational Models of Cell Signaling with BioModelAnalyzer},
journal={Current Protocols in Bioinformatics},
year={2020},
volume={69},
number={1},
doi={10.1002/cpbi.95},
art_number={e95},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081135787&doi=10.1002%2fcpbi.95&partnerID=40&md5=35a0e6cf878556a3caf98e8229993d2d},
affiliation={MRC Cancer Unit, University of Cambridge, Cambridge, United Kingdom; UCL Cancer Institute, University College London, London, United Kingdom},
abstract={BioModelAnalyzer (BMA) is an open-source graphical tool for the development of executable models of protein and gene networks within cells. Based upon the Qualitative Networks formalism, the user can rapidly construct large networks, either manually or by connecting motifs selected from a built-in library. After the appropriate functions for each variable are defined, the user has access to three analysis engines to test the model. In addition to standard simulation tools, BMA includes an interface to the stability-testing algorithm and to a graphical Linear Temporal Logic (LTL) editor and analysis tool. Alongside this, we have developed a novel ChatBot to aid users constructing LTL queries and to explain the interface and run through tutorials. Here we present worked examples of model construction and testing via the interface. As an initial example, we discuss fate decisions in Dictyostelium discoidum and cAMP signaling. We go on to describe the workflow leading to the construction of a published model of the germline of C. elegans. Finally, we demonstrate how to construct simple models from the built-in network motif library. © 2020 by John Wiley & Sons, Inc. Basic Protocol 1: Modeling the signaling network of Dictyostelium discoidum. Basic Protocol 2: Modeling the germline progression of Caenorhabditis elegans. Basic Protocol 3: Constructing a model of the cell cycle using motifs. © 2020 John Wiley & Sons, Inc.},
author_keywords={cell signaling;  executable models;  formal verification;  systems biology},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kenny2020,
author={Kenny, A. and Gordon, N. and Downey, J. and Eddins, O. and Buchholz, K. and Menyon, A. and Mansah, W.},
title={Design and implementation of a mobile health electronic data capture platform that functions in fully-disconnected settings: A pilot study in rural Liberia},
journal={BMC Medical Informatics and Decision Making},
year={2020},
volume={20},
number={1},
doi={10.1186/s12911-020-1059-6},
art_number={39},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079797316&doi=10.1186%2fs12911-020-1059-6&partnerID=40&md5=3a7026645c834b1ffec5c32a60b88ee8},
affiliation={Department of Biostatistics, University of Washington, 1705 NE Pacific Street F-600, Seattle, WA  98195, United States; Last Mile Health, 205 Portland St #200, Boston, MA  02114, United States; Liberia Ministry of Health, Tubman Blvd, Congo Town, Monrovia, Liberia},
abstract={Background: Mobile phones and personal digital assistants have been used for data collection in developing world settings for over three decades, and have become increasingly common. However, the use of electronic data capture (EDC) through mobile phones is limited in many areas by inconsistent network connectivity and poor access to electricity, which thwart data transmission and device usage. This is the case in rural Liberia, where many health workers live and work in areas without any access to cellular connectivity or reliable power. Many existing EDC mobile software tools are built for occasionally-disconnected settings, allowing a user to collect data while out of range of a cell tower and transmit data to a central server when he/she regains a network connection. However, few tools exist that can be used indefinitely in fully-disconnected settings, where a user will never have access to the internet or a cell network. This led us to create and implement an EDC software tool that allows for completely offline data transfer and application updating. Results: We designed, pilot-Tested, and scaled an open-source fork of Open Data Kit Collect (an Android application that can be used to create EDC systems) that allows for offline Bluetooth-based bidirectional data transfer, enabling a system in which permanently-offline users can collect data and receive application updates. We implemented this platform among a cohort of 317 community health workers and 28 supervisors in a remote area of rural Liberia with incomplete cellular connectivity and low access to power sources. Conclusions: Running a fully-offline EDC program that completely bypasses the cellular network was found to be feasible; the system is still running, over 4 years after the initial pilot program. The users of this program can theoretically collect data offline for months or years, assuming they receive hardware support when needed. Fully-offline EDC has applications in settings where cellular network coverage is poor, as well as in disaster relief settings in which portions of the communications infrastructure may be temporarily nonfunctional. © 2020 The Author(s).},
author_keywords={Community health worker;  Data collection;  Digital health;  Disconnected;  EDC;  eHealth;  Electronic data capture;  mHealth;  Mobile health;  Offline},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Golzadeh2020,
author={Golzadeh, M. and Decan, A. and Mens, T.},
title={Evaluating a bot detection model on git commit messages},
journal={CEUR Workshop Proceedings},
year={2020},
volume={2912},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111375654&partnerID=40&md5=2f0e8960d7ed949aa2008a81256a7594},
affiliation={Software Engineering Lab, University of Mons, Belgium},
abstract={Detecting the presence of bots in distributed software development activity is very important in order to prevent bias in large-scale socio-technical empirical analyses. In previous work, we proposed a classification model to detect bots in GitHub repositories based on the pull request and issue comments of GitHub accounts. The current study generalises the approach to git contributors based on their commit messages. We train and evaluate the classification model on a large dataset of 6,922 git contributors. The original model based on pull request and issue comments obtained a precision of 0.77 on this dataset. Retraining the classification model on git commit messages increased the precision to 0.80. As a proof-of-concept, we implemented this model in BoDeGiC, an open source command-line tool to detect bots in git repositories. Copyright 2020 for this paper by its authors.},
author_keywords={Bot detection;  Classification model;  Distributed software development;  Empirical analysis},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2020,
title={BENEVOL 2020 - Proceedings of the 19th Belgium-Netherlands Software Evolution Workshop},
journal={CEUR Workshop Proceedings},
year={2020},
volume={2912},
page_count={35},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111361767&partnerID=40&md5=a6f5f9b54fc58d97d9e2f1ad1df62ad9},
abstract={The proceedings contain 7 papers. The topics discussed include: an empirical investigation of forks as variants in npm; an empirical study of technical debt management as a motivation for forking; SearchSECO: a worldwide index of the open source software ecosystem; extracting software modules as communities; evaluating a bot detection model on git commit messages; moldable requirements; and crash reproduction difficulty, an initial assessment.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{McAleer2020,
author={McAleer, S. and Lanier, J. and Fox, R. and Baldi, P.},
title={Pipeline PSRO: A scalable approach for finding approximate nash equilibria in large games},
journal={Advances in Neural Information Processing Systems},
year={2020},
volume={2020-December},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108398403&partnerID=40&md5=6b8712c99c7810d0df370fc8db3d120e},
affiliation={Department of Computer Science, University of California, Irvine, Irvine, CA, United States},
abstract={Finding approximate Nash equilibria in zero-sum imperfect-information games is challenging when the number of information states is large. Policy Space Response Oracles (PSRO) is a deep reinforcement learning algorithm grounded in game theory that is guaranteed to converge to an approximate Nash equilibrium. However, PSRO requires training a reinforcement learning policy at each iteration, making it too slow for large games. We show through counterexamples and experiments that DCH and Rectified PSRO, two existing approaches to scaling up PSRO, fail to converge even in small games. We introduce Pipeline PSRO (P2SRO), the first scalable PSRO-based method for finding approximate Nash equilibria in large zero-sum imperfect-information games. P2SRO is able to parallelize PSRO with convergence guarantees by maintaining a hierarchical pipeline of reinforcement learning workers, each training against the policies generated by lower levels in the hierarchy. We show that unlike existing methods, P2SRO converges to an approximate Nash equilibrium, and does so faster as the number of parallel workers increases, across a variety of imperfect information games. We also introduce an open-source environment for Barrage Stratego, a variant of Stratego with an approximate game tree complexity of 1050. P2SRO is able to achieve state-of-the-art performance on Barrage Stratego and beats all existing bots. Experiment code is available at https://github.com/JBLanier/pipeline-psro. © 2020 Neural information processing systems foundation. All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Storch2020,
author={Storch, M. and Haines, M.C. and Baldwin, G.S.},
title={DNA-BOT: A low-cost, automated DNA assembly platform for synthetic biology},
journal={Synthetic Biology},
year={2020},
volume={5},
number={1},
doi={10.1093/SYNBIO/YSAA010},
art_number={ysaa010},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101156819&doi=10.1093%2fSYNBIO%2fYSAA010&partnerID=40&md5=8fea9385cf58c9668c97aaef8dc21a44},
affiliation={Department of Life Sciences, Imperial College London, London, SW7 2AZ, United Kingdom; Imperial College Centre for Synthetic Biology, Imperial College London, London, SW7 2AZ, United Kingdom; London Biofoundry, Imperial College Translation and Innovation Hub, London, W12 0BZ, United Kingdom},
abstract={Multi-part DNA assembly is the physical starting point for many projects in Synthetic and Molecular Biology. The ability to explore a genetic design space by building extensive libraries of DNA constructs is essential for creating programmed biological systems. With multiple DNA assembly methods and standards adopted in the Synthetic Biology community, automation of the DNA assembly process is now receiving serious attention. Automation will enable larger builds using less researcher time, while increasing the accessible design space. However, these benefits currently incur high costs for both equipment and consumables. Here, we address this limitation by introducing low-cost DNA assembly with BASIC on OpenTrons (DNA-BOT). For this purpose, we developed an open-source software package and demonstrated the performance of DNA-BOT by simultaneously assembling 88 constructs composed of 10 genetic parts, evaluating the promoter, ribosome binding site and gene order design space for a three-gene operon. All 88 constructs were assembled with high accuracy, at a consumables cost of $1.50-$5.50 per construct. This illustrates the efficiency, accuracy and affordability of DNA-BOT, making it accessible for most labs and democratizing automated DNA assembly. © The Author(s) 2020. Published by Oxford University Press.},
author_keywords={Automation;  Biofoundry;  DNA assembly;  Synthetic biology},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Gilson202053,
author={Gilson, F. and Annand, S. and Steel, J.},
title={Recording software design decisions on the fly},
journal={CEUR Workshop Proceedings},
year={2020},
volume={2799},
pages={53-66},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099359984&partnerID=40&md5=3af7471b97c9d1997b202fb98b19bb50},
affiliation={University of Canterbury, Private Bag 4800, Christchurch, 8140, New Zealand},
abstract={A common trend in the software engineering field shows developers are not documenting their design decisions as much as they believe they should be. Part of the reason for this is that developers consider the design decision documentation process to be cumbersome. However documentation of design decisions proves to be a crucial aspect of software maintenance and enhance teams' shared understanding of a product. With the recent emergence of instant messaging in software teams (e.g., Slack, Microsoft Teams), our goal is to leverage their platform coupled to chat bots and natural language processing technologies to record design decisions as they arise. In doing so we place the system for recording design decisions into an environment that is already common place for software teams, dramatically reducing the barriers involved with recording design decisions as a separate task. We therefore propose a general framework composed of a chatbot, a natural language processing engine and exporting API to wikis to record and search design decisions enabling teams to focus on their day-to-day work with minimal disruptions in their workflow, but still keeping a project documentation up to date. © 2020 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
author_keywords={Agile software development;  Architecture knowledge;  Chatbot;  Design decisions;  Documentation;  Instant messaging;  Natural language processing},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Udayakumar20201017,
author={Udayakumar, T. and Saranu, K. and Oak, M.S. and Saunshikar, A.A. and Bapat, S.S.},
title={Rapid enhancement of nlp systems by acquisition of data in correlated domains},
journal={Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
year={2020},
volume={2020-October},
pages={1017-1018},
doi={10.21437/Interspeech.2020-4008},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098124226&doi=10.21437%2fInterspeech.2020-4008&partnerID=40&md5=a65884727ea89125a88f67734e1093c1},
affiliation={Samsung Research and Development Institute, Bangalore, India},
abstract={In a generation where industries are going through a paradigm shift because of the rampant growth of deep learning, structured data plays a crucial role in the automation of various tasks. Textual structured data is one such kind which is extensively used in systems like chat bots and automatic speech recognition. Unfortunately, a majority of these textual data available is unstructured in the form of user reviews and feedback, social media posts etc. Automating the task of categorizing or clustering these data into meaningful domains will reduce the time and effort needed in building sophisticated human-interactive systems. In this paper, we present a web tool that builds a domain specific data based on a search phrase from a database of highly unstructured user utterances. We also show the usage of Elasticsearch database with custom indexes for full correlated text-search. This tool uses the open sourced Glove model combined with cosine similarity and performs a graph based search to provide semantically and syntactically meaningful corpora. In the end, we discuss its applications with respect to natural language processing. Copyright © 2020 ISCA},
author_keywords={Automation;  Elasticsearch;  Glove Model;  Speech Recognition},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Neves20206035,
author={Neves, C. and Coheur, L. and Nicolau, H.},
title={HamNoSyS2SiGML: Translating HamNoSys into SiGML},
journal={LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings},
year={2020},
pages={6035-6039},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096578252&partnerID=40&md5=46fbcb9787eb0d8ccd0dab9d0530e098},
affiliation={Instituto Superior Técnico, Universidade de Lisboa, INESC-ID Lisboa, Portugal},
abstract={Sign Languages are visual languages and the primary means of communication used by Deaf people. However, the majority of the information available online is presented through written form. Hence, it is not of easy access to the Deaf community. Avatars have gained an increase of interest due to their potential in automatically generating signs from text. Synthetic animation of conversational agents can be achieved through the use of notation systems. HamNoSys is one of these systems, which describes movements of the body through symbols. SiGML is an XML-compliant machine-readable format that enables avatars to animate HamNoSys symbols. However, there are no freely available open-source libraries that allow the conversion from HamNoSys to SiGML. In this paper, we present our open-source and cross-platform tool that performs such conversion. This system represents a crucial intermediate step in the broader pipeline of animating signing avatars. Finally, we describe two cases studies to illustrate different applications of our tool. © European Language Resources Association (ELRA), licensed under CC-BY-NC},
author_keywords={HamNoSys;  SiGML;  Signing avatar;  Translation},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Parmelee12020388,
author={Parmelee1, M.C.},
title={Adventures in the art of enterprise artificial intelligence transformation},
journal={CEUR Workshop Proceedings},
year={2020},
volume={2721},
pages={388-389},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096207442&partnerID=40&md5=69d35e35d1bdd7d0de3fbd93887d3da0},
affiliation={MITRE Corporation, Bedford, MA  01730, United States},
abstract={Organizations are looking for ways to implement Artificial Intelligence (AI) in a scalable, sustainable, cost-effective way without retooling. The MITRE Embedded Intelligence Framework represents our experience and lessons learned from a three-year, enterprise AI adventure. It provides a tested, end-to-end approach to implementing a semantic transformation ecosystem that infuses AI into enterprise systems without disrupting current processes, or practices. We will demonstrate how we combine commercial AI cloud services with best of breed open source tools and Semantic Web technologies to manage the AI lifecycle, share AI artifacts and deliver AI services that can converse with us in natural language, interpret our needs, and provide quick answers our questions. Examples include AI-driven search, a publication recommender, an intelligent chatbot, and a voice-enabled virtual assistant with robotic process automation. © 2020 CEUR-WS. All rights reserved.},
author_keywords={Enterprise AI;  Knowledge Graphs;  Machine Learning;  NLP;  RDF;  RDFS;  SHACL;  SKOS},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Daswani202044,
author={Daswani, M. and Desai, K. and Patel, M. and Vani, R. and Eirinaki, M.},
title={CollegeBot: A Conversational AI Approach to Help Students Navigate College},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12424 LNCS},
pages={44-63},
doi={10.1007/978-3-030-60117-1_4},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094159735&doi=10.1007%2f978-3-030-60117-1_4&partnerID=40&md5=3db9ee151a357b57d05182dcede68358},
affiliation={Computer Engineering Department, San Jose State University, San Jose, CA  95192, United States},
abstract={In an organization as big as a university that has many distinct departments and administrative bodies, it becomes almost impossible to easily obtain information online or by other means. Assistance over the phone or in-person is often limited to office hours and the information online is scattered through numerous (often nested) web pages, often independently administered and maintained by each sub-division. In this work, we present CollegeBot, a conversational AI agent that uses natural language processing and machine learning to assist visitors of a university’s web site in easily locating information related to their queries. We discuss how we create the knowledge base by collecting and appropriately preprocessing information that is used to train the conversational agent for answering domain-specific questions. We have evaluated two different algorithms for training the conversational model for the chatbot, namely a semantic similarity model and a deep learning one leveraging Sequence-to-Sequence learning model. The proposed system is able to capture the user’s intent and switch context appropriately. It also leverages the open source AIML chatbot ALICE to answer any generic (non domain-specific) questions. We present a proof-of-concept prototype for San Jose State University, to demonstrate how such an approach can be easily adopted by other academic institutions as well. © 2020, Springer Nature Switzerland AG.},
author_keywords={AIML;  Chatbot;  Conversational AI;  Deep learning;  Natural language processing;  Semantic sentence similarity;  Sequence-to-Sequence},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Heras20202023,
author={Heras, S.C.D.L. and Jones, M.N. and Gernaey, K.V. and Kruhne, U. and Mansouri, S.S.},
title={An E-learning Bot for Bioprocess Systems Engineering},
journal={Computer Aided Chemical Engineering},
year={2020},
volume={48},
pages={2023-2028},
doi={10.1016/B978-0-12-823377-1.50338-4},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092933058&doi=10.1016%2fB978-0-12-823377-1.50338-4&partnerID=40&md5=d1d519920e261a9d995677cec688c06d},
affiliation={Process and Systems Eng. Centre (PROSYS), Dept. of Chemical and Biochemical Eng., Technical University of Denmark, Søltofts Plads, Lyngby, Kgs  2800, Denmark},
abstract={Receiving an engineering education is not a smooth path and in the last years, several digital platforms have been developed with the aim to help the students in the field. Nonetheless, the initial efforts to use digital platforms have not yet been successful, partly due to the lack of support to the teachers, the lack of motivation strategies inside the platforms or the loss of the social interaction, which is key in a collaborative learning process. Collaborative learning integrates the interaction between the students and the teacher, or in the case of digital learning, with an educational software. However, it is difficult to provide such a frame of interaction between learners inside an educational software. Therefore, a chatbot is proposed with its own design and architecture which behaves like a “friend” or colleague in the education, here applied to bioprocesses. Along with the chatbot architecture, it is explained how it is integrated in the learning design through its database. This tailored database contains training example dialogs through questions raised by students from a course on Bioprocess Technology, while it also collects their common mistakes, etc. Moreover, this database contains a novel system of twin databases; one with correct information and another with small errors. Using this system, the chatbot provides a more accurate representation of a learner's peer and triggers critical thinking. Finally, the chatbot architecture is embedded inside a prototype open-source Educational Virtual Bioprocess Plant developed by the Department of Chemical and Biochemical Engineering of the Technical University of Denmark, called FermProc. © 2020 Elsevier B.V.},
author_keywords={Bioprocess;  Chatbot;  Knowledge transfer;  Process System Education},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Leoni2020504,
author={Leoni, C. and Torre, I. and Vercelli, G.},
title={Conversiamo: Improving italian question answering exploiting ibm watson services},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12284 LNAI},
pages={504-512},
doi={10.1007/978-3-030-58323-1_54},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091185902&doi=10.1007%2f978-3-030-58323-1_54&partnerID=40&md5=21f8e73eff2bbb69819ee260a185954d},
affiliation={DIBRIS, University of Genoa, Viale F. Causa 13, Genoa, 16145, Italy},
abstract={Chatbots, conversational interfaces and NLP have achieved considerable improvements and are spreading more and more in everyday applications. Solutions on the market allow their implementation easily in different languages, but the proposals for the Italian language are not so effective as the English ones. This paper introduces ConversIAmo, the prototype of a conversational agent which implements a question answering system in Italian on a closed domain concerning artificial intelligence, taking the answers from online articles. This system integrates IBM services (Watson Assistant, Discovery and Natural Language Understanding) with functions developed within ConversIAmo and Tint, an open-source tool for the analysis of the Italian language. Our QA pipeline turned out to give better results than those obtained from using Watson Discovery service on its own, as for precision, F1-score and correct answer ranking (on average +12%, +21% and +20% respectively). Our main contribution is to address the need for an effective but easy-to-apply method aimed to improve performances of IBM Watson services for the Italian language. In addition, the AI domain is a new one for an Italian conversational agent. © Springer Nature Switzerland AG 2020.},
author_keywords={Artificial intelligence;  Conversational agents;  IBM Watson;  Italian language;  Question answering},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2020,
title={17th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, DIMVA 2020},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12223 LNCS},
page_count={279},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088521704&partnerID=40&md5=cfc9160d7eb9b578f1570f356ac5e582},
abstract={The proceedings contain 13 papers. The special focus in this conference is on Detection of Intrusions and Malware, and Vulnerability Assessment. The topics include: Distributed Heterogeneous N-Variant Execution; sec2graph: Network Attack Detection Based on Novelty Detection on Graph Structured Data; Efficient Context-Sensitive CFI Enforcement Through a Hardware Monitor; backstabber’s Knife Collection: A Review of Open Source Software Supply Chain Attacks; putting Attacks in Context: A Building Automation Testbed for Impact Assessment from the Victim’s Perspective; fast and Furious: Outrunning Windows Kernel Notification Routines from User-Mode; HAEPG: An Automatic Multi-hop Exploitation Generation Framework; Understanding Android VoIP Security: A System-Level Vulnerability Assessment; web Runner 2049: Evaluating Third-Party Anti-bot Services; short Paper - Taming the Shape Shifter: Detecting Anti-fingerprinting Browsers; it Never Rains but It Pours: Analyzing and Detecting Fake Removal Information Advertisement Sites.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Al-Kasassbeh2020421,
author={Al-Kasassbeh, M. and Almseidin, M. and Alrfou, K. and Kovacs, S.},
title={Detection of IoT-botnet attacks using fuzzy rule interpolation},
journal={Journal of Intelligent and Fuzzy Systems},
year={2020},
volume={39},
number={1},
pages={421-431},
doi={10.3233/JIFS-191432},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087412635&doi=10.3233%2fJIFS-191432&partnerID=40&md5=0c87494ea2a0fa8159913e84174a5db3},
affiliation={Department of Computer Science, Princess Sumaya University for Technology, Amman, Jordan; Department of Information Technology, University of Miskolc, Miskolc, Hungary; Department of Computer Science, University of Wisconsin-Milwaukee, Milwaukee, United States},
abstract={Recently, the Internet of Things (IoT) has been used in technology for different aspects to increase the efficiency and comfort of human life. Protecting the IoT infrastructure is not a straightforward task. There is an urgent need to handle different attack scenarios within the IoT smart environment. Attackers continuously targeted the modern aspects of technology, and trying abusing these technologies using complex attack scenarios such as Botnet attacks. Botnet attacks considered a serious challenge faces of the IoT smart environment. In this paper, we introduce a novel idea that capable of supporting the detecting of IoT-Botnet attack and in meanwhile to avoid the issues associated with the deficiencies of the knowledge-based representation and the binary decision. This paper aims to introduce a detection approach for the IoT-BotNet attack by using the Fuzzy Rule Interpolation (FRI). The FRI reasoning methods added a benefit to enhance the robustness of fuzzy systems and effectively reduce the system's complexity. These benefits help the Intrusion Detection System (IDS) to generate more realistic and comprehensive alerts. The proposed approach was applied to an open-source BoT-IoT dataset from the Cyber Range Lab of the center of UNSW Canberra Cyber. The proposed approach was tested, evaluated and obtained a 95.4% detection rate. Moreover, it effectively smooth the boundary between normal and IoT-BotNet traffics because of its fuzzy-nature, as well as, it had the ability to generate the required IDS alert in case of the deficiencies of the knowledge-based representation. © 2020-IOS Press and the authors. All rights reserved.},
author_keywords={botnet attack;  fuzzy rule interpolation;  Internet of things;  intrusion detection system},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Dinan20204537,
author={Dinan, E. and Humeau, S. and Weston, J. and Chintagunta, B.},
title={Build it break it fix it for dialogue safety: Robustness from adversarial human attack},
journal={EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
year={2020},
pages={4537-4546},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084309314&partnerID=40&md5=925982a6c4af91be10d92658bb63f40f},
affiliation={Facebook AI Research; Virginia Tech, United States},
abstract={The detection of offensive language in the context of a dialogue has become an increasingly important application of natural language processing. The detection of trolls in public forums (Galán-García et al., 2016), and the deployment of chatbots in the public domain (Wolf et al., 2017) are two examples that show the necessity of guarding against adversarially offensive behavior on the part of humans. In this work, we develop a training scheme for a model to become robust to such human attacks by an iterative build it, break it, fix it strategy with humans and models in the loop. In detailed experiments we show this approach is considerably more robust than previous systems. Further, we show that offensive language used within a conversation critically depends on the dialogue context, and cannot be viewed as a single sentence offensive detection task as in most previous work. Our newly collected tasks and methods are all made open source and publicly available. © 2019 Association for Computational Linguistics},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Debnath2020160,
author={Debnath, S. and Spoletini, P.},
title={Designing a Virtual Client for Requirements Elicitation Interviews},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12045 LNCS},
pages={160-166},
doi={10.1007/978-3-030-44429-7_12},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083990480&doi=10.1007%2f978-3-030-44429-7_12&partnerID=40&md5=cd7633fd3caeb0db1c28e19c4bab941c},
affiliation={Kennesaw State University, Marietta, United States},
abstract={[Context and motivation] Role-playing offer experiential learning through the simulation of real-world scenarios; for this reason, it is widely used in software engineering education. In Requirements Engineering, role-playing is a popular way to provide students hands-on experience with requirements elicitation interviews. [Problem] However, managing a role-playing activity to simulate requirements elicitation interviews in a class is time consuming, as it often requires pairing students with student assistants or fellow classmates who act as either customers or requirement analysts as well as creating and maintaining the interview schedules between the actors. To make the adoption of role-playing activities in a class feasible, there is a need to develop a solution to reduce instructors’ workload. [Principal ideas] To solve this problem we propose the use of VIrtual CustOmer (VICO), an intent-based, multimodal, conversational agent. VICO offers an interview experience comparable to talking to a human and provides a transcript of the interview annotated with the mistakes students made in it. The adoption of VICO will eliminate the need to schedule interviews as the students can interact with it in their free time. Moreover, the transcript of the interview allows students to evaluate their performance to refine and improve their interviewing skills. [Contribution] In this research preview, we show the architecture of VICO and how it can be developed using existing technologies, we provide an online rule-based initial prototype and show the practicality and applicability of this tool through an exploratory study. © 2020, Springer Nature Switzerland AG.},
author_keywords={Intelligent agent;  Requirements elicitation interview;  Requirements engineering education and training;  Role-playing},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Shanthini2020552,
author={Shanthini, A. and Rao, C.P. and Vadivu, G.},
title={AI BOT: An Intelligent Personal Assistant},
journal={Lecture Notes on Data Engineering and Communications Technologies},
year={2020},
volume={31},
pages={552-559},
doi={10.1007/978-3-030-24643-3_66},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083666431&doi=10.1007%2f978-3-030-24643-3_66&partnerID=40&md5=b0c073e3ea4c405a184998941b1d45cf},
affiliation={SRM Institute of Science and Technology, Kattankulathur, Chennai, India},
abstract={Intelligent Personal Assistants (IPA) such as Google’s Assistant, Apple’s Siri and Microsoft’s Cortana excels in their natural language user interface. Still there is a need for single bundled IPA with multi-functionalities is increasing day by day. This paper presents the design and development of an artificial Intelligent personal assistant (AIPA), an open end-to-end web service application which receives queries in the form of voice and text and responds with natural language. The paper emphasizes on the implementation of different ways of interacting with a personal assistant and incorporating various functionalities which aren’t found in any of the existing virtual assistants with the help of several AI algorithms and open-source tools. Understanding context is important for any AI and increase in the context leads to the effective handling of open-ended requests. Unlike commercial products, this AI bot uses open ended requests than specific tasks to provide multifunctional to artificial brain. © Springer Nature Switzerland AG 2020.},
author_keywords={Artificial Intelligence;  Intelligent Personal Assistant;  Natural Language},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Shetty2020325,
author={Shetty, A. and Vashi, H. and Khambaty, A. and Dave, D. and Chitroda, J. and Khan, M. and Bhattacharjee, S.},
title={Wi-fi-Controlled Robotic Arm Using Arduino},
journal={Lecture Notes on Data Engineering and Communications Technologies},
year={2020},
volume={36},
pages={325-333},
doi={10.1007/978-981-15-1002-1_34},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083449943&doi=10.1007%2f978-981-15-1002-1_34&partnerID=40&md5=4e0105a627f2c7b7eba5a8419b5b4d97},
affiliation={Department of EXTC, SVKM’s DJSCE, UOM, Mumbai, India},
abstract={Robotics is one such field where work and research are done every day to make human life much more easy and efficient. In general, robots perform operations with an outside user, with a preexisting set of commands or a person controlling the bot. Robotics and specifically robotic arms are present in almost every field in this world. Robotics arm comes under the medical industry, defense sector, and also under the mechatronics field of engineering. This paper is an overview of how we can control a robotic arm using servomotors and interfacing it with an android app using a Wi-fi module. Arduino Uno is used to program the servos, and the android app is built using the MIT App Inventor which is open-source software. © 2020, Springer Nature Singapore Pte Ltd.},
author_keywords={3D printing;  Android;  Arduino;  Microcontroller;  Servomotor;  Wi-fi},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Assenmacher2020101,
author={Assenmacher, D. and Adam, L. and Frischlich, L. and Trautmann, H. and Grimme, C.},
title={Inside the tool set of automation: Free social bot code revisited},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12021 LNCS},
pages={101-114},
doi={10.1007/978-3-030-39627-5_9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080965525&doi=10.1007%2f978-3-030-39627-5_9&partnerID=40&md5=f0a1706afd8407c5d924f1089aef4f5b},
affiliation={Department of Information Systems, University of Münster, Leonardo-Campus 3, Münster, 48149, Germany; Department of Communication, University of Münster, Bispinghof 9-14, Münster, 48149, Germany},
abstract={Social bots have recently gained attention in the context of public opinion manipulation on social media platforms. While a lot of research effort has been put into the classification and detection of such automated programs, it is still unclear how technically sophisticated those bots are, which platforms they target, and where they originate from. To answer these questions, we gathered repository data from open source collaboration platforms to identify the status-quo of social bot development as well as first insights into the overall skills of publicly available bot code. © Springer Nature Switzerland AG 2020.},
author_keywords={Code sharing;  Data analysis;  Implementation;  Social bots},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Baena-Perez2020216,
author={Baena-Perez, R. and Ruiz-Rube, I. and Dodero, J.M. and Bolivar, M.A.},
title={A framework to create conversational agents for the development of video games by end-users},
journal={Communications in Computer and Information Science},
year={2020},
volume={1173 CCIS},
pages={216-226},
doi={10.1007/978-3-030-41913-4_18},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080903984&doi=10.1007%2f978-3-030-41913-4_18&partnerID=40&md5=ac7e3128a5fccae30c4409430f544b32},
affiliation={University of Cadiz, Cádiz, Spain},
abstract={Video game development is still a difficult task today, requiring strong programming skills and knowledge of multiple technologies. To tackle this problem, some visual tools such as Unity or Unreal have appeared. These tools are effective and easy to use, but they are not entirely aimed at end-users with little knowledge of software engineering. Currently, there is a resurgence in the use of chatbots thanks to the recent advances in fields such as artificial intelligence or language processing. However, there is no evidence about the use of conversational agents for developing video games with domain-specific languages (DSLs). This work states the following two hypotheses: (i) Conversational agents based on natural language can be used to work with DSL for the creation of video games; (ii) these conversational agents can be automatically created by extracting the concepts, properties and relationships from their abstract syntax. To demonstrate the hypotheses, we propose and detail the implementation of a framework to work with DSLs through a chatbot, its implementation details and a systematic method to automate its construction. This approach could be also suitable for other disciplines, in addition to video games development. © Springer Nature Switzerland AG 2020.},
author_keywords={Chatbots;  Conversational agents;  Domain Specific Languages;  End-User Development;  Model-Driven Engineering;  Video games},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Philip2020103,
author={Philip, S.K. and Poonawala, H. and Anita, R.},
title={Open world chatbot using neural networks in green cloud environment},
journal={Journal of Green Engineering},
year={2020},
volume={10},
number={1},
pages={103-117},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079865282&partnerID=40&md5=4239e6884ea99d70f6f932d842827772},
affiliation={Department of Computer Science and Engineering, SRM Institute of Science and Technology, KattankulathurTamil Nadu, India},
abstract={In present day, Conversational Modelling is one of the foremost fields in Natural Language Processing. This can be attributed to the availability of better hardware and competent software. The processing capacity available has grown exponentially in the last decade. This has contributed to the creation of better chatbots through the years. More effort is required to build a model of this kind. The lack of open source chatbots that can be readily incorporated into specific fields is a concern. Parallel technologies have open-source alternatives for various possibilities. It is important for the field to have similar resources. So, that future effort can be directed towards better performance and mechanisms. We focused on creating a chatbot using a combination of rule-based approaches and neural networks in Green cloud. This helped us to create a chatbot that can also improve with time. It helped to reduce latencies involved in standard approaches, and also helps in quick classification of queries. This work also analysed the possibility of creating open-domain response generators of open-world nature. A successful model of this kind will help in further development of chatbots with specialized features and better responses. © 2020 the Author(s). All rights reserved.},
author_keywords={Chatbot;  Context;  Human;  Natural Language Processing;  Neural Networks;  Seq2seq},
document_type={Article},
source={Scopus},
}

@ARTICLE{Daniel202015332,
author={Daniel, G. and Cabot, J. and Deruelle, L. and Derras, M.},
title={Xatkit: a Multimodal Low-Code Chatbot Development Framework},
journal={IEEE Access},
year={2020},
volume={8},
pages={15332-15346},
doi={10.1109/aCCESS.2020.2966919},
art_number={8960373},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079821080&doi=10.1109%2faCCESS.2020.2966919&partnerID=40&md5=1a4ce3195f2d538c8b4ff9149d85b2ef},
affiliation={IN3, UOC, Castelldefels, 08060, Spain; FICREa, Barcelona, 08010, Spain; Berger-Levrault, Champigneulles, 54250, France},
abstract={Chatbot (and voicebot) applications are increasingly adopted in various domains such as e-commerce or customer services as a direct communication channel between companies and end-users. Multiple frameworks have been developed to ease their definition and deployment. While these frameworks are efficient to design simple chatbot applications, they still require advanced technical knowledge to define complex interactions and are difficult to evolve along with the company needs (e.g. it is typically impossible to change the NL engine provider). In addition, the deployment of a chatbot application usually requires a deep understanding of the targeted platforms, especially back-end connections, increasing the development and maintenance costs. In this paper, we introduce the Xatkit framework. Xatkit tackles these issues by providing a set of Domain Specific Languages to define chatbots (and voicebots and bots in general) in a platform-independent way. Xatkit also comes with a runtime engine that automatically deploys the chatbot application and manages the defined conversation logic over the platforms of choice. Xatkit's modular architecture facilitates the separate evolution of any of its components. Xatkit is open source and fully available online. © 2013 IEEE.},
author_keywords={chatbot deployment;  chatbot design;  DSL;  Modeling},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gross202094,
author={Gross, J.H. and Townsend, M. and Hong, H.Y. and Miller, E. and Kallogjeri, D. and Zenga, J. and Pipkorn, P. and Jackson, R.S. and Haughey, B. and Rich, J.T.},
title={Predictors of swallow function after transoral surgery for locally advanced oropharyngeal cancer},
journal={Laryngoscope},
year={2020},
volume={130},
number={1},
pages={94-100},
doi={10.1002/lary.27856},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064081389&doi=10.1002%2flary.27856&partnerID=40&md5=2311ae2a9972f1666cbf09047e86d3fa},
affiliation={Department of Otolaryngology, Washington University School of Medicine, Saint Louis, MO, United States; University of Maryland Medical System, Baltimore, MD, United States; Medical College of Wisconsin, Milwaukee, WI, United States; University of Miami School of Medicine, Miami, FL, United States; Florida ENT Surgical Specialists, Celebration, FL, United States},
abstract={Objective: Transoral surgery (TOS) for oropharyngeal carcinoma (OPC) is steadily becoming more routine. Expected posttreatment swallow function is a critical consideration for preoperative counseling. The objective of this study was to identify predictors of swallow dysfunction following TOS for advanced tumor (T)-stage (T3-T4) OPC. Methods: A retrospective review from 1997 to 2016 at a single institution was performed. Eighty-two patients who underwent primary transoral resection of locally advanced OPCs with at least 1 year of postoperative follow-up were included. The primary outcome measure was swallow function, as measured by the Functional Outcomes Swallowing Scale (FOSS) at 1 year postoperatively. Operative reports were reviewed, and the extent of resection and type of reconstruction were documented. Conjunctive consolidation was then performed to incorporate multiple variables and their impact on swallow function into a clinically meaningful classification system. Results: Fifty-six patients (68%) had acceptable swallowing at 1 year. T4 tumor stage and receipt of adjuvant chemoradiation therapy (CRT) were strongly associated with poor swallowing but did not reach statistical significance. Only base of tongue (BOT) resection ≥50% (odds ratio [OR] 3.19, 95% confidence interval [CI] 1.21–8.43) and older age (OR 1.06, 95% CI 1.00–1.12) were significantly associated. Utilizing T-stage, adjuvant CRT, and BOT resection, a conjunctive consolidation was performed to develop a classification system for swallow dysfunction at 1 year. Conclusion: This study provides risk stratification for swallow function at 1 year following primary transoral resection of locally advanced OPCs. BOT resection ≥50%, especially when coupled with T4 tumor stage or adjuvant CRT, was associated with poor long-term swallow outcomes. Level of Evidence: 3 Laryngoscope, 130:94–100, 2020. © 2019 The American Laryngological, Rhinological and Otological Society, Inc.},
author_keywords={oropharynx cancer;  swallow function;  Transoral surgery},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Neumann201911,
author={Neumann, A.T. and De Lange, P. and Klamma, R.},
title={Collaborative creation and training of social bots in learning communities},
journal={Proceedings - 2019 IEEE 5th International Conference on Collaboration and Internet Computing, CIC 2019},
year={2019},
pages={11-19},
doi={10.1109/CIC48465.2019.00011},
art_number={8998476},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080858915&doi=10.1109%2fCIC48465.2019.00011&partnerID=40&md5=b0745d83ea9e30a639cd47e0308b26cb},
affiliation={Department of Computer Science 5, RWTH Aachen University, Aachen, Germany},
abstract={The interaction between instructors and students is one of the key concepts to improve the student's learning process. To personalize learning on a massive scale, social bots can be used as supporting technology. However, their development for virtual learning environments currently requires deep technical knowledge. This leaves learner communities relying on highly-skilled developers to generate and tailor these social bots. Participatory design, end-user development and model-driven principles bear the potential to close this technical gap. In this paper, we propose a model-driven approach for creating social bots. Using our framework, learners can create, train and utilize these for self-hosted virtual learning environments relying on OpenAPI specifications offered, e.g. by Blackboard. We support both retrieval-based bots that react to certain events in predefined ways, as well as generative bots by utilizing open source deep learning technologies. Our first evaluation shows the usefulness of model-driven generation and utilization of social bots. We see the potential of this approach to move the development closer to the actual learner. © 2019 IEEE.},
author_keywords={Deep learning;  End user integration;  Model driven development;  Social bots;  Virtual learning environments},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Brewer2019,
author={Brewer, P. and Ratan, A.},
title={Data and replication supplement for double auction markets with snipers},
journal={Data in Brief},
year={2019},
volume={27},
doi={10.1016/j.dib.2019.104729},
art_number={104729},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074521792&doi=10.1016%2fj.dib.2019.104729&partnerID=40&md5=f78f74727f8777d8262dd749f5994cab},
affiliation={Economic and Financial Technology Consulting LLC, United States; Department of Economics, Monash Business School, Monash University, Australia},
abstract={We provide a dataset for our research article “Profitability, Efficiency and Inequality in Double Auction Markets with Snipers” [1]. This dataset [2] includes configuration files, raw output data, and replications of calculated metrics for our robot-populated market simulations. The raw data is subdivided into a hierarchy of folders corresponding to simulation treatment variables, in a 2 × 2 × 21 design for 84 treatments in total. Treatments variables include: (i) robot population ordering, either “primary” or “reverse”; (ii) two market schedules of agent's values and costs: equal-expected-profit “market 1” and unequal-expected-profit “market 2”; (iii) 21 robot populations identified by the number of Sniper Bots (0–20) on each side of the market. Each treatment directory contains a simulator input file and outputs for 10,000 periods of market data. The outputs include all acceptable buy and sell orders, all trades, profits for each agent, and market metrics such as efficiency-of-allocation, Gini coefficient, and price statistics. An additional public copy in Google Cloud is available for database query by users of Google BigQuery. The market simulator software is a private product created by Paul Brewer at Economic and Financial Technology Consulting LLC. Free open source modules are available for tech-savvy users at GitHub, NPM, and Docker Hub repositories and are sufficient to repeat the simulations. An easier-to-use paid market simulation product will eventually be available online from Econ1.Net. We provide instructions for repeating individual simulations using the free open source simulator and the free container tool Docker. © 2019 The Author(s)},
author_keywords={Competitive equilibrium;  Double auction;  Efficiency;  Inequality;  Markets;  Numerical experiments;  Simulations},
document_type={Data Paper},
source={Scopus},
}

@ARTICLE{Rasmussen2019,
author={Rasmussen, M.H. and Lefrançois, M. and Pauwels, P. and Hviid, C.A. and Karlshøj, J.},
title={Managing interrelated project information in AEC Knowledge Graphs},
journal={Automation in Construction},
year={2019},
volume={108},
doi={10.1016/j.autcon.2019.102956},
art_number={102956},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074170098&doi=10.1016%2fj.autcon.2019.102956&partnerID=40&md5=5fd51748651bc3f6e200ffc11c2dcb8b},
affiliation={Technical University of Denmark, Department of Civil Engineering, Denmark; Mines Saint-Étienne, Univ Lyon, Univ Jean Monnet, IOGS, CNRS, UMR 5516, LHC, Institut Henri Fayol, Saint-Étienne, F-42023, France; Eindhoven University of Technology, Department of the Built Environment, Netherlands},
abstract={In the architecture, engineering and construction (AEC) industry stakeholders from different companies and backgrounds collaborate in realising a common goal being some physical structure. The exact goal is typically not known from the beginning, and throughout all design stages, new decisions are made - similarly to other design industries [1]. As a result, the design must adapt and subsequent consequences follow. With working methods being predominantly document-centric, highly interrelated and rapidly changing design data in a complex network of decisions, requirements and product specifications is primarily captured in static documents. In this paper, we consider a purely data-driven approach based on semantic web technologies and an earlier proposed Ontology for Property Management (OPM). The main contribution of this work consists of extensions for OPM to account for new competency questions including the description of property reliability and the reasoning logic behind derived properties. The secondary contribution is the specification of a homogeneous way to generate parametric queries for managing an OPM-compliant AEC Knowledge Graph (AEC-KG). A software library for operating an OPM-compliant AEC-KG is further presented in the form of an OPM Query Generator (OPM-QG). The library generates SPARQL 1.1 queries to query and manipulate construction project Knowledge Graphs represented using OPM. The OPM ontology aligns with latest developments in the W3C Community Group on Linked Building Data and suggests an approach to working with design data in a distributed environment using separate graphs for explicit facts and for materialised, deduced data. Finally, we evaluate the suggested approach using an open-source software artefact developed using OPM and OPM-QG, demonstrated online with an actual building Knowledge Graph. The particular design task evaluated is performing heat loss calculations for spaces of a future building using an AEC-KG described using domain- and project specific extensions of the Building Topology Ontology (BOT) in combination with OPM. With this work, we demonstrate how a typical engineering task can be accomplished and managed in an evolving design environment, thereby providing the engineers with insights to support decision making as changes occur. The application uses a strict division between the client viewer and the actual data model holding design logic, and can easily be extended to support other design tasks. © 2019 Elsevier B.V.},
author_keywords={AEC Knowledge Graph;  BIM;  Building information modelling;  Complex design;  Inference;  Information exchange;  Linked building data;  Linked data;  Ontology},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Povinsky2019101,
author={Povinsky, M. and Melichercik, M. and Siladi, V.},
title={A Chatbot based on Deep Neural Network and Public Cloud Services with TJBot Interface},
journal={INFORMATICS 2019 - IEEE 15th International Scientific Conference on Informatics, Proceedings},
year={2019},
pages={101-106},
doi={10.1109/Informatics47936.2019.9119304},
art_number={9119304},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087638546&doi=10.1109%2fInformatics47936.2019.9119304&partnerID=40&md5=3a3c68ffec1d4d30fd7451a34b0b6277},
affiliation={Matej Bel University, Faculty of Natural Sciences, Banská Bystrica, Slovakia},
abstract={This paper describes an adaptation of the IBM TJBot as a chatbot interface. TJBot is an open source project designed to use artificial intelligence services in user friendly way. Primary it has been developed to be used with IBM Watson services. The adaptation has been done in three steps. In the first step deep neural network (DNN) based chat has been designed. Subsequently, three DNN where designed to perform experiments. They differed in training sets. The second step presents a join of DNN based chat with IBM Watson services (Speech-To-Text, Text-To-Speach). Originally, IBM Watson provides these services for limited number of languages. Slovak language is not included, too. Google cloud services fill this gap quite in good manner. This led to replacement of the IBM Watson services by the Google services. Finally, the chatbot is able to communicate in multiple languages, Slovak language including. Any non-English conversation has to be translated to English language and vice-versa by the Google translate service. This modified chatbot was tested by chat with randomly selected users. © 2019 IEEE.},
author_keywords={Chatbot;  cloud services;  deep learning;  deep neural network;  Raspberry Pi;  TJBot},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Alizadeh2019823,
author={Alizadeh, V. and Ouali, M.A. and Kessentini, M. and Chater, M.},
title={RefBot: Intelligent software refactoring bot},
journal={Proceedings - 2019 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019},
year={2019},
pages={823-834},
doi={10.1109/ASE.2019.00081},
art_number={8952287},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078915242&doi=10.1109%2fASE.2019.00081&partnerID=40&md5=71f3d519f05eda82f8ed2c59573c3c43},
affiliation={Software Engineering Intelligence Lab, CIS Department, University of Michigan, United States},
abstract={The adoption of refactoring techniques for continuous integration received much less attention from the research community comparing to root-canal refactoring to fix the quality issues in the whole system. Several recent empirical studies show that developers, in practice, are applying refactoring incrementally when they are fixing bugs or adding new features. There is an urgent need for refactoring tools that can support continuous integration and some recent development processes such as DevOps that are based on rapid releases. Furthermore, several studies show that manual refactoring is expensive and existing automated refactoring tools are challenging to configure and integrate into the development pipelines with significant disruption cost. In this paper, we propose, for the first time, an intelligent software refactoring bot, called RefBot. Integrated into the version control system (e.g. GitHub), our bot continuously monitors the software repository, and it is triggered by any 'open' or 'merge' action on pull requests. The bot analyzes the files changed during that pull request to identify refactoring opportunities using a set of quality attributes then it will find the best sequence of refactorings to fix the quality issues if any. The bot recommends all these refactorings through an automatically generated pull-request. The developer can review the recommendations and their impacts in a detailed report and select the code changes that he wants to keep or ignore. After this review, the developer can close and approve the merge of the bot's pull request. We quantitatively and qualitatively evaluated the performance and effectiveness of RefBot by a survey conducted with experienced developers who used the bot on both open source and industry projects © 2019 IEEE.},
author_keywords={Refactoring;  Software bot;  Software quality},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Valliyammai201914461,
author={Valliyammai, C. and Devakunchari, R.},
title={Distributed and scalable Sybil identification based on nearest neighbour approximation using big data analysis techniques},
journal={Cluster Computing},
year={2019},
volume={22},
pages={14461-14476},
doi={10.1007/s10586-018-2314-9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043357318&doi=10.1007%2fs10586-018-2314-9&partnerID=40&md5=de112480821d480ae43d1a0103ff047c},
affiliation={Department of Computer Technology, Faculty of Information and Communication, MIT Campus, Anna University, Chennai, India},
abstract={The problem of Sybil detection has been examined in multiple social media sources like Twitter, LinkedIn and Facebook. The detection of Sybils (fake accounts or social bots) across online social networks emerged as a major challenge due to the current improvement of different social networks, which are promptly generating a very huge data sets termed as big data. The open-source framework, spark-based distributed, fast and scalable nearest neighbor search (S-DFS-NNS) is proposed for profile-based fake account detection across large-scale online social networks. The proposed work performs an efficient parallel processing of the NN search problem. The performance of the k-nearest neighbor (k-NN) search significantly degrades for huge data sets, because the job is computationally hard. The framework is fast and adaptable to expansive, large-scale situations. By using in-memory computation, the suspected users are identified based on the novel private feature. The Spark-DFS-NN search technique provides a substantial performance development over the nearest neighbor computation in large-scale networks. The proposed framework is evaluated using detection accuracy which is able to expose and block a large fraction of suspicious accounts during account creation. The proposed S-DFS-NN framework maintains an approximately consistent and similar performance of 89–95% on the increase of attacks with a latency of 58 ms. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
author_keywords={Big data;  In-memory;  Online social networks;  Resilient distributed dataset;  Sybil attack},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Pereira201959,
author={Pereira, J. and Barcina, M.A.},
title={A chatbot assistant for writing good quality technical reports},
journal={ACM International Conference Proceeding Series},
year={2019},
pages={59-64},
doi={10.1145/3362789.3362798},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075445421&doi=10.1145%2f3362789.3362798&partnerID=40&md5=9efd544fcf1d0d9f099a49bf3bfc3d09},
affiliation={Department of Computer Science, University of the Basque Country, Spain},
abstract={It is frequently the case for final degree projects (FDP) to represent the largest academic endeavor students have been involved with. The writing of the FDP technical report tends to be one of the hurdles. Due to their inexperience, students fail to meet quality standards in their writing efforts. Research shows that text and image plagiarism, poor literature searches and lack of synthesis are some of the most usual errors. Yet, these error-filled memories keep publishing in university-backed open repositories. This paper describes a solution to help both students and supervisors detecting basic quality errors in FDP reports. Based on a chatbot front-end called Ikastenbot, students can upload their reports while they are writing them and spot, before publication, possible errors in spelling and grammar, text and images reuse, and lack of proper referencing. We applied the techniques described on the memories of our university FDP repository. Results show that Ikastenbot is able to detect errors in almost every report. The source code of our solution has been published under an open-source license. © 2019 ACM.},
author_keywords={Chatbots;  FDP;  Final Degree Projects;  Technical Writing;  Writing improvement},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2019,
title={2019 National Information Technology Conference, NITC 2019},
journal={2019 National Information Technology Conference, NITC 2019},
year={2019},
page_count={109},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087214960&partnerID=40&md5=20156e1f2f663388b54573e07540d1c4},
abstract={The proceedings contain 18 papers. The topics discussed include: a Sinhala and Tamil extension to generic environment for context-aware correction; enhanced tokenizer for Sinhala language; real time deception detection for criminal investigation; UniOntBot: semantic natural language generation based API approach for chatbot communication; measuring software integration effort: identifying factors affecting integration of software systems; RSSI and feed forward neural network (FFNN) based indoor localization in WSN; cloud-based open source primary care electronic patient record system for Sri Lankan citizens; fraud detection solution for monetary transactions with autoencoders; and HateSense: tackling ambiguity in hate speech detection.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Hu2019,
author={Hu, Z. and Gehringer, E.F.},
title={Improving Feedback on GitHub Pull Requests: A Bots Approach},
journal={Proceedings - Frontiers in Education Conference, FIE},
year={2019},
volume={2019-October},
doi={10.1109/FIE43999.2019.9028685},
art_number={9028685},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082484601&doi=10.1109%2fFIE43999.2019.9028685&partnerID=40&md5=078aa4daaa0f14de1ab0d288b715bf39},
affiliation={North Carolina State University, Department of Computer Science, Raleigh, United States},
abstract={Rising enrollments make it difficult for instructors and teaching assistants to give adequate feedback on each student's work. Our course projects require students to submit GitHub pull requests as deliverables for their open-source software (OSS) projects. We have set up a static code analyzer and a continuous integration service on GitHub to help students check different aspects of the code. However, these tools have some limitations. In this paper, we discuss how we bypass the limitations of existing tools by implementing three Internet bots. These bots are either open source or free for OSS projects and can be easily integrated with any GitHub repositories. One-hundred one Computer Science and Computer Engineering masters students participated in our study. The survey results showed that more than 84% of students thought bots can help them to contribute code with better quality. We analyzed 396 pull requests. Results revealed that bots can provide more timely feedback than teaching staff. The Danger Bot is associated with a significant reduction system-specific guideline violations (by 39%), and the Code Climate Bot is associated with a significant 60% decrease of code smells in student contributions. However, we found that the Travis CI Bot did not help student contributions pass automated tests. © 2019 IEEE.},
author_keywords={automated feedback;  Expertiza;  Internet bots;  open-source curriculum;  open-source software;  software engineering},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2019,
title={BCI 2019 - Proceedings: 9th Balkan Conference on Informatics},
journal={ACM International Conference Proceeding Series},
year={2019},
page_count={222},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073333820&partnerID=40&md5=0b26e927868b5879ec411dd9f519bd53},
abstract={The proceedings contain 38 papers. The topics discussed include: statistical analysis in the research of human factor in software engineering; deep learning in brain computer interfaces; automatic identification of skills’ dependency; development of base ontology for a digital library of the Bulgarian museums’ collections; e-commerce distributed chatbot system; trends review of the contemporary security problems in the cyberspace; analysis of keystream produced by generalized shrinking multiplexing generator controlled by ternary m-sequence; applied computing for portfolio optimization in Bulgarian stock exchange; and a framework for predicting community behavior in evolving social networks.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Čertický2019227,
author={Čertický, M. and Churchill, D. and Kim, K.-J. and Čertický, M. and Kelly, R.},
title={Starcraft AI competitions, bots, and tournament manager software},
journal={IEEE Transactions on Games},
year={2019},
volume={11},
number={3},
pages={227-237},
doi={10.1109/TG.2018.2883499},
art_number={2883499},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086703605&doi=10.1109%2fTG.2018.2883499&partnerID=40&md5=46e3db647aed93ee814ac63508b51a58},
affiliation={Artificial Intelligence Center, Czech Technical University in Prague, Prague, 16000, Czech Republic; Department of Computer Science, Memorial University of Newfoundland, St. John's, NF  A1C 5S7, Canada; Department of Computer Science and Engineering, Sejong University, Seoul, 143-747, South Korea; Department of Cybernetics and Artificial Intelligence, Technical University in Košice, Košice, 04001, Slovakia},
abstract={Real-time strategy games have become an increasingly popular test bed for modern artificial intelligence (AI) techniques. With this rise in popularity has come the creation of several annual competitions, in which AI agents (bots) play the full game of StarCraft: Broodwar by Blizzard Entertainment. The three major annual StarCraft AI Competitions are the Student StarCraft AI Tournament, the Computational Intelligence in Games competition, and the Artificial Intelligence and Interactive Digital Entertainment competition. In this paper, we will give an overview of the current state of these competitions, describe the bots that compete in them, and describe the underlying open-source Tournament Manager software that runs them. © 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.},
author_keywords={Artificial intelligence;  Computational intelligence;  Computer science education;  Education;  Educational programs;  Learning;  Machine learning},
document_type={Article},
source={Scopus},
}

@ARTICLE{Alexakis20191,
author={Alexakis, G. and Panagiotakis, S. and Fragkakis, A. and Markakis, E. and Vassilakis, K.},
title={Control of smart home operations using natural language processing, voice recognition and iot technologies in a multi-tier architecture},
journal={Designs},
year={2019},
volume={3},
number={3},
pages={1-18},
doi={10.3390/designs3030032},
art_number={32},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081124206&doi=10.3390%2fdesigns3030032&partnerID=40&md5=9c86697ce9de7c84bb57e8f52943ab4a},
affiliation={Department of Electrical and Computer Engineering, Hellenic Mediterranean University, Heraklion, GR71004, Greece},
abstract={The Internet of Things (IoT) is an emerging Internet-based architecture, enabling the exchange of data and services in a global network. With the advent of the Internet of Things, more and more devices are connecting to the Internet in order to help people get and share data or program actions. In this paper, we introduce an IoT Agent, a Web application for monitoring and controlling a smart home remotely. The IoT Agent integrates a chat bot that can understand text or voice commands using natural language processing (NLP). With the use of NLP, home devices are more user-friendly and controlling them is easier, since even when a command or question/command is different from the presets, the system understands the user’s wishes and responds accordingly. Our solution exploits several available Application Programming Interfaces (APIs), namely: the Dialogflow API for the efficient integration of NLP to our IoT system, the Web Speech API for enriching user experience with voice recognition and synthesis features, MQTT (Message Queuing Telemetry Transport) for the lightweight control of actuators and Firebase for dynamic data storage. This is the most significant innovation it brings: the integration of several third-party APIs and open source technologies into one mash-up, highlighting how a new IoT application can be built today using a multi-tier architecture. We believe that such a tiered architecture can be very useful for the rapid development of smart home applications. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
author_keywords={Chatbot;  Dialogflow API;  Internet of Things;  IoT;  MQTT;  Multi-tier architecture;  Natural language processing;  NLP;  Smart home;  Web Speech API},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Moore2019,
author={Moore, M. and Sooknanan, J. and Holley, J.},
title={Bobble-Bot: An educational platform for real-time control with ROS},
journal={2019 22nd IEEE International Symposium on Measurement and Control in Robotics: Robotics for the Benefit of Humanity, ISMCR 2019},
year={2019},
doi={10.1109/ISMCR47492.2019.8955713},
art_number={8955713},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078861093&doi=10.1109%2fISMCR47492.2019.8955713&partnerID=40&md5=4c22754afbd915ca328394cfefbd3cd3},
affiliation={Simulation and Software Lead, S.O. Engineering, Houston, TX, United States},
abstract={To help meet the growing needs of the robotics community, the Robot Operating System (ROS) is currently undergoing a major redesign in which one of its primary design goals is to prioritize support for real-time computing (ROS2). Real-time computing techniques are found in most industrial robots, and yet this capability is noticeably lacking from many of the open-source ROS robots in existence today. This knowledge gap is problematic for students using ROS and their future employers with realtime systems requiring development and maintenance. Bobble-Bot is an open-source ROS robot that was created to close this gap. The robot demonstrates the use of real-time control using ROS in a fun and engaging way. Bobble-Bot is a modern example of the classic inverted pendulum problem that is commonly covered in control theory. It is a controls problem that requires a real-time controller to maintain stability. This paper introduces Bobble-Bot and its accompanying simulator in order to demonstrate how to design a real-time system that uses the ROS and ROS2 frameworks. In addition, results from simulation and hardware tests are provided along with links to Bobble-Bot's open-source software and project documentation. © 2019 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Rebai2019152,
author={Rebai, S. and Ben Sghaier, O. and Alizadeh, V. and Kessentini, M. and Chater, M.},
title={Interactive refactoring documentation bot},
journal={Proceedings - 19th IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2019},
year={2019},
pages={152-162},
doi={10.1109/SCAM.2019.00026},
art_number={8930873},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077817405&doi=10.1109%2fSCAM.2019.00026&partnerID=40&md5=950e9d9bd0d2a6f2ca96b376f4835d9d},
affiliation={CIS Department, University of Michigan, Dearborn, MI, United States},
abstract={The documentation of code changes is significantly important but developers ignore it, most of the time, due to the pressure of the deadlines. While developers may document the most important features modification or bugs fixing, recent empirical studies show that the documentation of quality improvements and/or refactoring is often omitted or not accurately described. However, the automated or semi-automated documentation of refactorings has not been yet explored despite the extensive work on the remaining steps of refactoring including the detection, prioritization and recommendation. In this paper, we propose a semi-automated refactoring documentation bot that helps developers to interactively check and validate the documentation of the refactorings and/or quality improvements at the file level for each opened pull-request before being reviewed or merged to the master. The bot starts by checking the pullrequest if there are significant quality changes and refactorings at the file level and whether they are documented by the developer. Then, it checks the validity of the developers description of the refactorings, if any. Based on that analysis, the documentation bot will recommend a message to document the refactorings, their locations and the quality improvement for that pull-request when missing information is found. Then, the developer can modify his pull request description by interacting with the bot to accept/modify/reject part of the proposed documentation. Since refactoring do not happen in isolation most of the time, the bot is documenting the impact of a sequence of refactorings, in a pull-request, on quality and not each refactoring in isolation. We conducted a human survey with 14 active developers to manually evaluate the relevance and the correctness of our tool on different pull requests of 5 open source projects and one industrial system. The results show that the participants found that our bot facilitates the documentation of their quality-related changes and refactorings. © 2019 IEEE.},
author_keywords={Documentation;  Intelligent bot;  Refactoring},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Perez-Soler2019478,
author={Perez-Soler, S. and Guerra, E. and De Lara, J.},
title={Flexible modelling using conversational agents},
journal={Proceedings - 2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion, MODELS-C 2019},
year={2019},
pages={478-482},
doi={10.1109/MODELS-C.2019.00076},
art_number={8904633},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075935935&doi=10.1109%2fMODELS-C.2019.00076&partnerID=40&md5=8023bb3b7c9cef61d8f2115050712672},
affiliation={Computer Science Department, Universidad Autónoma de Madrid, Madrid, Spain},
abstract={The advances in natural language processing and the wide use of social networks have boosted the proliferation of chatbots. These are software services typically embedded within a social network, and which can be addressed using conversation through natural language. Many chatbots exist with different purposes, e.g., to book all kind of services, to automate software engineering tasks, or for customer support. In previous work, we proposed the use of chatbots for domain-specific modelling within social networks. In this short paper, we report on the needs for flexible modelling required by modelling using conversation. In particular, we propose a process of meta-model relaxation to make modelling more flexible, followed by correction steps to make the model conforming to its meta-model. The paper shows how this process is integrated within our conversational modelling framework, and illustrates the approach with an example. © 2019 IEEE.},
author_keywords={Chatbots;  Conversational Agent;  Flexible Modelling;  Natural Language Processing},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hukal201952,
author={Hukal, P. and Berente, N. and Germonprez, M. and Schecter, A.},
title={Bots Coordinating Work in Open Source Software Projects},
journal={Computer},
year={2019},
volume={52},
number={9},
pages={52-60},
doi={10.1109/MC.2018.2885970},
art_number={8812169},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071568761&doi=10.1109%2fMC.2018.2885970&partnerID=40&md5=9116d16adc7446d2702461a083b68bf4},
affiliation={Digitalization, Copenhagen Business School, Denmark; Business, University of Notre Dame, United States; Information Systems, University of Nebraska at Omaha, United States; Terry College of Business, University of Georgia, United States},
abstract={Increasingly, bots are being used to coordinate work in open source software projects. As mechanisms that ensure the smooth functioning of open source software projects, bot activity influences how scholars and practitioners understand open source software development. © 1970-2012 IEEE.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Miller2019,
author={Miller, M. and Washburn, M. and Khosmood, F.},
title={Evolving unsupervised neural networks for Slither.io},
journal={ACM International Conference Proceeding Series},
year={2019},
doi={10.1145/3337722.3341837},
art_number={55},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072830639&doi=10.1145%2f3337722.3341837&partnerID=40&md5=a7f6119b183e31a3db02dc488f6fa8a4},
affiliation={California Polytechnic State University, San Luis Obispo, CA, United States},
abstract={Slither.io is a massively multiplayer online game in which up to 500 players control worm-like avatars and consume food to grow with the goal of becoming the largest player while avoiding running into one another. The platform serves as a good testbed for developing AI controlled agents due to its accessibility, mechanical simplicity, and unpredictability. In this paper, we develop a Slither.io bot using neuroevolution of augmenting topologies (NEAT) and compare its performance to that of the best open source bot available online (a high-performing expert system bot). With a fitness function based on the final size of the agent, our results show steady improvement in average score. We discuss the unique emergent behaviors observed by our top performing agents. © 2019 Authors.},
author_keywords={Artificial intelligence in games;  Evolving artificial neural networks;  Genetic algorithm;  Neural evolution of augmenting topologies;  Unsupervised learning},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Jonell2019,
author={Jonell, P. and Lopes, J. and Fallgren, P. and Wennberg, U. and Doğan, F.I. and Skantze, G.},
title={Crowdsourcing a self-evolving dialog graph},
journal={ACM International Conference Proceeding Series},
year={2019},
doi={10.1145/3342775.3342790},
art_number={14},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075882531&doi=10.1145%2f3342775.3342790&partnerID=40&md5=ce6916cb8f81257b771880a957c1c6ed},
affiliation={KTH Royal Institute of Technology, Sweden; Heriot-Watt University, United Kingdom},
abstract={In this paper we present a crowdsourcing-based approach for collecting dialog data for a social chat dialog system, which gradually builds a dialog graph from actual user responses and crowd-sourced system answers, conditioned by a given persona and other instructions. This approach was tested during the second instalment of the Amazon Alexa Prize 2018 (AP2018), both for the data collection and to feed a simple dialog system which would use the graph to provide answers. As users interacted with the system, a graph which maintained the structure of the dialogs was built, identifying parts where more coverage was needed. In an ofine evaluation, we have compared the corpus collected during the competition with other potential corpora for training chatbots, including movie subtitles, online chat forums and conversational data. The results show that the proposed methodology creates data that is more representative of actual user utterances, and leads to more coherent and engaging answers from the agent. An implementation of the proposed method is available as open-source code. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
author_keywords={Crowdsourcing;  Datasets;  Dialog systems;  Human-computer interaction},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{DeLacerda2019,
author={De Lacerda, A.R.T. and Aguiar, C.S.R.},
title={FLOSS FAQ chatbot project reuse - How to allow nonexperts to develop a chatbot},
journal={Proceedings of the 15th International Symposium on Open Collaboration, OpenSym 2019},
year={2019},
doi={10.1145/3306446.3340823},
art_number={3},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073154681&doi=10.1145%2f3306446.3340823&partnerID=40&md5=67d4c6864705ced13c73e65d1a425c0b},
affiliation={UnB Faculty in Gama, University of Brasilia, Brasilia, Brazil},
abstract={FAQ chatbots possess the capability to provide answers to frequently asked questions of a particular service, platform, or system. Currently, FAQ chatbot is the most popular domain of use of dialog assistants. However, developing a chatbot project requires a full-stack team formed by numerous specialists, such as dialog designer, data scientist, software engineer, DevOps, business strategist and experts from the domain, which can be both time and resources consuming. Language processing can be particularly challenging in languages other than English due to the scarcity of training datasets. Most of the requirements of FAQ chatbots are similar, domain-specific, and projects could profit from Open Source Software (OSS) reuse. In this paper, we examine how OSS FAQ chatbot projects can benefit from reuse at the project level (black-box reuse). We present an experience report of a FLOSS FAQ chatbot project developed in Portuguese to an e-government service in Brazil. It comprises of the chatbot distribution service, as well as for analytics tool integrated and deployed on-premises. We identified assets that could be reused as a black-box and the assets that should be customized for a particular application. We categorized these assets in architecture, corpus, dialog flows, machine learning models, and documentation. This paper discusses how automation, pre-configuration, and templates can aid newcomers to develop chatbots in Portuguese without the need for specialized skills required from tools in chatbot. © 2019 Association for Computing Machinery.},
author_keywords={Black-Box reuse;  Conversational agents;  E-government;  Experience report;  FLOSS;  FLOSS FAQ chatbot;  Open source;  OSS;  Portuguese chatbot},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kai-Cheng201920,
author={Kai-Cheng, C. and Hsien-Tsung, C.},
title={Is it possible to use chatbot for the Chinese word segmentation?},
journal={ACM International Conference Proceeding Series},
year={2019},
pages={20-24},
doi={10.1145/3342827.3342836},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071657562&doi=10.1145%2f3342827.3342836&partnerID=40&md5=d422d87c6ef61cf8d2484b5b36e6846f},
affiliation={Chang Gung University, 259 Wen-Hwa 1st Road, Kwei-Shan Tao-Yuan, 333, Taiwan},
abstract={A word is the smallest item in Natural Language Processing. However, there is no obvious boundary for Chinese words. How to segment Chinese words always obstructs Chinese researches and applications. Nowadays, a neural network model, Seq2Seq with LSTM, is well-known for translation or chatbot application. In this paper, we try to transform the Chinese word segmentation problem into a translation problem. And we utilized an open-source chatbot to simulate the translation task. In our experimental results, we can produce similar Chinese word segmentation results when we provide training data which is automatically generated from famous Chinese word segmentation services. © 2019 Association for Computing Machinery.},
author_keywords={Chatbot;  Chinese word segmentation;  LSTM;  Seq2Seq},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lee2019793,
author={Lee, C.-S. and Wang, M.-H. and Chen, L.-C. and Nojima, Y. and Huang, T.-X. and Woo, J. and Kubota, N. and Sato-Shimokawara, E. and Yamaguchi, T.},
title={A GFML-based Robot Agent for Human and Machine Cooperative Learning on Game of Go},
journal={2019 IEEE Congress on Evolutionary Computation, CEC 2019 - Proceedings},
year={2019},
pages={793-799},
doi={10.1109/CEC.2019.8790015},
art_number={8790015},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071295044&doi=10.1109%2fCEC.2019.8790015&partnerID=40&md5=9ba97e723ea88c8d47b835af353915e4},
affiliation={National University of Tainan, Tainan, Taiwan; Osaka Prefecture University, Osaka, Japan; Tokyo Metropolitan University, Tokyo, Japan},
abstract={This paper applies a genetic algorithm and fuzzy markup language to construct a human and smart machine cooperative learning system on game of Go. The genetic fuzzy markup language (GFML)-based Robot Agent can work on various kinds of robots, including Palro, Pepper, and TMU's robots. We use the parameters of FAIR open source Darkforest and OpenGo AI bots to construct the knowledge base of Open Go Darkforest (OGD) cloud platform for student learning on the Internet. In addition, we adopt the data from AlphaGo Master's sixty online games as the training data to construct the knowledge base and rule base of the co-learning system. First, the Darkforest predicts the win rate based on various simulation numbers and matching rates for each game on the OGD platform, then the win rate of OpenGo is as the final desired output. The experimental results show that the proposed approach can improve knowledge base and rule base of the prediction ability based on Darkforest and OpenGo AI bot with various simulation numbers. © 2019 IEEE.},
author_keywords={FAIR ELF OpenGo;  fuzzy markup language;  game of Go;  Genetic algorithm;  robot},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gilson2019238,
author={Gilson, F. and Weyns, D.},
title={When Natural Language Processing Jumps into Collaborative Software Engineering},
journal={Proceedings - 2019 IEEE International Conference on Software Architecture - Companion, ICSA-C 2019},
year={2019},
pages={238-241},
doi={10.1109/ICSA-C.2019.00049},
art_number={8712352},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066474736&doi=10.1109%2fICSA-C.2019.00049&partnerID=40&md5=a00813bb68cb54aa0d60c8fa622c0515},
affiliation={University of Canterbury, Computer Science and Software Engineering, Christchurch, New Zealand; Katholieke Universiteit Leuven, Belgium Linnaeus University, Department of Computer Science, Vaxjo, Sweden},
abstract={Software engineering is an intrinsically collaborative activity, especially in the era of Agile Software Development. Many actors are partaking in development activities, such that a common understanding should be reached at numerous stages during the overall development life-cycle. For a few years now, Natural Language Processing techniques have been employed either to extract key information from free-form text or to generate models from the analysis of text in order to ease the sharing of knowledge across all parties. A significant part of these approaches focuses on retrieving lost domain and architectural knowledge through the analysis of documents, issue management systems or other forms of knowledge management systems. However, these post-processing methods are time-consuming by nature since they require to invest significant resources into the validation of the extracted knowledge. In this paper, inspired by collaborative tools, bots and Natural Language extraction approaches, we envision new ways to collaboratively record and document design decisions as they are discussed. These decisions will be documented as they are taken and, for some of them, static or behavioural models may be generated on-the-fly. Such an interactive process will ensure everyone agrees on critical design aspects of the software. We believe development teams will benefit from this approach because manual encoding of design knowledge will be reduced and will not be pushed to a later stage, when not forgotten. © 2019 IEEE.},
author_keywords={agile software development;  documentation;  model-driven development;  natural language processing},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2019,
title={Proceedings - 2019 IEEE/ACM 1st International Workshop on Bots in Software Engineering, BotSE 2019},
journal={Proceedings - 2019 IEEE/ACM 1st International Workshop on Bots in Software Engineering, BotSE 2019},
year={2019},
page_count={75},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084011690&partnerID=40&md5=0ae9a7c504b0db0c3bbef7a2c2628eb2},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Monperrus201912,
author={Monperrus, M.},
title={Explainable software bot contributions: Case study of automated bug fixes},
journal={Proceedings - 2019 IEEE/ACM 1st International Workshop on Bots in Software Engineering, BotSE 2019},
year={2019},
pages={12-15},
doi={10.1109/BotSE.2019.00010},
art_number={8823632},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072933116&doi=10.1109%2fBotSE.2019.00010&partnerID=40&md5=bbf088ffb337274d0246e6c468bf4559},
affiliation={KTH Royal Institute of Technology, Sweden},
abstract={In a software project, esp. in open-source, a contribution is a valuable piece of work made to the project: writing code, reporting bugs, translating, improving documentation, creating graphics, etc. We are now at the beginning of an exciting era where software bots will make contributions that are of similar nature than those by humans. Dry contributions, with no explanation, are often ignored or rejected, because the contribution is not understandable per se, because they are not put into a larger context, because they are not grounded on idioms shared by the core community of developers. We have been operating a program repair bot called Repairnator for 2 years and noticed the problem of 'dry patches': a patch that does not say which bug it fixes, or that does not explain the effects of the patch on the system. We envision program repair systems that produce an 'explainable bug fix': an integrated package of at least 1) a patch, 2) its explanation in natural or controlled language, and 3) a highlight of the behavioral difference with examples. In this paper, we generalize and suggest that software bot contributions must explainable, that they must be put into the context of the global software development conversation. © 2019 IEEE.},
author_keywords={Program repair;  Software bot;  Software engineering},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wessel201938,
author={Wessel, M. and Steinmacher, I. and Wiese, I. and Gerosa, M.A.},
title={Should i stale or should i close? An analysis of a bot that closes abandoned issues and pull requests},
journal={Proceedings - 2019 IEEE/ACM 1st International Workshop on Bots in Software Engineering, BotSE 2019},
year={2019},
pages={38-42},
doi={10.1109/BotSE.2019.00018},
art_number={8823598},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072929326&doi=10.1109%2fBotSE.2019.00018&partnerID=40&md5=e7d9e971ee4b032b9f173c859eee1469},
affiliation={University of Sao Paulo, Sao Paulo, SP, Brazil; Northern Arizona University, Flagstaff, AZ, United States; Fed. Univ. of Technology, Parana, Campo Mourao, PR, Brazil},
abstract={On GitHub, projects use bots to automate predefined and repetitive tasks related to issues and pull requests. Our research investigates the adoption of the stale bot, which helps maintainers triaging abandoned issues and pull requests. We analyzed the bots' configuration settings and their modifications over time. These settings define the time for tagging issues and pull request as stale and closing them. We collected data from 765 OSS projects hosted on GitHub. Our results indicate that most of the studied projects made no more than three modifications in the configurations file, issues tagged as bug reports are exempt from being considered stale, while the same occurs with pull requests that need some input to be processed. © 2019 IEEE.},
author_keywords={Abandoned issues;  Bots;  Open source software},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Erlenhov20197,
author={Erlenhov, L. and Gomes De Oliveira Neto, F. and Scandariato, R. and Leitner, P.},
title={Current and future bots in software development},
journal={Proceedings - 2019 IEEE/ACM 1st International Workshop on Bots in Software Engineering, BotSE 2019},
year={2019},
pages={7-11},
doi={10.1109/BotSE.2019.00009},
art_number={8823643},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072918829&doi=10.1109%2fBotSE.2019.00009&partnerID=40&md5=a84531e35ef4df3a2580a128ed1f4907},
affiliation={Software Engineering Division, Chalmers | University of Gothenburg, Gothenburg, Sweden},
abstract={Bots that support software development ('DevBots') are seen as a promising approach to deal with the ever-increasing complexity of modern software engineering and development. Existing DevBots are already able to relieve developers from routine tasks such as building project images or keeping dependencies up-to-date. However, advances in machine learning and artificial intelligence hold the promise of future, significantly more advanced, DevBots. In this paper, we introduce the terminology of contemporary and ideal DevBots. Contemporary DevBots represent the current state of practice, which we characterise using a facet-based taxonomy. We exemplify this taxonomy using 11 existing, industrial-strength bots. We further provide a vision and definition of future (ideal) DevBots, which are not only autonomous, but also adaptive, as well as technically and socially competent. These properties may allow ideal DevBots to act more akin to artificial team mates than simple development tools. © 2019 IEEE.},
author_keywords={Software Bot;  Sotware Engineering;  Taxonomy},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Shenoy201962,
author={Shenoy, A. and Sushma Ravindra, Y. and Sharma, A. and Rajan, A. and Gv, A.},
title={NLP models behind RASA stack},
journal={International Journal of Engineering and Advanced Technology},
year={2019},
volume={8},
number={5 Special Issue},
pages={62-66},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069544023&partnerID=40&md5=761878214fea60154deb5936103cae48},
affiliation={School of C&IT, REVA University, India},
abstract={This paper brings about the foundation of a platform for conversational AI the Rasa platform. This Rasa stack contains a block of open source machine learning tools exclusively used in intend to create a contextual chatbots and assistants. The services hold by this platform undergoes a major classification of powerful APIs and embedded together with Rasa stack which includes Rasa core and Rasa NLU in the form of an event stream discussed throughout this paper and also the algorithm involved in building upon this platform. Its ingredients include the Bag of words algorithm helping in simplifying representation used in the NLP, CRFs – Conditional Random Field used in statistical modelling and machine learning platforms and also advanced technology such as LTSM neural networks. This paper discusses all the algorithms involved in building up the platform and also the result produced in building up the student assistant chatbot using this platform. It also encourages the use of this RASA platform for the user required custom format as per their requirements and also promotes to contribute in developing the platform for better efficiency of the platform to function. © BEIESP.},
author_keywords={Bag of words;  Chatbot;  CRFs;  NLP;  Rasa stack},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sandeep20191,
author={Sandeep, M. and Shivgonda, L. and Rajeswari, M. and Kaushik, S. and Tengli, N.},
title={Robotic ARM using computer vision},
journal={International Journal of Engineering and Advanced Technology},
year={2019},
volume={8},
number={5 Special Issue},
pages={1-5},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069540955&partnerID=40&md5=cf179d6d8ab232a62b6a10822339661c},
affiliation={School of C & I T, REVA University, India},
abstract={A Bot which pursues Human hand developments. Its unlimited authority lies with the client and doesn't have any knowledge of its own. Programmed robots having man-made brainpower are a danger to society and may cause hurt in certain situations. Subsequently, having full oversight over the robot is a protected method to work with such robots. In this paper, we have proposed a comparable arrangement of a robot. catching pictures from the PC web cam progressively condition and procedure them as we are required. By utilizing open source Computer vision library (OpenCV for short), a picture can be caught on the basis of its Hue saturation value (HSV) extend. The fundamental library capacities for picture dealing with and handling are utilized. Fundamental library capacities are utilized for stacking a picture, making windows to hold picture at run time, sparing pictures, and to separate pictures dependent on their shading values. I have additionally connected capacity to edge the yield picture so as to diminish the twisting in it. While handling, the pictures are changed over from their essential plain Red, Green, and Blue (RGB) to an increasingly reasonable one that is HSV. © BEIESP.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Xie2019,
author={Xie, Q. and Tan, D. and Zhu, T. and Zhang, Q. and Xiao, S. and Wang, J. and Li, B. and Sun, L. and Yi, P.},
title={Chatbot Application on Cryptocurrency},
journal={CIFEr 2019 - IEEE Conference on Computational Intelligence for Financial Engineering and Economics},
year={2019},
doi={10.1109/CIFEr.2019.8759121},
art_number={8759121},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069533276&doi=10.1109%2fCIFEr.2019.8759121&partnerID=40&md5=56ae3526629e1b53fdb06a50a70ae87e},
affiliation={Department of Computer Science and Electrical Engineering, UMBC, USA, United Kingdom; University of Illinois, Urbana Champaign, United States; Hunan University, China; Carnegie Mellon University, United States; Shanghai Graduate School, Chinese Academy of Social Sciences, China; Shanghai Jiaotong University, China},
abstract={Many chatbots have been developed that provide a multitude of services through a wide range of methods. A chatbot is a brand-new conversational agent in the highspeed changing technology world. With the advance of Artificial Intelligence and machine learning, chatbots are becoming more and more popular. A chatbot is the extension of human interface mediums such as the phone and social platforms. Similarly, Cryptocurrency is a new extension of digital or virtual currency designed to work as a medium of exchange. In the current digital exchanging world, investors and interested parties are eager to know more information about, and the capabilites of, this new type of currency. One of the potential paths to retrieve the info automatically and quickly is through a chatbot. We explored the open source python library, Chatterbot, to apply Itchat API (a WeChat interface) with the aim of building a robot chatting application, IC Chat, on the topic of cryptocurrency. First, we collected question and answer pairs datasets from Quora websites. Furthermore, we also created API calls to query the real time quote for the top 25 cryptocurrencies. Then we used the collected data to train our chatbot and implemented a logic adapter to receive the price quote of cryptocurrencies based on the incoming question. The Itchat API method will return the best matched answer to the asking party automatically. The response time of different questions has been investigated. The results imply that this application is quite useful, feasible and beneficial to the digital currency world. © 2019 IEEE.},
author_keywords={Chatbot;  Cryptocurrency},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Saba201914,
author={Saba, L. and Biswas, M. and Kuppili, V. and Cuadrado Godia, E. and Suri, H.S. and Edla, D.R. and Omerzu, T. and Laird, J.R. and Khanna, N.N. and Mavrogeni, S. and Protogerou, A. and Sfikakis, P.P. and Viswanathan, V. and Kitas, G.D. and Nicolaides, A. and Gupta, A. and Suri, J.S.},
title={The present and future of deep learning in radiology},
journal={European Journal of Radiology},
year={2019},
volume={114},
pages={14-24},
doi={10.1016/j.ejrad.2019.02.038},
note={cited By 85},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062451021&doi=10.1016%2fj.ejrad.2019.02.038&partnerID=40&md5=7f50b3a7356f099786b7585685ed6a23},
affiliation={Department of Radiology, Policlinico Universitario, Cagliari, Italy; National Institute of Technology Goa, India; IMIM – Hospital del Mar, Passeig Marítim 25-29, Barcelona, Spain; Brown University, Providence, RI, United States; Department of Neurology, University Medical Centre Maribor, Slovenia; Cardiology Department, St. Helena Hospital, St. Helena, CA, United States; Cardiology Department, Apollo Hospitals, New Delhi, India; Cardiology Clinic, Onassis Cardiac Surgery Center, Athens, Greece; Department of Cardiovascular Prevention & Research Unit Clinic & Laboratory of Pathophysiology, National and Kapodistrian Univ. of Athens, Greece; Rheumatology Unit, National Kapodistrian University of Athens, Greece; MV Hospital for Diabetes and Professor M Viswanathan Diabetes Research Centre, Chennai, India; Arthritis Research UK Centre for Epidemiology, Manchester University, Manchester, United Kingdom; Department of Rheumatology, Dudley Group NHS Foundation Trust, Dudley, United Kingdom; Vascular Screening and Diagnostic Centre, London, United Kingdom; Department of Biological Sciences, University of Cyprus, Nicosia, Cyprus; Brain and Mind Research Institute and Department of Radiology, Weill Cornell Medical CollegeNY, United States; Stroke Monitoring and Diagnostic Division, AtheroPoint™, Roseville, CA, United States},
abstract={The advent of Deep Learning (DL) is poised to dramatically change the delivery of healthcare in the near future. Not only has DL profoundly affected the healthcare industry it has also influenced global businesses. Within a span of very few years, advances such as self-driving cars, robots performing jobs that are hazardous to human, and chat bots talking with human operators have proved that DL has already made large impact on our lives. The open source nature of DL and decreasing prices of computer hardware will further propel such changes. In healthcare, the potential is immense due to the need to automate the processes and evolve error free paradigms. The sheer quantum of DL publications in healthcare has surpassed other domains growing at a very fast pace, particular in radiology. It is therefore imperative for the radiologists to learn about DL and how it differs from other approaches of Artificial Intelligence (AI). The next generation of radiology will see a significant role of DL and will likely serve as the base for augmented radiology (AR). Better clinical judgement by AR will help in improving the quality of life and help in life saving decisions, while lowering healthcare costs. A comprehensive review of DL as well as its implications upon the healthcare is presented in this review. We had analysed 150 articles of DL in healthcare domain from PubMed, Google Scholar, and IEEE EXPLORE focused in medical imagery only. We have further examined the ethic, moral and legal issues surrounding the use of DL in medical imaging. © 2019},
author_keywords={Deep learning;  Machine learning;  Medical imaging;  Radiology},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Ciupe20191100,
author={Ciupe, A. and Mititica, D.F. and Meza, S. and Orza, B.},
title={Learning agile with intelligent conversational agents},
journal={IEEE Global Engineering Education Conference, EDUCON},
year={2019},
volume={April-2019},
pages={1100-1107},
doi={10.1109/EDUCON.2019.8725192},
art_number={8725192},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067474538&doi=10.1109%2fEDUCON.2019.8725192&partnerID=40&md5=72cf29687a4cc791389b69b06008c698},
affiliation={Multimedia Systems and Applications Laboratory, Technical University of Cluj-Napoca, Cluj-Napoca, Romania},
abstract={Conversational agents assist traditional teaching-learning instruments in proposing new designs for knowledge creation and learning analysis, across organizational environments. Means of building common educative background in both industry and academic fields become of interest for ensuring educational effectiveness and consistency. Such a context requires transferable practices and becomes the basis for the Agile adoption into Higher Education, at both curriculum and operational levels. The current work proposes a model for delivering Agile Scrum training through an assistive web-based conversational service, where analytics are collected to provide an overview on learners' knowledge path. Besides its specific applicability into Software Engineering (SE) industry, the model is to assist the academic SE curriculum. A user-acceptance test has been carried out among 200 undergraduate students and patterns of interaction have been depicted for 2 conversational strategies. © 2019 IEEE.},
author_keywords={Agile scrum training;  Conversational agent;  Educational design;  Higher education;  Learning analytics},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Shruthi20191505,
author={Shruthi, C.M. and Satya Sai Srinath, N.G.N.V.V. and Vamsi, G.V. and Sudheer, A.P. and Joy, M.L.},
title={Android based control of transmission line robot for traversing through straight line and crossing of tower junctions},
journal={International Journal of Innovative Technology and Exploring Engineering},
year={2019},
volume={8},
number={6},
pages={1505-1510},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066836115&partnerID=40&md5=1825a42f6a713806b5647c42b6c1afb2},
affiliation={Department of Mechanical Engineering, NIT, Calicut, India},
abstract={The most widely used means to transmit electricity is through transmission lines. These power lines are prone to problems with adverse weather conditions prevailing in different locations. Workers climb the poles and manually check if any faults occur in power lines and this makes their lives riskier. It also interrupts the power supply. A robot based inspection makes this task easier, efficient, foolproof and safe. Android based control is one of the simple and powerful methodologies due to the availability of smart phones. Also android is an open source platform which has software with lot of applications for online and offline operations. This paper mainly concentrates on an Android based control of a dual arm suspended type mobile robot for tension and suspension towers. Methodology of crossing and description of the robot model are also explained in this paper. The communication in android based control of robot is done through a mobile application. Control of the main subsystems such as mobile robot base, pulley system and dual arm is established using the smart phone application named ‘Bot Controller’ developed using MIT App Inventor which communicates with the Arduino Mega using Bluetooth module. All the tasks are controlled using corresponding buttons in the application interface. The communication between the onboard electronics and the user is taken care by the MIT App Inventor where multiple functions corresponding to various motion of robot are created. Speed and direction of rotation of each and every motor have been given as functions for motions. Complete control flow architecture with all hardware are also depicted. © BEIESP.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Balwal201976,
author={Balwal, U. and Krishnamurthy, V.},
title={Bot assisted software development},
journal={International Journal of Innovative Technology and Exploring Engineering},
year={2019},
volume={8},
number={6},
pages={76-80},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066072574&partnerID=40&md5=fb57899e5971de53ba3a42a55d5c3aaf},
affiliation={SSN College of Engineering, Anna University, Chennai, Tamil Nadu, India},
abstract={Many software products are direct or indirect implementations of already available algorithms; most of which are Open Source and available online. The problem is that we have to search the vast repositories to find the relevant implementation. We propose a way to catalog the program code, so that a bot could read that catalog to figure out the working of a code block and fetch required functionality that can be customized for the new project. This will increase the productivity of the team, is convenient for the developer community and will greatly reduce initial development time. © BEIESP.},
author_keywords={Assisted;  Automated;  Development;  Software},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Püchel2019,
author={Püchel, L.},
title={Online content complexity: A conceptual framework to categorize and evaluate presentation modes},
journal={40th International Conference on Information Systems, ICIS 2019},
year={2019},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114902197&partnerID=40&md5=4d811057b9346a28799bd2aa754f7d49},
affiliation={University of Cologne, Pohligstr. 1, Cologne, 50969, Germany},
abstract={Open Source formats, long-reads, chat-bot-systems, accelerated mobile pages and stories format are but a few examples of modern ways to communicate content to an audience. The presentation of media as well as the communication about media obviously does not forego without generic designations. However, these have not been empirically accessed nor does a system exist to analyze presentation modes. This article provides a platform-independent framework for measuring and categorizing presentation modes. A combination of qualitative and quantitative measurements is used to identify key dimensions that make up digital presentation modes. As an object of investigation, we choose the journalism environment, as the presentation of news is one of the oldest tools to spread information. The study's main finding is that presentation modes are made up of nine central dimensions with specified manifestations. © 40th International Conference on Information Systems, ICIS 2019. All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ghandeharioun2019,
author={Ghandeharioun, A. and Shen, J.H. and Jaques, N. and Ferguson, C. and Jones, N. and Lapedriza, A. and Picard, R.},
title={Approximating interactive human evaluation with self-play for open-domain dialog systems},
journal={Advances in Neural Information Processing Systems},
year={2019},
volume={32},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090177820&partnerID=40&md5=34f3cf41539657653d179004b278df32},
affiliation={Department of Media Arts and Science, Massachusetts Institute of Technology, Cambridge, MA  02139, United States},
abstract={Building an open-domain conversational agent is a challenging problem. Current evaluation methods, mostly post-hoc judgments of static conversation, do not capture conversation quality in a realistic interactive context. In this paper, we investigate interactive human evaluation and provide evidence for its necessity; we then introduce a novel, model-agnostic, and dataset-agnostic method to approximate it. In particular, we propose a self-play scenario where the dialog system talks to itself and we calculate a combination of proxies such as sentiment and semantic coherence on the conversation trajectory. We show that this metric is capable of capturing the human-rated quality of a dialog model better than any automated metric known to-date, achieving a significant Pearson correlation (r >.7, p <.05). To investigate the strengths of this novel metric and interactive evaluation in comparison to state-of-the-art metrics and human evaluation of static conversations, we perform extended experiments with a set of models, including several that make novel improvements to recent hierarchical dialog generation architectures through sentiment and semantic knowledge distillation on the utterance level. Finally, we open-source the interactive evaluation platform we built and the dataset we collected to allow researchers to efficiently deploy and evaluate dialog models. © 2019 Neural information processing systems foundation. All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sedoc201960,
author={Sedoc, J. and Ippolito, D. and Kirubarajan, A. and Thirani, J. and Ungar, L. and Callison-Burch, C.},
title={ChatEval: A tool for chatbot evaluation},
journal={NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Demonstrations Session},
year={2019},
pages={60-65},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085639195&partnerID=40&md5=41ee9092e7f3dca580ee057fb4607d44},
affiliation={University of Pennsylvania, United States},
abstract={Open-domain dialog systems (i.e., chatbots) are difficult to evaluate. The current best practice for analyzing and comparing these dialog systems is the use of human judgments. However, the lack of standardization in evaluation procedures, and the fact that model parameters and code are rarely published hinder systematic human evaluation experiments. We introduce a unified framework for human evaluation of chatbots that augments existing tools and provides a web-based hub for researchers to share and compare their dialog systems. Researchers can submit their trained models to the ChatEval web interface and obtain comparisons with baselines and prior work. The evaluation code is open-source to ensure standardization and transparency. In addition, we introduce open-source baseline models and evaluation datasets. ChatEval can be found at https://chateval.org. © 2019 The Association for Computational Linguistics.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2019,
title={Proceedings of the 2nd Student Workshop on Computer Science and Software Engineering, CS and SE@SW 2019},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2546},
page_count={253},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079642136&partnerID=40&md5=f6efe6af3bcbf1755347e99b13c84893},
abstract={The proceedings contain 18 papers. The topics discussed include: dynamic doxastic action in doxastic modal logic; the dawn of software engineering education; an empirical comparison of machine learning clustering methods in the study of internet addiction among students majoring in computer sciences; automated recognition and sorting of agricultural objects using multi-agent approach; comparative analysis of the cryptocurrency and the stock markets using the random matrix theory; convolutional neural networks for image classification; credit scoring model for microfinance organizations; development of a chatbot for informing students of the schedule; system for detecting network anomalies using a hybrid of an uncontrolled and controlled neural network; and modeling university environment: means and applications for university education.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Widyaningrum2019723,
author={Widyaningrum, P. and Ruldeviyani, Y. and Dharayani, R.},
title={Sentiment analysis to assess the community's enthusiasm towards the development chatbot using an appraisal theory},
journal={Procedia Computer Science},
year={2019},
volume={161},
pages={723-730},
doi={10.1016/j.procs.2019.11.176},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078890448&doi=10.1016%2fj.procs.2019.11.176&partnerID=40&md5=5692c3a22b708d372210f7a6ab3ec925},
affiliation={Faculty of Computer Science, Universitas Indonesia, Depok, 16424, Indonesia},
abstract={PT Kreatif Dinamika Integrasi will develop a chatbot as the computer program designed to simulate intellectual conversation via text and voice by using Artificial Intelligence (AI). However, because development costs are high enough, it is necessary to gather opinions on the community's enthusiasm that will support the decision whether the development should or should not to have proceeded. Community sentiment analysis of data obtained from social media Twitter. Appraisal Theory method is exercised utilizing the R Studio tool to perform tweet crawling, preprocessing, scoring and term weighting. R is an open-source language and environment used for statistical computing and graphics. The results of the analysis indicate positive sentiment where the positive and negative comparison ratio was 4,78. The expression of sentiment analysis results by using the NRC library is 547 for “anticipation” sentiment and 728 for “trust” expression so that the technology of chatbot can be developed by the company. Although the results of the analysis of obtained are positive assessment, there is still the negative sentiment in the community, so it is necessary to act to reduce the risk. © 2019 The Authors.},
author_keywords={Appraisal theory;  Chatbot;  Sentiment analysis;  Twitter},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={4th International Conference on Information, Communication and Computing Technology, ICICCT 2019},
journal={Communications in Computer and Information Science},
year={2019},
volume={1025 CCIS},
page_count={311},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077704117&partnerID=40&md5=16f3fd0a2c51243c240df744056fff8b},
abstract={The proceedings contain 24 papers. The special focus in this conference is on Information, Communication and Computing Technology. The topics include: A comparative analysis of mobility models for network of UAVs; role of artificial intelligence and machine learning in resolving the issues and challenges with prosthetic knees; a noise tolerant auto resonance network for image recognition; design of hardware accelerator for artificial neural networks using multi-operand adder; performance analysis of collaborative recommender system: A heuristic approach; plant disease detection by leaf image classification using convolutional neural network; soft modeling approach in predicting surface roughness, temperature, cutting forces in hard turning process using artificial neural network: An empirical study; semi-automatic system for title construction; object recognition in hand drawn images using machine ensembling techniques and smote sampling; design and implementation of low noise amplifier in neural signal analysis; key phrase extraction system for agricultural documents; performance analysis of flappy bird playing agent using neural network and genetic algorithm; open domain conversational chatbot; human protein function prediction enhancement using decision tree based machine learning approach; efficient pruning methods for obtaining compact associative classifiers with enhanced classification accuracy rate; apache hadoop based distributed denial of service detection framework; quality assessment models for open source projects hosted on modern web-based forges: A review; VaFLE: Value flag length encoding for images in a multithreaded environment; impact of sink location in the routing of wireless sensor networks; Development of a WSN based data logger for electrical power system; embedded subscriber identity module with context switching.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Padalkar2019591,
author={Padalkar, A. and Wasil, M. and Mahajan, S. and Kumar, R. and Bakaraniya, D. and Shirodkar, R. and Andradi, H. and Padmanabhan, D. and Wiesse, C. and Abdelrahman, A. and Chavan, S. and Gurulingan, N. and Nair, D. and Thoduka, S. and Awaad, I. and Schneider, S. and Plöger, P.G. and Kraetzschmar, G.K.},
title={b-it-bots: Our Approach for Autonomous Robotics in Industrial Environments},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11531 LNAI},
pages={591-602},
doi={10.1007/978-3-030-35699-6_48},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076897490&doi=10.1007%2f978-3-030-35699-6_48&partnerID=40&md5=7e520e2968b2c1345e5c7ba9fd9af68b},
affiliation={Department of Computer Science, Hochschule Bonn-Rhein-Sieg, Grantham-Allee 20, Sankt Augustin, 53757, Germany},
abstract={This paper presents the approach of our team, b-it-bots, in the RoboCup@Work competition which resulted in us winning the World Championship in Sydney in 2019. We describe our current hardware, including modifications made to the KUKA youBot, the underlying software framework and components developed for navigation, manipulation, perception and task planning for scenarios in industrial environments. Our combined 2D and 3D approach for object recognition has improved robustness and performance compared to previous years, and our task planning framework has moved us away from large state machines for high-level control. Future work includes closing the perception-manipulation loop for more robust grasping. Our open-source repository is available at https://github.com/b-it-bots/mas_industrial_robotics. © 2019, Springer Nature Switzerland AG.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={16th Extended Semantic Web Conference, ESWC 2019},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11762 LNCS},
page_count={299},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075575789&partnerID=40&md5=282d1a7d7171c9c3687aa7ba3bb5c756},
abstract={The proceedings contain 48 papers. The special focus in this conference is on Extended Semantic Web. The topics include: How to Validate Ontologies with Themis; The Magic of Semantic Enrichment and NLP for Medical Coding; an Ontology of Finnish Historical Occupations; Information Extraction in Editorial Setting. A Tale of PDFs; an Open Source Dataset and Ontology for Product Footprinting; IEDM: An Ontology for Irradiation Experiments Data Management; CALVADOS: A Tool for the Semantic Analysis and Digestion of Web Contents; efficient Retrieval of Knowledge Graph Fact Evidences; SAD Generator: Eating Our Own Dog Food to Generate KGs and Websites for Academic Events; mining Scholarly Publications for Scientific Knowledge Graph Construction; OECM: A Cross-Lingual Approach for Ontology Enrichment; how Diverse Are Federated Query Execution Plans Really?; open Data Chatbot; question Answering for Link Prediction and Verification; extracting Genealogical Networks of Linked Data from Biographical Texts; entity Embedding Analogy for Implicit Link Discovery; a License-Based Search Engine; historEx: Exploring Historical Text Corpora Using Word and Document Embeddings; ordia: A Web Application for Wikidata Lexemes; towards Cataloguing Potential Derivations of Personal Data; republishing OpenStreetMap’s Roads as Linked Routable Tiles; DAFO: An Ontological Database System with Faceted Queries; a Configurable Evaluation Framework for Node Embedding Techniques; querying the Edit History of Wikidata; A New Tool for Linked Data Visualization and Exploration in 3D/VR Space; open Cultural Heritage Data in University Programming Courses; Using an Existing Website as a Queryable Low-Cost LOD Publishing Interface; a Tagger for Glossary of Terms Extraction from Ontology Competency Questions.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Belenko2019681,
author={Belenko, M. and Burym, N. and Muratova, U. and Balakshin, P.},
title={Training aspects of automatic speech recognition systems during chat bot creation},
journal={International Multidisciplinary Scientific GeoConference Surveying Geology and Mining Ecology Management, SGEM},
year={2019},
volume={19},
number={2.1},
pages={681-688},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073388160&partnerID=40&md5=1d26c0fcd16323dbac830838550f0a88},
affiliation={ITMO University, Russian Federation},
abstract={This article describes the key features of the automatic speech recognition systems training process that can be used in a work of chat bot or voice assistant. Importance of research in this area is grazed. Difference between chat bot, voice helper and voice assistance are explained. Basic requirements for correct chat bot usage are formulated. Some common automatic speech recognition systems are reviewed. Kaldi and CMU Sphinx has been used as an open source systems’ example. The whole installation and training process are reviewed, instruction for further researchers are documented. Examined systems have been trained with different parameter sets and training data. As a result, the most important training parameters of automatic speech recognition system for chat bot are designated and described. Criteria for selecting data for proper ASR testing is formed. Peculiar chat bot prototype development has started. Results of this research can help to significantly improve the speed and quality of the speech recognition in chat bots and voice assistants. Next steps to continue work with personal solution are presented. © SGEM 2019.},
author_keywords={Chat bot;  CMU Sphinx;  Kaldi;  Speech recognition;  Training},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Amin2019,
author={Amin, M. and Shah, B. and Sharif, A. and Ali, T. and Kim, K.-L. and Anwar, S.},
title={Android malware detection through generative adversarial networks},
journal={Transactions on Emerging Telecommunications Technologies},
year={2019},
doi={10.1002/ett.3675},
art_number={e3675},
note={cited By 13},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069892612&doi=10.1002%2fett.3675&partnerID=40&md5=9864c889326f4582315c9677290be317},
affiliation={Department of Computer Science, Institute of Management Sciences, Peshawar, Pakistan; College of Information Technology, Zayed University, Dubai, United Arab Emirates; Department of Computer Science, National University of Computer and Emerging Sciences, Peshawar, Pakistan; Department of Computer Science and Engineering, Chungnam National University, Daejeon, South Korea},
abstract={Mobile and cell devices have empowered end users to tweak their cell phones more than ever and introduce applications just as we used to with personal computers. Android likewise portrays an uprise in mobile devices and personal digital assistants. It is an open-source versatile platform fueling incalculable hardware units, tablets, televisions, auto amusement frameworks, digital boxes, and so forth. In a generally shorter life cycle, Android also has additionally experienced a mammoth development in application malware. In this context, a toweringly large measure of strategies has been proposed in theory for the examination and detection of these harmful applications for the Android platform. These strategies attempt to both statically reverse engineer the application and elicit meaningful information as features manually or dynamically endeavor to quantify the runtime behavior of the application to identify malevolence. The overgrowing nature of Android malware has enormously debilitated the support of protective measures, which leaves the platforms such as Android feeble for novel and mysterious malware. Machine learning is being utilized for malware diagnosis in mobile phones as a common practice and in Android distinctively. It is important to specify here that these systems, however, utilize and adapt the learning-based techniques, yet the overhead of hand-created features limits ease of use of such methods in reality by an end user. As a solution to this issue, we mean to make utilization of deep learning–based algorithms as the fundamental arrangement for malware examination on Android. Deep learning turns up as another way of research that has bid the scientific community in the fields of vision, speech, and natural language processing. Of late, models set up on deep convolution networks outmatched techniques utilizing handmade descriptive features at various undertakings. Likewise, our proposed technique to cater malware detection is by design a deep learning model making use of generative adversarial networks, which is responsible to detect the Android malware via famous two-player game theory for a rock-paper-scissor problem. We have used three state-of-the-art datasets and augmented a large-scale dataset of opcodes extracted from the Android Package Kit bytecode and used in our experiments. Our technique achieves F1 score of 99% with a receiver operating characteristic of 99% on the bytecode dataset. This proves the usefulness of our technique and that it can generally be adopted in real life. © 2019 John Wiley & Sons, Ltd.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Choueib2019,
author={Choueib, S. and Pinter, C. and Lasso, A. and Fillion-Robin, J.-C. and Vimort, J.-B. and Martin, K. and Fichtinger, G.},
title={Evaluation of 3D slicer as a medical virtual reality visualization platform},
journal={Progress in Biomedical Optics and Imaging - Proceedings of SPIE},
year={2019},
volume={10951},
doi={10.1117/12.2513053},
art_number={1095113},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068940860&doi=10.1117%2f12.2513053&partnerID=40&md5=b25226a3d9c47c96f02ac28897a156e8},
affiliation={Laboratory for Percutaneous Surgery, School of Computing, Queen's University, Kingston, Canada; Kitware Incorporated, Carrboro, NC, United States},
abstract={PURPOSE: There is a lack of open-source or free virtual reality (VR) software that can be utilized for research by medical professionals and researchers. We propose the design and implementation of such software. We also aim to assess the feasibility of using VR as a modality for navigating 3D visualizations of medical scenes. METHODS: To achieve our goal, we added VR capabilities to the open-source medical image analysis and visualization platform, 3D Slicer. We designed the VR extension by basing the software architecture on VTK's vtkRenderingOpenVR software module. We extended this module by adding features such as full interactivity between 3D Slicer and the VR extension during VR use, variable volume rendering quality based on user headset motion etc. Furthermore, the VR extension was tested in a feasibility study in which participants were asked to complete specific tasks using bot the conventional mouse-monitor and VR method. For this experiment, we used 3D Slicer to create two virtual settings, each having an associated task. Participants were asked to maneuver the virtual settings using two approaches, the conventional method, using mouse and monitor, and VR using the head-mounted-display and controllers. The main outcome measure was total time to complete the task. RESULTS: We developed a VR extension to 3D Slicer-SlicerVirtualReality (SlicerVR). Additionally, from the experiment we conducted we found that when comparing mean completion times, participants, when using VR, were able to complete the first task 3 minutes and 28 seconds quicker than the mouse and monitor method (4 minutes and 24 seconds vs. 7 minutes and 52 seconds, respectively); and the second task 1 minute and 20 seconds quicker (2 minutes and 37 seconds, vs. 3 minutes and 57 seconds, respectively). CONCLUSION: We augmented the 3D Slicer platform with virtual reality capabilities. Experiments results show a considerable improvement in time required to navigate and complete tasks within complex virtual scenes compared to the traditional mouse and monitor method. © 2019 SPIE.},
author_keywords={3D Slicer;  Medical Training;  Open-source;  Procedural Planning;  Segmentation;  Virtual Reality;  Visualization},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lee2019121,
author={Lee, J. and Um, C. and Hwang, S. and Jeong, J.},
title={Container-Based Multi-purpose IoT Architecture for User-Friendly Applications with Cloud Chatbot Agent},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11624 LNCS},
pages={121-134},
doi={10.1007/978-3-030-24311-1_9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068602456&doi=10.1007%2f978-3-030-24311-1_9&partnerID=40&md5=d328d18326c7d39242d1249f8a4fd339},
affiliation={Department of Smart Factory Convergence, Sungkyunkwan University, Suwon, Gyeonggi-do  16419, South Korea},
abstract={IoT is a new era technology that can be used by end users because of its functionality and necessity. Most of IoT devices are aimed at versatile smart devices, and these features need to be conveniently provided to users, such as for use in mobile. In addition, these devices must be able to tailor various functions and purposes to the needs of the user. Currently, open source platform provides flexibility in perspective of the developers in order to enable multi-purpose as a single device in terms of requirements for end users. However, this flexibility should be reconsidered from the end users, too. In this paper, we propose the cloud based multi-purpose IoT and provide convenience to the end user through the chatbot agent for end user friendliness. In addition, container technology is applied for versatility and flexibility of devices. These researches can be useful in multi-purpose robot pendants, protocol conversion genders in factory area, and motor boxes that can convert gears in smart toys situations where change flexibility and affinity are required according to the request of users. © 2019, Springer Nature Switzerland AG.},
author_keywords={Chatbot agent;  Docker;  Internet of Things;  User-Friendly Applications},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Toepke2019143,
author={Toepke, S.L.},
title={Exploring bot pervasiveness in global cities using publicly available volunteered geographic information},
journal={GISTAM 2019 - Proceedings of the 5th International Conference on Geographical Information Systems Theory, Applications and Management},
year={2019},
pages={143-153},
doi={10.5220/0007796701430153},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067483396&doi=10.5220%2f0007796701430153&partnerID=40&md5=19e682abc9cbafe5802d057c33a398b5},
affiliation={Private Engineering Firm, Washington, DC, United States},
abstract={Effective crisis management and response heavily relies on up-to-date and trustworthy information. Near realtime, volunteered geographic information (VGI) has previously been shown to be instrumental during disaster response by helping direct resources, create communication channels between the affected, etc. Trustworthiness continues to be a challenge when leveraging crowd sourced data, as quality information directly impacts the effectiveness of response. Previous research has demonstrated cloud-based VGI collection, storage, presentation, and bot mitigation using open source technologies and freely available web services. Alas, the technology was deployed as a prototype for small urban areas in the United States. This research explores bot pervasiveness in several global cities that have previously suffered a catastrophic event and/or are at risk for a future crisis event. The existence of non-trustworthy information in social media data has always been a known issue, taking steps to quantify the presence of bots in Twitter data can allow an end-user to more holistically understand their dataset. Copyright © 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved},
author_keywords={Bot Detection;  Data Acquisition;  Geographic Information Systems;  Knowledge Extraction;  Translation;  Trustworthiness;  Volunteered Geographic Information},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Daniel2019177,
author={Daniel, G. and Cabot, J. and Deruelle, L. and Derras, M.},
title={Multi-platform Chatbot Modeling and Deployment with the Jarvis Framework},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11483 LNCS},
pages={177-193},
doi={10.1007/978-3-030-21290-2_12},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067359420&doi=10.1007%2f978-3-030-21290-2_12&partnerID=40&md5=636676c2cfac8155b8929d5a2a7985c0},
affiliation={Internet Interdisciplinary Institute (IN3), Universitat Oberta de Catalunya (UOC), Barcelona, Spain; ICREA, Barcelona, Spain; Berger-Levrault, P&#x00E9;rols, France; Berger-Levrault, Lab&#x00E8;ge, France},
abstract={Chatbot applications are increasingly adopted in various domains such as e-commerce or customer services as a direct communication channel between companies and end-users. Multiple frameworks have been developed to ease their definition and deployment. They typically rely on existing cloud infrastructures and artificial intelligence techniques to efficiently process user inputs and extract conversation information. While these frameworks are efficient to design simple chatbot applications, they still require advanced technical knowledge to define complex conversations and interactions. In addition, the deployment of a chatbot application usually requires a deep understanding of the targeted platforms, increasing the development and maintenance costs. In this paper we introduce the Jarvis framework, that tackles these issues by providing a Domain Specific Language (DSL) to define chatbots in a platform-independent way, and a runtime engine that automatically deploys the chatbot application and manages the defined conversation logic. Jarvis is open source and fully available online. &#x00A9; 2019, Springer Nature Switzerland AG.},
author_keywords={Chatbot deployment;  Chatbot design;  DSL;  MDE},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Granda2019102,
author={Granda, J.-L. and Chamba-Eras, L. and Labanda-Jaramillo, M. and Coronel-Romero, E. and Guaman-Quinche, R. and Maldonado-Ortega, C.},
title={OpenChatBotUNL: Proposal for the execution platform of conversational agents [OpenChatBotUNL: Propuesta de plataforma de ejecución de agentes conversacionales]},
journal={RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao},
year={2019},
number={E17},
pages={102-112},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061199912&partnerID=40&md5=37579f8be6411913ef741814b197e591},
affiliation={Grupo de Investigación en Tecnologías de la Información y Comunicación (GITIC), Carrera de Ingeniería en Sistemas, Facultad de Energía, Universidad Nacional de Loja, Av. Pío Jaramillo Alvarado y Reinaldo Espinosa, Loja, EC 110110, Ecuador; Carrera de Ingeniería en Sistemas, Facultad de Energía, Universidad Nacional de Loja, Av. Pío Jaramillo Alvarado y Reinaldo Espinosa, Loja, EC 110110, Ecuador},
abstract={In this work we propose an architecture of execution of Conversational Agents (ChatBots) based on Open Source tools, called OpenChatBotUNL. The proposal integrates various software package on an architecture, such as the XMPP protocol, Openfire, martinbigio/chatterbot, Python ChatterBot, as support for the communication, management, monitoring and artificial intelligence infrastructure. OpenChatBotUNL is proposed as an alternative to implementation and execution platforms (SDKs), available under the Software as a Service modality, representing an opportunity for innovation in the Natural Language Processing research line at universities in Ecuador. © 2019, Associacao Iberica de Sistemas e Tecnologias de Informacao. All rights reserved.},
author_keywords={Artificial intelligence;  ChatBot;  Conversational agent;  Natural language processing;  Open source},
document_type={Article},
source={Scopus},
}

@ARTICLE{D’silva2019115,
author={D’silva, G.M. and Roy, L. and Kunjumon, A. and Khan, A.},
title={Developing a multi-modal transport system by linkage of local public transport with commuter trains using software as a service (SaaS) architecture},
journal={Smart Innovation, Systems and Technologies},
year={2019},
volume={106},
pages={115-123},
doi={10.1007/978-981-13-1742-2_12},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059658884&doi=10.1007%2f978-981-13-1742-2_12&partnerID=40&md5=a4deeee28f224056ae291ea1673b76aa},
affiliation={St. John College of Engineering and Technology, Palghar, India},
abstract={A system needs to be developed to automate the traveling of every individual by unification of Amazon web services public cloud and various open-source technologies like MongoDB for persisting data and data-driven documents (D3.js) for visualization. This system is a multi-modal structure by integrating the commuter trains with local public transport like buses to make traveling swift and regulated. The system will authenticate every user in real time and plan the journey of every commuter from his/her source to the desired destination as per their traveling behavior. This system will notify the commuters via SES (email) and chatbot which is an interactive service platform to keep commuters up to date about their daily travels and other journey related information. Besides users can also directly communicate with the chatbot for any queries or questions related to their travel. The commuters and admin can also visualize their data in the form of real-time graphs from their user accounts or admin page. The commuters will be notified about the real-time availability of trains and buses to set up their journey, thereby making this system more robust and plain sailing. This entire architecture is hosted on a public cloud which will make it more reliable, inexpensive, and easy to scale. © 2019, Springer Nature Singapore Pte Ltd.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={1st International Conference on VR Technologies in Cultural Heritage, VRTCH 2018},
journal={Communications in Computer and Information Science},
year={2019},
volume={904},
page_count={244},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059005529&partnerID=40&md5=0bc4725209b83bfa7e9c6d37f9e8a585},
abstract={The proceedings contain 18 papers. The special focus in this conference is on VR Technologies in Cultural Heritage. The topics include: Automatic Creation of a Virtual/Augmented Gallery Based on User Defined Queries on Online Public Repositories; digital Data, Virtual Tours, and 3D Models Integration Using an Open-Source Platform; appropriate Control Methods for Mobile Virtual Exhibitions; exploring European Cultural Heritage Using Conversational Agents; “I Went to America to See Ancient Italian Paintings”: The Problem of the Re-contextualization of Artworks Uprooted from Their Original Settings; non-physical Painting Restoration in Improved Reality; improving Dissemination and Localization of Cultural Heritage Through Multimedia Maps - The Case of Lipari Island; virtual Assistants for the Cultural Heritage Domain; digital Scanning and Non-destructive Techniques for Size Recovering and Rehabilitating the Structural Performance of Traditional Stuccoes; proposal for an Automated Form Finder System to Deduce the Authentic Morphology of Siirt Cas Houses; towards Preserving Transylvanian Fortified Churches in Virtual Reality; evaluation of Using Mobile Devices for 3D Reconstruction of Cultural Heritage Artifacts; towards a Novel User Satisfaction Modelling for Museum Visit Recommender Systems; DinofelisAR: Users’ Perspective About a Mobile AR Application in Cultural Heritage; Exploring Cultural Heritage Using Augmented Reality Through Google’s Project Tango and ARCore; from Exploration of Virtual Replica to Cultural Immersion Through Natural Gestures.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={8th International Workshop on Spoken Dialogue Systems, IWSDS 2017},
journal={Lecture Notes in Electrical Engineering},
year={2019},
volume={510},
page_count={258},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051788197&partnerID=40&md5=692c577fa9d4a2b131a198413bba7605},
abstract={The proceedings contain 25 papers. The special focus in this conference is on Spoken Dialogue Systems. The topics include: Towards metrics of evaluation of pepper robot as a social companion for the elderly; a social companion and conversational partner for the elderly; adapting a virtual agent to user personality; A conversational dialogue manager for the humanoid Robot ERICA; eliciting positive emotional impact in dialogue response selection; predicting interaction quality in customer service dialogs; direct and mediated interaction with a holocaust survivor; acoustic-prosodic entrainment in multi-party spoken dialogues: Does simple averaging extend existing pair measures properly?; how to find the right voice commands? Semantic priming in task representations; automatic evaluation of chat-oriented dialogue systems using large-scale multi-references; exploring the applicability of elaborateness and indirectness in dialogue management; an open-source dialog system with real-time engagement tracking for job interview training applications; on the applicability of a user satisfaction-based reward for dialogue policy learning; OntoVPA—An ontology-based dialogue management system for virtual personal assistants; regularized neural user model for goal-oriented spoken dialogue systems; yeah, right, uh-huh: A deep learning backchannel predictor; what information should a dialogue system understand?: Collection and analysis of perceived information in chat-oriented dialogue; chunks in multiparty conversation—building blocks for extended social talk; debbie, the debate bot of the future; data-driven dialogue systems for social agents; chaD: Chat-oriented dialog systems; domain complexity and policy learning in task-oriented dialogue systems; single-model multi-domain dialogue management with deep learning.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Pradeepthi2018118,
author={Pradeepthi, K.V. and Kannan, A.},
title={Detection of Botnet traffic by using Neuro-fuzzy based Intrusion Detection},
journal={2018 10th International Conference on Advanced Computing, ICoAC 2018},
year={2018},
pages={118-123},
doi={10.1109/ICoAC44903.2018.8939109},
art_number={8939109},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078034666&doi=10.1109%2fICoAC44903.2018.8939109&partnerID=40&md5=a9baf446efbde156a81090d2402a9dd2},
affiliation={Anna University, Depatrment of Information Science and Technology, Chennai, India},
abstract={The attacks on various networks by intruders is on the rise and one of the most common model for launching attacks is by botnets. It has become very difficult for network administrators to detect and eradicate the bots in their network. Machine learning algorithms are increasingly being used for solving many classification problems including security systems for cloud. In this paper, we propose a new algorithm for the detection of botnet traffic by the use of neuro-fuzzy classification techniques. The dataset for the experimentation purpose was created by setting up an application on Eucalyptus cloud and attacking the application using various open source botnet simulation tools. The system achieved an accuracy of 94.78% with 15,000 instances and 56 attributes. The false positives of the system are considerably reduced when it is compared with the other related systems because of the introduction of the fuzzy rules into the system. © 2018 IEEE.},
author_keywords={botnet detection;  classification;  machine learning;  supervised learning},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={Proceedings of 2018 Learning With MOOCS, LWMOOCS 2018},
journal={Proceedings of 2018 Learning With MOOCS, LWMOOCS 2018},
year={2018},
page_count={181},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058994211&partnerID=40&md5=c9ee046e99430db4bd846e3f4e8b85e8},
abstract={The proceedings contain 41 papers. The topics discussed include: scalable team-based software engineering education via automated systems; design of a conversational agent as an educational tool; the influence of immediate homework feedback on student performance and satisfaction in an engineering MOOC; intention-behavior dynamics in MOOC learning; what happens to good intentions along the way?; a comprehensive MOOC creation approach; making a creative commons MOOC: challenges and opportunities; blending MOOCs into higher education courses - a case study; team-based assignments in MOOCs - user feedback; and the clustering analysis system based on students' motivation and learning behavior.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{vanderStruijk2018159,
author={van der Struijk, S. and Mirzaei, M.S. and Huang, H.-H. and Nishida, T.},
title={Facsvatar: An Open Source Modular Framework for Real-Time FACS based Facial Animation},
journal={Proceedings of the 18th International Conference on Intelligent Virtual Agents, IVA 2018},
year={2018},
pages={159-164},
doi={10.1145/3267851.3267918},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058492365&doi=10.1145%2f3267851.3267918&partnerID=40&md5=9ca91f67fcfb3bc97e78096b30d34033},
affiliation={School of Informatics, Kyoto University, Kyoto, Japan; RIKEN Center for Advanced Intelligence Project Kyoto, Japan},
abstract={Embodied Conversational Agents often employ advanced multi-modal analysis of human users for affective inference, however, its facial expressions in response are often pre-made or coded animations. Generated data-driven facial animations have the advantage that they can be more natural and do not require a database at run-time. The open source modular framework FACSvatar is presented, which processes and animates FACS based data in real-time. Tools that create 3D human models are supported and facial data can be visualized in popular tools in the gaming industry. All functionality is split-up into modules set-up in a publisher-subscriber pattern to provide easy integration with other platforms. A deep learning module for real-time generation of AU data for data-driven animation is implemented. A user evaluation of their expressions being animated through our framework was done. Their ratings were slightly positive, but more improvements have to be made in terms of data quality and individual fine-tuning. Also, the modules’ latency and performance have been measured. On average, FACS data is visualized in 28.55 ms. © 2018 Association for Computing Machinery.},
author_keywords={Animation Generation;  Facial Expression;  FACS;  Virtual Human},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wessel2018,
author={Wessel, M. and De Souza, B.M. and Steinmacher, I. and Wiese, I.S. and Polato, I. and Chaves, A.P. and Gerosa, M.A.},
title={The power of bots: Understanding bots in OSS projects},
journal={Proceedings of the ACM on Human-Computer Interaction},
year={2018},
volume={2},
number={CSCW},
doi={10.1145/3274451},
art_number={182},
note={cited By 34},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064157845&doi=10.1145%2f3274451&partnerID=40&md5=9b136fc43db8f92bbd51f215980b01ba},
affiliation={University of São Paulo, São Paulo, Brazil; Federal University of Technology, Paraná, Campo Mourão, Brazil; Northern Arizona University, Flagsta, AZ, United States},
abstract={Leveraging the pull request model of social coding platforms, Open Source Software (OSS) integrators review developers' contributions, checking aspects like license, code quality, and testability. Some projects use bots to automate predened, sometimes repetitive tasks, thereby assisting integrators' and contributors' work. Our research investigates the usage and impact of such bots. We sampled 351 popular projects from GitHub and found that 93 (26%) use bots. We classied the bots, collected metrics from before and after bot adoption, and surveyed 228 developers and integrators. Our results indicate that bots perform numerous tasks. Although integrators reported that bots are useful for maintenance tasks, we did not nd a consistent, statistically signicant dierence between before and after bot adoption across the analyzed projects in terms of number of comments, commits, changed les, and time to close pull requests. Our survey respondents deem the current bots as not smart enough and provided insights into the bots' relevance for specic tasks, challenges, and potential new features. We discuss some of the raised suggestions and challenges in light of the literature in order to help GitHub bot designers reuse and test ideas and technologies already investigated in other contexts. © 2018 Association for Computing Machinery.},
author_keywords={Automated agents;  Bots;  Chatbots;  Open source software;  Pull request;  Pull-based model},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Angus201843,
author={Angus, D. and Yu, Y. and Vrbik, P. and Back, A. and Wiles, J.},
title={PauseCode: Computational conversation timing analysis},
journal={Proceedings of the 4th Workshop on Multimodal Analyses Enabling Artificial Agents in Human-Machine Interaction, MA3HMI 2018 - In conjunction with ICMI 2018},
year={2018},
pages={43-47},
doi={10.1145/3279972.3279975},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058160648&doi=10.1145%2f3279972.3279975&partnerID=40&md5=45908b21667c195c59e81494a35eecfe},
affiliation={University of Queensland, St Lucia, QLD, Australia},
abstract={Pauses play a critical role in adding, shifting or contradicting meaning in a conversation. To enable the study and incorporation of this important modality in computational discourse analytic and processing systems, we require extensible open source pause coding systems and associated software libraries. We designed and implemented a coding and visualisation system for pause and overlap detection and analysis, extending existing voicing and silence detection algorithms. Demonstrating the system using the TalkBank CallFriend and CallHome corpora we show how the approach can be used to code many different kinds of pauses and overlaps within and between interlocutors, and calculate the temporal distribution of these different types of pause and overlap. The coding schema is intended to be combined with other speech modalities to provide novel approaches to predicting social cues and markers, useful for designing more naturalistic conversational agents, and in new tools for measuring turn-taking structure of conversation in greater depth and accuracy. © 2018 Copyright held by the owner/author(s).},
author_keywords={Conversation;  Discourse;  Discursis;  Pause;  Pragmatics;  Speech;  Talk},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={Conference of Open Innovation Association, FRUCT},
journal={Conference of Open Innovation Association, FRUCT},
year={2018},
volume={2018-May},
page_count={310},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055566287&partnerID=40&md5=806bb64e16e4838acb92361da50d02fb},
abstract={The proceedings contain 41 papers. The topics discussed include: design of cyber-physical production system prototype based on an ethereum private network; DSLR imperfections extraction from image for source detection; survey on deduplication techniques in flash-based storage; analysis of user activity in wireless local area network of petrozavodsk state university; web-service for drive safely system user analysis: architecture and implementation; open source tool for VH-replacement products discovery and analysis; motivate online users by moderating and providing tasty testing experiences.; EvoCut: a new generalization of Albert-BarabaÁsi model for evolution of complex networks; compact fixed-point filter implementation; queuing system for the spacefibre standard; botanicum: a telegram bot for tree classification; data distribution services performance evaluation framework; evaluation of modern laser based indoor SLAM algorithms; deadlock-free routing in spacewire onboard network; network topology transformation for fault tolerance in spacewire onboard networks; measurement of inductance of liquefied natural gas; and unleashing full potential of ansible framework: university labs administration.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Hussain2018698,
author={Hussain, S. and Athula, G.},
title={Extending a conventional chatbot knowledge base to external knowledge source and introducing user based sessions for diabetes education},
journal={Proceedings - 32nd IEEE International Conference on Advanced Information Networking and Applications Workshops, WAINA 2018},
year={2018},
volume={2018-January},
pages={698-703},
doi={10.1109/WAINA.2018.00170},
art_number={8418155},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056269323&doi=10.1109%2fWAINA.2018.00170&partnerID=40&md5=46997eb7f1247166fa05b3d588c3160e},
affiliation={School of Computing, Engineering and Mathematics, Western Sydney University, Sydney, Australia},
abstract={Chatbots or conversational agents are computer programs, which interact with users using natural language through artificial intelligence in a way that the user thinks he is having dialogue with a human. One of the main limit of a chatbot technology is associated to the construction of its local knowledge base. A conventional chatbot knowledge base is typically hand constructed, which is a very time-consuming process and may take years to train a chatbot in a particular field of expertise. This work presented in this paper extends the knowledge base of a conventional chatbot beyond its local knowledge base to external knowledge source Wikipedia. This has been achieved by using Media Wiki API to retrieve information from Wikipedia when the chatbot's local knowledge base does not contain the answer to user query. To make the conversation with chatbot more meaningful with regards to the user's previous chat sessions, a user specific session ability has been added to the chatbot architecture. An open source AIML web based chatbot has been modified and programmed for the use in health informatics domain. The chatbot has been named VDMS-Virtual Diabetes Management System. It is intended to be used by the general community and diabetic patients for diabetes education and management. © 2018 IEEE.},
author_keywords={AIML;  Chatbot;  Conversational Agent;  Diabetes;  VDMS},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Aiken2018797,
author={Aiken, W. and Kim, H.},
title={POSTER: DeepCRACk: Using deep learning to automatically CRack audio CAPTCHAs},
journal={ASIACCS 2018 - Proceedings of the 2018 ACM Asia Conference on Computer and Communications Security},
year={2018},
pages={797-799},
doi={10.1145/3196494.3201581},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049172613&doi=10.1145%2f3196494.3201581&partnerID=40&md5=91c2da890b84d5cd1584d03d70ca8d5b},
affiliation={Sungkyunkwan University, Suwon, South Korea},
abstract={A Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA) is a defensive mechanism designed to differentiate humans and computers to prevent unauthorized use of online services by automated attacks. They often consist of a visual or audio test that humans can perform easily but that bots cannot solve. However, with current machine learning techniques and open-source neural network architectures, it is now possible to create a self-contained system that is able to solve specific CAPTCHA types and outperform some human users. In this paper, we present a neural network that leverages Mozilla's open source implementation of Baidu's Deep Speech architecture; our model is currently able to solve the audio version of an open-source CATPCHA system (named SimpleCaptcha) with 98.8% accuracy. Our network was trained on 100,000 audio samples generated from SimpleCaptcha and can solve new SimpleCaptcha audio tests in 1.25 seconds on average (with a standard deviation of 0.065 seconds). Our implementation seems additionally promising because it does not require a powerful server to function and is robust to adversarial examples that target Deep Speech's pre-trained models. © 2018 Association for Computing Machinery.},
author_keywords={Adversarial machine learning;  CAPTCHA;  Neural networks},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={Proceedings - International Conference on Software Engineering},
journal={Proceedings - International Conference on Software Engineering},
year={2018},
page_count={65},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051666734&partnerID=40&md5=5c4256238b87854e73f8036028b0a1f7},
abstract={The proceedings contain 12 papers. The topics discussed include: the beginning of a cognitive software engineering era with self-managing applications; self-organizing infrastructure for machine (deep) learning at scale; intra-thalamic and thalamocortical connectivity: potential implication for deep learning; safety from ethical hazards: prospects for a contribution from software engineering; learning network flow based on rough set flow graphs and ACO clustering in distributed cognitive environments; enterprise crowd computing for human aided Chatbots; toward truly personal Chatbots: on the development of custom conversational assistants; keeping intelligence under control; toward a practical process model for anomaly detection systems; adaptive rule monitoring system; and smart conversational agents for reminiscence.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={Proceedings - International Conference on Software Engineering},
journal={Proceedings - International Conference on Software Engineering},
year={2018},
volume={Part F137725},
page_count={64},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051169223&partnerID=40&md5=b21c8335cb56693ba5ebc21866b8a461},
abstract={The proceedings contain 8 papers. The topics discussed include: integrating a dialog component into a framework for spoken language understanding; exploring the benefits of utilizing conceptual information in test-to-code traceability; complementing machine learning classifiers via dynamic symbolic execution: human vs. bot generated tweets; CodeCatch: extracting source code snippets from online sources; semi-automatic generation of active ontologies from web forms for intelligent assistants; ways of applying artificial intelligence in software engineering; a replication study: just-in-time defect prediction with ensemble learning; and evaluating the adaptive selection of classifiers for cross-project bug prediction.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={Proceedings - International Conference on Software Engineering},
journal={Proceedings - International Conference on Software Engineering},
year={2018},
volume={Part F137813},
page_count={134},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051192304&partnerID=40&md5=dc3c44df6d32041e8e67f595e5e83f9c},
abstract={The proceedings contain 25 papers. The topics discussed include: a case study of distances in a large co-located software development organization; a collaborative approach to teaching software startups: findings from a study using challenge based learning; a framework for understanding chatbots and their future; an exploratory study for scoping software product lines in a collaborative way; an initial understanding of task interdependence in software engineering: a case study; code review for newcomers: is it different?; context in programming: an investigation of how programmers create context; designing a capability-centric web tool to support agile team composition and task allocation: a work in progress; and how do practitioners perceive assurance cases in safety-critical software systems?.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Beller2018503,
author={Beller, M.},
title={Toward an empirical theory of feedback-driven development},
journal={Proceedings - International Conference on Software Engineering},
year={2018},
pages={503-505},
doi={10.1145/3183440.3190332},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049687731&doi=10.1145%2f3183440.3190332&partnerID=40&md5=58649b5bf992d4baa441adf0b8d64183},
affiliation={Delft University of Technology, Netherlands},
abstract={Software developers today crave for feedback, be it from their peers or even bots in the form of code review, static analysis tools like their compiler, or the local or remote execution of their tests in the Continuous Integration (CI) environment. With the advent of social coding sites like GitHub and tight integration of CI services like Travis CI, software development practices have fundamentally changed. Despite a highly changed software engineering landscape, however, we still lack a suitable description of an individual's contemporary software development practices, that is how an individual code contribution comes to be. Existing descriptions like the v-model are either too coarse-grained to describe an individual contributor's workflow, or only regard a sub-part of the development process like Test-Driven Development. In addition, most existing models are pre-rather than de-scriptive. By contrast, in our thesis, we perform a series of empirical studies to describe the individual constituents of Feedback-Driven Development (FDD) and then compile the evidence into an initial framework on how modern software development works. Our thesis culminates in the finding that feedback loops are the characterizing criterion of contemporary software development. Our model is flexible enough to accommodate a broad bandwidth of contemporary workflows, despite large variances in how projects use and configure parts of FDD. © 2018 ACM.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Urli201895,
author={Urli, S. and Yu, Z. and Seinturier, L. and Monperrus, M.},
title={How to design a program repair bot?: Insights from the repairnator project},
journal={Proceedings - International Conference on Software Engineering},
year={2018},
pages={95-104},
doi={10.1145/3183519.3183540},
note={cited By 36},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049683828&doi=10.1145%2f3183519.3183540&partnerID=40&md5=d05ff74d4c321189a3c9e47d86ef90ac},
affiliation={University of Lille and Inria Lille, France; KTH Royal Institute of Technology, Sweden},
abstract={Program repair research has made tremendous progress over the last few years, and software development bots are now being invented to help developers gain productivity. In this paper, we investigate the concept of a "program repair bot" and present Repairnator. The Repairnator bot is an autonomous agent that constantly monitors test failures, reproduces bugs, and runs program repair tools against each reproduced bug. If a patch is found, Repairnator bot reports it to the developers. At the time of writing, Repairnator uses three different program repair systems and has been operating since February 2017. In total, it has studied 11 523 test failures over 1 609 open-source software projects hosted on GitHub, and has generated patches for 15 different bugs. Over months, we hit a number of hard technical challenges and had to make various design and engineering decisions. This gives us a unique experience in this area. In this paper, we reflect upon Repairnator in order to share this knowledge with the automatic program repair community. © 2018 ACM.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Brown20189,
author={Brown, S.S. and Dibari, N. and Bhatia, S.},
title={I am 'totally' human: Bypassing the recaptcha},
journal={Proceedings - 13th International Conference on Signal-Image Technology and Internet-Based Systems, SITIS 2017},
year={2018},
volume={2018-January},
pages={9-12},
doi={10.1109/SITIS.2017.13},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048883115&doi=10.1109%2fSITIS.2017.13&partnerID=40&md5=d6a83f3137acf57b8630eeb51dcb710c},
affiliation={Department of Computer and Information Science, Fordham University, Bronx, United States; School of Computing, Sacred Heart University, Fairfield, United States},
abstract={In recent years, website administrators have searched for a tool to prevent automated 'bots' from using their sites' resources, hindering legitimate user access. By offering a 'challenge' in the form of analyzing a picture for certain features, matching like symbols from a selection, or listening to an audio clip and transcribing the text, these tasks are intended to be easy for humans to solve but impossible for a program to overcome. More recently, there have been many successful attempts at using modern technology to automate passing these challenges. In this paper, we propose a simple approach which makes use of open-source tools (reCaptcha Widget, Selenium-a proxy server pool and a public Speech to Text API) to circumvent the reCaptcha tool utilized by Google. Preliminary results demonstrate an approximately 35% success rate which can be easily improved with minor modification. However, the focal point is the simplicity of the proposed approach to highlight the vulnerability of Google's reCaptcha tool against Speech to Text API attack. © 2017 IEEE.},
author_keywords={Authentication;  Bots;  Captcha;  Recaptcha;  Security},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Carver2018102,
author={Carver, J.C. and Serebrenik, A.},
title={Software maintenance and evolution and automated software engineering},
journal={IEEE Software},
year={2018},
volume={35},
number={2},
pages={102-104},
doi={10.1109/MS.2018.1661318},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043683289&doi=10.1109%2fMS.2018.1661318&partnerID=40&md5=6fb412a68532f1860d6bd86f8a543926},
affiliation={University of Alabama, United States; Eindhoven University of Technology, Netherlands},
abstract={This issue's column reports on the 33rd International Conference on Software Maintenance and Evolution and 32nd International Conference on Automated Software Engineering. Topics include flaky tests, technical debt, QA bots, and regular expressions. © 1984-2012 IEEE.},
author_keywords={32nd International Conference on Automated Software Engineering;  33rd International Conference on Software Maintenance and Evolution;  ASE 17;  automated software engineering;  flaky tests;  ICSME 17;  Practitioners' Digest;  QA bots;  regexes;  regular expressions;  SATD;  self-admitted technical debt;  software development;  software engineering;  software evolution;  software maintenance;  technical debt},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Pautler2018249,
author={Pautler, D. and Ramanarayanan, V. and Cofino, K. and Lange, P. and Suendermann-Oeft, D.},
title={Leveraging multimodal dialog technology for the design of automated and interactive student agents for teacher training},
journal={SIGDIAL 2018 - 19th Annual Meeting of the Special Interest Group on Discourse and Dialogue - Proceedings of the Conference},
year={2018},
pages={249-252},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091560269&partnerID=40&md5=98262ceaa2d6e4f5f03898f23bd56383},
affiliation={Educational Testing Service R&D, 90 New Montgomery St, San Francisco, CA, United States},
abstract={We present a paradigm for interactive teacher training that leverages multimodal dialog technology to puppeteer custom-designed embodied conversational agents (ECAs) in student roles. We used the open-source multimodal dialog system HALEF to implement a small-group classroom math discussion involving Venn diagrams where a human teacher candidate has to interact with two student ECAs whose actions are controlled by the dialog system. Such an automated paradigm has the potential to be extended and scaled to a wide range of interactive simulation scenarios in education, medicine, and business where group interaction training is essential. © 2018 Association for Computational Linguistics},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sedoc201842,
author={Sedoc, J. and Ippolito, D. and Kirubarajan, A. and Thirani, J. and Ungar, L. and Callison-Burch, C.},
title={ChatEval: A tool for the systematic evaluation of chatbots},
journal={2IS and NLG 2018 - Workshop on Intelligent Interactive Systems and Language Generation, Proceedings of the Workshop},
year={2018},
pages={42-44},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082478318&partnerID=40&md5=c5d48ceba0332d1e658aed2fa5697c73},
affiliation={University of Pennsylvania, United States},
abstract={Open-domain dialog systems are difficult to evaluate. The current best practice for analyzing and comparing these dialog systems is the use of human judgments. However, the lack of standardization in evaluation procedures, and the fact that model parameters and code are rarely published hinder systematic human evaluation experiments. We introduce a unified framework for human evaluation of chatbots that augments existing chatbot tools, and provides a web-based hub for researchers to share and compare their dialog systems. Researchers can submit their trained models to the ChatEval web interface and obtain comparisons with baselines and prior work. The evaluation code is open-source to ensure evaluation is performed in a standardized and transparent way. In addition, we introduce open-source baseline models and evaluation datasets. ChatEval can be found at https://chateval.org. © 2018 Association for Computational Linguistics},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sokhin2018284,
author={Sokhin, T. and Butakov, N.},
title={Semi-automatic sentiment analysis based on topic modeling},
journal={Procedia Computer Science},
year={2018},
volume={136},
pages={284-292},
doi={10.1016/j.procs.2018.08.286},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062548644&doi=10.1016%2fj.procs.2018.08.286&partnerID=40&md5=18feb13f6469884babd3a8f12c74568d},
affiliation={ITMO University, 49 Kronverksky Pr, St. Petersburg, 197101, Russian Federation},
abstract={Sentiment is an important feature of natural language. It is used to understand semantic of texts and opinion of people. There are many practical applications, which require to extract sentiment from texts: advertising analytics, interactive chat bots, opinion mining. Today, different supervised techniques are used to extract sentiment from texts which require large manually labeled datasets that are expensive and time consuming to build. Moreover, such datasets should cover vocabularies and patterns of use of different contexts. Additionally, the efficiency of supervised methods trained on a well-written texts can dramatically decrease on users' texts from social media due to typos, slang, short length of sentences. To solve these problems and to reduce human involvement, we propose semi-supervised sentiment analysis method based on topic modeling with Additive Regularization. To evaluate the efficiency of this method we applied it to several open-source datasets for which sentiment labels are available. The study shows promising results in terms of f1-score with minimal human involvement. © 2018 The Author(s).},
author_keywords={ARTM;  Semi-supervised learning;  Sentiment analysis;  Topic modeling},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Toepke2018663,
author={Toepke, S.L.},
title={Leveraging elasticsearch and botometer to explore volunteered geographic information},
journal={Proceedings of the International ISCRAM Conference},
year={2018},
volume={2018-May},
pages={663-676},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060702457&partnerID=40&md5=33fb5fab9ca94b5cb137b94bc4d6743a},
affiliation={Private Engineering Firm, United States},
abstract={In the past year, numerous weather-related disasters have continued to display the critical importance of crisis management and response. Volunteered geographic information (VGI) has been previously shown to provide illumination during all parts of the disaster timeline. Alas, for a geospatial area, the amount of data provided can cause information overload, and be difficult to process/visualize. This work presents a set of open-source tools that can be easily configured, deployed and maintained, to leverage data from Twitter’s streaming service. The user interface presents data in near real-time, and allows for dynamic queries, visualizations, maps and dashboards. Another VGI challenge is quantifying trustworthiness of the data. The presented work shows integration of a Twitter-bot assessment service, which uses several heuristics to determine the bot-ness of a Twitter account. Architecture is described, Twitter data from a major metropolitan area is explored using the tools, and conclusions/follow-on work are discussed. © Information Systems for Crisis Response and Management ISCRAM. All rights reserved.},
author_keywords={Botometer.;  Crisis Management;  Elasticsearch;  Response;  Social Media;  Volunteered Geographic Information},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gopinathan2018227,
author={Gopinathan, K. and Kaloumenos, N.A. and Ajmera, K. and Matei, A. and Williams, I. and Davis, A.},
title={FHIR FLI: An open source platform for storing, sharing and analysing lifestyle data},
journal={ICT4AWE 2018 - Proceedings of the 4th International Conference on Information and Communication Technologies for Ageing Well and e-Health},
year={2018},
volume={2018-March},
pages={227-233},
doi={10.5220/0006791302270233},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051944325&doi=10.5220%2f0006791302270233&partnerID=40&md5=1de0186dd6f35b48f4f575afaa052927},
affiliation={University College London, United Kingdom; Nuffield Health, United Kingdom},
abstract={Consumers and healthcare organisations alike are increasingly interested in using digital health solutions to reduce the risk of chronic conditions or to help manage these conditions outside hospitals. Equally, there is a strong public health benefit in helping individuals adopt and improve healthy lifestyle behaviours. The first step in this direction is the ability to record and analyse lifestyle data. Currently, lifestyle logging platforms use proprietary data formats. Data is segregated among different platforms, impacting consumers, service providers, research institutes and public health bodies. Our aim is to facilitate the transfer of information between individuals and organisations that hold or require their lifestyle data. We demonstrate that an open source platform based on a clinically recognised interoperability standard - Fast Healthcare Interoperability Resources (FHIR) - can meet both consumers and industry needs. We use as an example the case of people managing arthritis. Our contributions are: (i) an extension of the FHIR standard for lifestyle data, (ii) a reference architecture for a Personal Lifestyle Record, (iii) integration with voice-enabled digital assistants for lifestyle data capture and (iv) an open source implementation of this architecture that retrieves, saves and analyses lifestyle data from wearable devices. Copyright © 2018 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
author_keywords={FHIR;  Lifestyle Data;  Personal Health Record},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={CEUR Workshop Proceedings},
journal={CEUR Workshop Proceedings},
year={2018},
volume={2075},
page_count={250},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045432027&partnerID=40&md5=065c142a3a91f8b57173f8ad49bb552e},
abstract={The proceedings contain 35 papers. The topics discussed include: how to deal with inaccurate service requirements? insights in our current approach and new ideas; requirements quality defect detection with the Qualicen requirements scout; CORDULA: software requirements extraction utilizing Chatbot as communication interface; research on NLP for RE at CNR-ISTI: a report; back to basics: extracting software requirements with a syntactic approach; research on NLP for RE at Fraunhofer FKIE: a report on grouping requirements; which semantics for requirements engineering: from shallow to deep; knowledge representation of requirements documents using natural language processing; is there really a need for using NLP to elicit requirements? a benchmarking study to assess scalability of manual analysis; managing multi-lingual user feedback: the SUPERSEDE project experience; educating for empathy in software engineering course; requirements-driven supervision of socio-technical systems; analysis of requirement problems regarding their causes and effects for projects with the objective to model qualitative PRIS empirical study; towards a systematic approach for designing gamification for RE; the interactive narrator tool: effective requirements exploration and discussion through visualization; and tool support for value modeling and risk analysis of e-services.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={5th International Symposium on Data Mining Applications, SDMA 2018},
journal={Advances in Intelligent Systems and Computing},
year={2018},
volume={753},
page_count={245},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045275457&partnerID=40&md5=a507f10f29962d3808f09854c543c565},
abstract={The proceedings contain 18 papers. The special focus in this conference is on Data Mining Applications. The topics include: Comparative analysis of danger theory variants in measuring risk level for text spam messages; analyzing user behaviors: A study of tips in foursquare; classification of customer tweets using big data analytics; evolution of hashtags on twitter: A case study from events groups; investments in deep learning techniques for improving the biometric system accuracy; new feature extraction approach based on adaptive fuzzy systems for reliable biometric identification; An efficient PHSW-DC algorithm for solving motif finding problem in TP53 cancer gene; the effect of vitamin B12 deficiency on blood count using data mining; analysis of traffic accident in riyadh using clustering algorithms; support of Existing Chatbot Development Framework for Arabic Language: A Brief Survey; the Generative Power of Arabic Morphology and Implications: A case for pattern orientation in arabic corpus annotation and a proposed pattern ontology; A benchmark collection for mapping program educational objectives to ABET student outcomes: Accreditation; bug reports evolution in open source systems; analysis of Call Detail Records for Understanding Users Behavior and Anomaly Detection Using Neo4j; empirical analysis of static code metrics for predicting risk scores in android applications; toward stream analysis of software debugging data.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Augello2018236,
author={Augello, A. and Gentile, M. and Dignum, F.},
title={An Overview of Open-Source Chatbots Social Skills},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10750 LNCS},
pages={236-248},
doi={10.1007/978-3-319-77547-0_18},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044462662&doi=10.1007%2f978-3-319-77547-0_18&partnerID=40&md5=ac3879ac09c4c6328263a0d539e7a153},
affiliation={ICAR - National Research Council of Italy, Via Ugo La Malfa 153, Palermo, 90146, Italy; ITD - National Research Council of Italy, Via Ugo La Malfa 153, Palermo, 90146, Italy; Utrecht University, Princetonplein 5, De Uithof, Utrecht, 3584 CC, Netherlands},
abstract={This paper aims to analyze and compare some of the most known open source chatbot technologies focusing on their potential to model a conversational agent able to show a form of “social intelligence”. The main features and drawbacks of each system will be examined. Then, we will discuss their flexibility to produce more realistic social conversational scenarios adopting as the reference the social practice theory. © 2018, Springer International Publishing AG, part of Springer Nature.},
author_keywords={Chatbots;  Conversational agents;  Social practices},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={4th International Conference on Internet Science, INSCI 2017 co-located with IFIN, DATA ECONOMY, DSI, and CONVERSATIONS 2017},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10750 LNCS},
page_count={165},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044442665&partnerID=40&md5=4cad6ed8ebfc8e32add93c9052e13779},
abstract={The proceedings contain 18 papers. The special focus in this conference is on. The topics include: The Case for Collaborative Policy Experimentation Using Advanced Geospatial Data Analytics and Visualisation; an Engagement-Related Behaviour Change Approach for SavingFood in Greece; developing a Social Innovation Methodology in the Web 2.0 Era; code Hunting Games: A Mixed Reality Multiplayer Treasure Hunt Through a Conversational Interface; politician – An Imitation Game; Towards Open Domain Chatbots—A GRU Architecture for Data Driven Conversations; creating Dialogues Using Argumentation and Social Practices; an Overview of Open-Source Chatbots Social Skills; technology Adoption and Social Innovation: Assessing an Online Financial Awareness Platform; aalto Observatory on Digital Valuation Systems: A Position Paper; a Novel Lexicon-Based Approach in Determining Sentiment in Financial Data Using Learning Automata; a Hybrid Recommendation System Based on Density-Based Clustering; computing Platform for Virtual Economic Activities Index; data Based Stock Portfolio Construction Using Computational Intelligence; yourDataStories: Transparency and Corruption Fighting Through Data Interlinking and Visual Exploration; the Maker Movement and the Disruption of the Producer-Consumer Relation.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={17th International Conference on Web Engineering, ICWE 2017},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10544 LNCS},
page_count={271},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042790395&partnerID=40&md5=70d5f57b6266ff65a56d9cd68911721f},
abstract={The proceedings contain 26 papers. The special focus in this conference is on Web Engineering. The topics include: Towards an Acceptance Testing Approach for Internet of Things Systems; ABC Algorithm for URL Extraction; Towards a UML and IFML Mapping to GraphQL; accessing Government Open Data Through Chatbots; using Ontologies for Official Statistics: The Istat Experience; ontology Population from Raw Text Corpus for Open-Source Intelligence; named Entity Recognition in Twitter Using Images and Text; online Expectation Maximization for Language Characterization of Streaming Text; analysing Cultural Events on Twitter; semantic Discovery in the Web of Things; harvesting Knowledge from Social Networks: Extracting Typed Relationships Among Entities; novel Comment Spam Filtering Method on Youtube: Sentiment Analysis and Personality Recognition; mining Communication Data in a Music Community: A Preliminary Analysis; measuring Personal Branding in Social Media: Towards an Influence Indication Score; big Web Data: Warehousing and Analytics: Recent Trends and Future Challenges; model-Based Development of JavaScript Web Applications; Liquid Web Applications: ICWE2017 Tutorial; challenges When Moving from Monolith to Microservice Architecture; IoT Application Deployment Using Request-Response Pattern with MQTT; wireless Brain-Computer Interface for Wheelchair Control by Using Fast Machine Learning and Real-Time Hyper-Dimensional Classification; case Study: Building a Serverless Messenger Chatbot; four Key Factors to Design a Web of Things Architecture; liquid Transfer of User Identity; engineering Task-Automation Systems for Domain Specificity.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Cabot2018154,
author={Cabot, J. and Clarisó, R. and Brambilla, M. and Gérard, S.},
title={Cognifying Model-Driven Software Engineering},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10748 LNCS},
pages={154-160},
doi={10.1007/978-3-319-74730-9_13},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042643413&doi=10.1007%2f978-3-319-74730-9_13&partnerID=40&md5=dd5f4fc3dcfcf5d408fed0d45b83bc51},
affiliation={ICREA, Barcelona, Spain; Universitat Oberta de Catalunya, Barcelona, Spain; Politecnico di Milano, Milan, Italy; CEA List, Palaiseau, France},
abstract={The limited adoption of Model-Driven Software Engineering (MDSE) is due to a variety of social and technical factors, which can be summarized in one: its (real or perceived) benefits do not outweigh its costs. In this vision paper we argue that the cognification of MDSE has the potential to reverse this situation. Cognification is the application of knowledge (inferred from large volumes of information, artificial intelligence or collective intelligence) to boost the performance and impact of a process. We discuss the opportunities and challenges of cognifying MDSE tasks and we describe some potential scenarios where cognification can bring quantifiable and perceivable advantages. And conversely, we also discuss how MDSE techniques themselves can help in the improvement of AI, Machine learning, bot generation and other cognification techniques. © Springer International Publishing AG 2018.},
author_keywords={AI;  Bot;  Machine learning;  Model;  Model-driven},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Khanna2018305,
author={Khanna, A. and Akshay and Garg, A. and Bhalla, A.},
title={Designing natural language processing systems with quickscript as a platform},
journal={Advances in Intelligent Systems and Computing},
year={2018},
volume={564},
pages={305-312},
doi={10.1007/978-981-10-6875-1_30},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042352635&doi=10.1007%2f978-981-10-6875-1_30&partnerID=40&md5=336e19cca0a5f4d0c033c0fea4e8ecba},
affiliation={School of Computer Sciences, Chitkara University, Chandigarh-Patiala National Highway (NH-64)Punjab  140401, India},
abstract={Chatbots are the most prolific examples of Natural Language Processing systems. These are computer software which can talk to users in natural language (via written and/or verbal methods). Like all other programs, these are also designed by computer programmers who are sometimes called “botmasters.” There are some languages and development tools that are used to create chatbots, and QuickScript is one such platform. We started the development of QuickScript as an open-source platform for creating artificial conversational agents, with an intention to generate wider interest in the field of Natural Language Processing (NLP) and chatbot designing. The power of QuickScript is its simplicity and minimalism. QuickScript is relatively fundamental software with which one can design a chatbot in no time, without memorizing a lot of syntaxes and just paying attention to basic query-and-reply pairs. This paper will focus its discussion on introduction to the QuickScript project and using QuickScript for working with natural language systems. © Springer Nature Singapore Pte Ltd. 2018.},
author_keywords={Artificial intelligence;  Chatbot;  Human–computer interaction;  Natural language processing;  QuickScript},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hajjdiab20171,
author={Hajjdiab, H. and Ghazal, M. and Khalil, A.},
title={Random image matching CAPTCHA system},
journal={Electronic Letters on Computer Vision and Image Analysis},
year={2017},
volume={16},
number={3},
pages={1-13},
doi={10.5565/rev/elcvia.1036},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049051627&doi=10.5565%2frev%2felcvia.1036&partnerID=40&md5=5f3c90aa69124c0161b493302e7c7e07},
affiliation={Department of Computer Science and Information Technology, Abu dhabi University, Abu Dhabi City, United Arab Emirates; Department of Electrical and Computer Engineering, Abu Dhabi City, United Arab Emirates},
abstract={Online security risks is an important issue and caught the attention of researchers in the area of networks, web development, human computer interaction and software engineering. One main challenge for online systems is to identify whether the users are humans or software robots (bots). While it is natural to provide service to human users, providing service for software robots (bots) comes with many security risks and challenges. Software robots are often used by spammers to create fake online accounts, affect search engine ranking, take part in on-line polls, send out spam or simply waste the resources of the server. In this paper we introduce a visual CAPTCHA technique that is based on generating random images by the computer, the user is then asked to match a feature point between two images (i.e. solve the correspondence problem as defined by the researchers in the computer vision area). The relationship between the two images is based on a randomly generated homography transformation function. The main advantage of our approach compared to other visual CAPTCHA techniques is that we eliminate the need for a database of images while retaining ease of use. © 2017 Universitat Autonoma de Barcelona.},
author_keywords={CAPTCHA;  Computer vision;  Image matching;  Internet security},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Tian2017153,
author={Tian, Y. and Thung, F. and Sharma, A. and Lo, D.},
title={APIBot: Question answering bot for API documentation},
journal={ASE 2017 - Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering},
year={2017},
pages={153-158},
doi={10.1109/ASE.2017.8115628},
art_number={8115628},
note={cited By 17},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041445342&doi=10.1109%2fASE.2017.8115628&partnerID=40&md5=f2f7b22aee5df7fa6d7103ada05a5b0a},
affiliation={School of Information Systems, Singapore Management University, Singapore},
abstract={As the carrier of Application Programming Interfaces (APIs) knowledge, API documentation plays a crucial role in how developers learn and use an API. It is also a valuable information resource for answering API-related questions, especially when developers cannot find reliable answers to their questions online/offline. However, finding answers to API-related questions from API documentation might not be easy because one may have to manually go through multiple pages before reaching the relevant page, and then read and understand the information inside the relevant page to figure out the answers. To deal with this challenge, we develop APIBot, a bot that can answer API questions given API documentation as an input. APIBot is built on top of SiriusQA, the QA system from Sirius, a state of the art intelligent personal assistant. To make SiriusQA work well under software engineering scenario, we make several modifications over SiriusQA by injecting domain specific knowledge. We evaluate APIBot on 92 API questions, answers of which are known to be present in Java 8 documentation. Our experiment shows that APIBot can achieve a Hit@5 score of 0.706. © 2017 IEEE.},
author_keywords={API Documentation;  Bot;  Question Answering},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Justesen2017162,
author={Justesen, N. and Risi, S.},
title={Learning macromanagement in starcraft from replays using deep learning},
journal={2017 IEEE Conference on Computational Intelligence and Games, CIG 2017},
year={2017},
pages={162-169},
doi={10.1109/CIG.2017.8080430},
art_number={8080430},
note={cited By 32},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040008192&doi=10.1109%2fCIG.2017.8080430&partnerID=40&md5=f9505dc6c4eee51794da6dd8d6d79082},
affiliation={IT University of Copenhagen, Copenhagen, Denmark},
abstract={The real-time strategy game StarCraft has proven to be a challenging environment for artificial intelligence techniques, and as a result, current state-of-the-art solutions consist of numerous hand-crafted modules. In this paper, we show how macromanagement decisions in StarCraft can be learned directly from game replays using deep learning. Neural networks are trained on 789,571 state-action pairs extracted from 2,005 replays of highly skilled players, achieving top-1 and top-3 error rates of 54.6% and 22.9% in predicting the next build action. By integrating the trained network into UAlbertaBot, an open source StarCraft bot, the system can significantly outperform the game's built-in Terran bot, and play competitively against UAlbertaBot with a fixed rush strategy. To our knowledge, this is the first time macromanagement tasks are learned directly from replays in StarCraft. While the best hand-crafted strategies are still the state-of-the-art, the deep network approach is able to express a wide range of different strategies and thus improving the network's performance further with deep reinforcement learning is an immediately promising avenue for future research. Ultimately this approach could lead to strong StarCraft bots that are less reliant on hard-coded strategies. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lee2017677,
author={Lee, C.-S. and Wang, M.-H. and Yang, S.-C. and Hung, P.-H. and Lin, S.-W. and Shuo, N. and Kubota, N. and Chou, C.-H. and Chou, P.-C. and Kao, C.-H.},
title={FML-based Dynamic Assessment Agent for Human-Machine Cooperative System on Game of Go},
journal={International Journal of Uncertainty, Fuzziness and Knowlege-Based Systems},
year={2017},
volume={25},
number={5},
pages={677-705},
doi={10.1142/S0218488517500295},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028932070&doi=10.1142%2fS0218488517500295&partnerID=40&md5=c2903237f5eacf29e607f9df266dc19e},
affiliation={Department of Computer Science and Information Engineering, National University of Tainan, Tainan, Taiwan; Department of Education, National University of Tainan, Tainan, Taiwan; Dept. of System Design, Tokyo Metropolitan University, Japan; Haifong Weiqi Academy, Taiwan},
abstract={In this paper, we demonstrate the application of Fuzzy Markup Language (FML) to construct an FML-based Dynamic Assessment Agent (FDAA), and we present an FML-based Human-Machine Cooperative System (FHMCS) for the game of Go. The proposed FDAA comprises an intelligent decision-making and learning mechanism, an intelligent game bot, a proximal development agent, and an intelligent agent. The intelligent game bot is based on the open-source code of Facebook's Darkforest, and it features a representational state transfer application programming interface mechanism. The proximal development agent contains a dynamic assessment mechanism, a GoSocket mechanism, and an FML engine with a fuzzy knowledge base and rule base. The intelligent agent contains a GoSocket engine and a summarization agent that is based on the estimated win rate, real-time simulation number, and matching degree of predicted moves. Additionally, the FML for player performance evaluation and linguistic descriptions for game results commentary are presented. We experimentally verify and validate the performance of the FDAA and variants of the FHMCS by testing five games in 2016 and 60 games of Google's Master Go, a new version of the AlphaGo program, in January 2017. The experimental results demonstrate that the proposed FDAA can work effectively for Go applications. © 2017 World Scientific Publishing Company.},
author_keywords={decision support engine;  FAIR darkforest Go engine;  Fuzzy markup language;  prediction agent;  robot engine},
document_type={Article},
source={Scopus},
}

@ARTICLE{Carr2017701,
author={Carr, S.A. and Logozzo, F. and Payer, M.},
title={Automatic Contract Insertion with CCBot},
journal={IEEE Transactions on Software Engineering},
year={2017},
volume={43},
number={8},
pages={701-714},
doi={10.1109/TSE.2016.2625248},
art_number={7736073},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029589253&doi=10.1109%2fTSE.2016.2625248&partnerID=40&md5=f186abdb4307dd53937ed6fa7c1f48c9},
affiliation={Purdue University, West Lafayette, IN  47907, United States; FaceBook, Seattle, WA  98109, United States},
abstract={Existing static analysis tools require significant programmer effort. On large code bases, static analysis tools produce thousands of warnings. It is unrealistic to expect users to review such a massive list and to manually make changes for each warning. To address this issue we propose CCBot (short for CodeContracts Bot), a new tool that applies the results of static analysis to existing code through automatic code transformation. Specifically, CCBot instruments the code with method preconditions, postconditions, and object invariants which detect faults at runtime or statically using a static contract checker. The only configuration the programmer needs to perform is to give CCBot the file paths to code she wants instrumented. This allows the programmer to adopt contract-based static analysis with little effort. CCBot's instrumented version of the code is guaranteed to compile if the original code did. This guarantee means the programmer can deploy or test the instrumented code immediately without additional manual effort. The inserted contracts can detect common errors such as null pointer dereferences and out-of-bounds array accesses. CCBot is a robust large-scale tool with an open-source C# implementation. We have tested it on real world projects with tens of thousands of lines of code. We discuss several projects as case studies, highlighting undiscovered bugs found by CCBot, including 22 new contracts that were accepted by the project authors. © 1976-2012 IEEE.},
author_keywords={assertions;  automated patching;  class invariants;  Contract-based verification},
document_type={Article},
source={Scopus},
}

@BOOK{Baker2017141,
author={Baker, M.J. and Détienne, F. and Barcellini, F.},
title={Argumentation and conflict management in online epistemic communities: A narrative approach to wikipedia debates},
journal={Interpersonal Argumentation in Educational and Professional Contexts},
year={2017},
pages={141-157},
doi={10.1007/978-3-319-59084-4_7},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052138281&doi=10.1007%2f978-3-319-59084-4_7&partnerID=40&md5=5144c1a71be6d773868a6cbf0ce6e778},
affiliation={Institut Interdisciplinaire de l'Innovation, Centre National de la Recherche Scientifique and Telecom ParisTech, Paris, France; Conservatoire National des Arts et Métiers, Paris, France},
abstract={With the rise of Internet-based technologies, new web-based communities of practice have emerged, that we term online epistemic communities, or "OECs", whose raison d'être is the co-creation of knowledge objects such as open-source programming languages or encyclopædias (for example, Wikipedia). In this chapter we focus on the case of Wikipedia, where general public participation has recently grown very quickly, in part due to egalitarian principles that encourage free participation by everyone. However, widespread participation, coupled with the principle of neutrality of viewpoint, has led to "editing wars" (repeated text deletions and "reverts", now largely controlled by "(ro)bots"). The nature of participation has tended to change over time, with a migration of conflicts to discussion pages, especially in the case of articles on contentious issues (e.g. "The Turin Shroud"). Our aim is to describe the characteristics of such OEC debates, in relation to their contexts and potential for effective knowledge elaboration. We describe an approach to studying argumentation practices in OECs based on articulating third-person (researcher) analyses, based on a pragma-dialectic model extended to include dimensions of knowledge elaboration and interpersonal relations, with a first-person (participant) perspective, where key contributors to controversial articles produced narratives on their 'life cycles'. On the basis of two case-study discussions we show that although debates are mostly epistemic, concerning article content and structure, the possibilities of anonymity and completely open participation also lead to disputes on an interpersonal (ad hominem) level, concerning expertise. We conclude with prospects for rendering OEC debates more constructive and productive. © Springer International Publishing AG 2017.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Justesen2017187,
author={Justesen, N. and Risi, S.},
title={Continual online evolutionary planning for in-game build order adaptation in starcraft},
journal={GECCO 2017 - Proceedings of the 2017 Genetic and Evolutionary Computation Conference},
year={2017},
pages={187-194},
doi={10.114S/3071178.3071210},
note={cited By 24},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026384177&doi=10.114S%2f3071178.3071210&partnerID=40&md5=941fb0ff90250f600005a4aa01840c5c},
affiliation={IT University of Copenhagen, Denmark},
abstract={The real-time strategy game StarCraft has become an important benchmark for AI research as it poses a complex environment with numerous challenges. An important strategic aspect in this game is to decide what buildings and units to produce. StarCraft bots playing in AI competitions today are only able to switch between predefined strategies, which makes it hard to adapt to new situations. This paper introduces an evolutionary-based method to overcome this challenge, called Continual Online Evolutionary Planning (COEP), which is able to perform in-game adaptive build-order planning. COEP was added to an open source StarCraft bot called UAlbertaBot and is able to outperform the built-in bots in the game as well as being competitive against a number of scripted opening strategies. The COEP augmented bot can change its build order dynamically and quickly adapt to the opponent's strategy. © 2017 ACM.},
author_keywords={Evolutionary Algorithms;  Game AI;  Online Evolution;  StarCraft},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Beschastnikh201735,
author={Beschastnikh, I. and Lungu, M.F. and Zhuang, Y.},
title={Accelerating software engineering research adoption with analysis bots},
journal={Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: New Ideas and Emerging Results Track, ICSE-NIER 2017},
year={2017},
pages={35-38},
doi={10.1109/ICSE-NIER.2017.17},
art_number={7966875},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026768019&doi=10.1109%2fICSE-NIER.2017.17&partnerID=40&md5=ca707870f8cc5f3ccb6c4b6d540ac95c},
affiliation={University of British Columbia, Canada; University of Groningen, Netherlands; University of Colorado, Colorado Springs, CO, United States},
abstract={An important part of software engineering (SE) research is to develop new analysis techniques and to integrate these techniques into software development practice. However, since access to developers is non-trivial and research tool adoption is slow, new analyses are typically evaluated as follows: A prototype tool that embeds the analysis is implemented, a set of projects is identified, their revisions are selected, and the tool is run in a controlled environment, rarely involving the developers of the software. As a result, research artifacts are brittle and it is unclear if an analysis tool would actually be adopted. In this paper, we envision harnessing the rich interfaces provided by popular social coding platforms for automated deployment and evaluation of SE research analysis. We propose that SE analyses can be deployed as analysis bots. We focus on two specific benefits of such an approach: (1) analysis bots can help evaluate analysis techniques in a less controlled, and more realistic context, and (2) analysis bots provide an interface for developers to 'subscribe' to new research techniques without needing to trust the implementation, the developer of the new tool, or to install the analysis tool locally. We outline basic requirements for an analysis bots platform, and present research challenges that would need to be resolved for bots to flourish. © 2017 IEEE.},
author_keywords={research tool adoption;  software analysis;  software engineering research evaluation;  software engineering tools},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: New Ideas and Emerging Results Track, ICSE-NIER 2017},
journal={Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: New Ideas and Emerging Results Track, ICSE-NIER 2017},
year={2017},
page_count={76},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026738738&partnerID=40&md5=4a619db0e289c5dd3a7b84afa438e8a8},
abstract={The proceedings contain 14 papers. The topics discussed include: performance metamorphic testing: motivation and challenges; anger and its direction in collaborative software development; DevOps in regulated software development: case medical devices; at the end of synthesis: narrowing program candidates; production-driven patch generation; statistical learning for inference between implementations and documentation; GuideAutomator: continuous delivery of end user documentation; accelerating software engineering research adoption with analysis bots; and on accelerating ultra-large-scale mining.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={ACM International Conference Proceeding Series},
journal={ACM International Conference Proceeding Series},
year={2017},
volume={Part F129475},
page_count={273},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028315786&partnerID=40&md5=0de824cc2ae18fe50be5dcb2e37d6824},
abstract={The proceedings contain 35 papers. The topics discussed include: towards easier visualization of linked data for lay users; large-scale storage and query processing for semantic sensor data; exploring lurking behaviors in online social networks; knowledge extraction from on-line open source bug tracking systems to predict bug-fixing time; a time series classification approach to game Bot detection; evolutionary mining of relaxed dependencies from big data collections; HERMEVENT: a news collection for emerging-event detection; querying and searching the deep web; on the SPARQL metamodeling semantics entailment regime for OWL 2 QL ontologies; semantic technology for open data publishing; efficient top-k shortest path query processing in sparse graph databases; mitigating linked data quality issues in knowledge-intense information extraction methods; analysis of semantic URLs to support automated linking of structured data on the web; managing road safety through the use of linked data and heat maps; an extended spreading activation technique for hashtag recommendation in microblogging platforms; a real-time twitter sentiment analysis using an unsupervised method; and an innovative majority voting mechanism in interactive social network clustering.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Cocar2017,
author={Cocar, M. and Harris, R. and Khmelevsky, Y.},
title={Utilizing Minecraft bots to optimize game server performance and deployment},
journal={Canadian Conference on Electrical and Computer Engineering},
year={2017},
doi={10.1109/CCECE.2017.7946694},
art_number={7946694},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021801265&doi=10.1109%2fCCECE.2017.7946694&partnerID=40&md5=4110700c24023951aec3ac77172a541d},
affiliation={Computer Science Department, Okanagan College, Kelowna, BC  V1Y 4X8, Canada},
abstract={To simulate a realistic game server environment, we utilized open source software libraries to create automated players (bots) for the globally renowned online game: Minecraft. The fairly simple design of the Minecraft server as well as its massive development and support community facilitates considerable research and analysis prospects. As such, the goal of our investigation was to emulate and then analyze the real-world stress that game-players actively create on hosting servers. We achieved this through creating scripted movements of Minecraft characters that are connected to the Minecraft server(s) hosted within our virtual infrastructure. After this was achieved, we explored altering the methods of running the active Minecraft servers to control CPU load; we primarily explored manually setting the CPU affinity of the Minecraft server thread to run on specific virtual cores. Collecting CPU workload data while the bots were running around on our servers gave us consistent and predictable readings that confirmed the success of our methods we used to control performance. Evidence of this is illustrated through the use of graphs and other experimental data outlined in the body of this document. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Muratore201777,
author={Muratore, L. and Laurenzi, A. and Hoffman, E.M. and Rocchi, A. and Caldwell, D.G. and Tsagarakis, N.G.},
title={XBotCore: A real-time cross-robot software platform},
journal={Proceedings - 2017 1st IEEE International Conference on Robotic Computing, IRC 2017},
year={2017},
pages={77-80},
doi={10.1109/IRC.2017.45},
art_number={7926518},
note={cited By 55},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020221894&doi=10.1109%2fIRC.2017.45&partnerID=40&md5=f5b2fc6c9b5c037d6e12be440f3432e4},
affiliation={Advanced Robotics Department (ADVR), Istituto Italiano di Tecnologia, Genova, Italy; School of Electrical and Electronic Engineering, University of ManchesterM13 9PL, United Kingdom},
abstract={In this work we introduce XBotCore (Cross-Bot-Core), a light-weight, Real-Time (RT) software platform for EtherCAT-based robots. XBotCore is open-source and is designed to be both an RT robot control framework and a software middleware. It satisfies hard RT requirements, while ensuring 1 kHz control loop even in complex Multi-Degree-Of-Freedom systems. It provides a simple and easy-To-use middleware Application Programming Interface (API), for both RT and non-RT control frameworks. This API is completely flexible with respect to the framework a user wants to utilize. Moreover it is possible to reuse the code written using XBotCore API with different robots (cross-robot feature). In this paper, the XBotCore design and architecture will be described and experimental results on the humanoid robot WALK-MAN [17], developed at the Istituto Italiano di Tecnologia (IIT), will be presented. © 2017 IEEE.},
author_keywords={Humanoid robot control;  Real-Time robotics;  Robotic middlewares;  Robotics software architecture;  Software architecture design},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Tian20172660,
author={Tian, Y. and Gong, Q. and Shang, W. and Wu, Y. and Zitnick, C.L.},
title={ELF: An extensive, lightweight and flexible research platform for real-time strategy games},
journal={Advances in Neural Information Processing Systems},
year={2017},
volume={2017-December},
pages={2660-2670},
note={cited By 39},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047016527&partnerID=40&md5=7599405cb44a53c338cf55998d6a62b0},
affiliation={Facebook AI Research, United States; Oculus, United States},
abstract={In this paper, we propose ELF, an Extensive, Lightweight and Flexible platform for fundamental reinforcement learning research. Using ELF, we implement a highly customizable real-time strategy (RTS) engine with three game environments (Mini-RTS, Capture the Flag and Tower Defense). Mini-RTS, as a miniature version of StarCraft, captures key game dynamics and runs at 40K frame-per-second (FPS) per core on a laptop. When coupled with modern reinforcement learning methods, the system can train a full-game bot against built-in AIs end-to-end in one day with 6 CPUs and 1 GPU. In addition, our platform is flexible in terms of environment-agent communication topologies, choices of RL methods, changes in game parameters, and can host existing C/C++-based game environments like ALE [4]. Using ELF, we thoroughly explore training parameters and show that a network with Leaky ReLU [17] and Batch Normalization [11] coupled with long-horizon training and progressive curriculum beats the rule-based built-in AI more than 70% of the time in the full game of Mini-RTS. Strong performance is also achieved on the other two games. In game replays, we show our agents learn interesting strategies. ELF, along with its RL platform, is open sourced at https://github.com/facebookresearch/ELF. © 2017 Neural information processing systems foundation. All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lebeuf201718,
author={Lebeuf, C. and Storey, M.-A. and Zagalsky, A.},
title={Software Bots},
journal={IEEE Software},
year={2017},
volume={35},
number={1},
pages={18-23},
doi={10.1109/MS.2017.4541027},
art_number={8239928},
note={cited By 54},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040311039&doi=10.1109%2fMS.2017.4541027&partnerID=40&md5=653a512a2a464fa818c630b71ac0aa77},
affiliation={Department of Computer Science, University of Victoria, Canada},
abstract={Although the development and widespread adoption of software bots has occurred in just a few years, bots have taken on many diverse tasks and roles. This article discusses current bot technology and presents a practical case study on how to use bots in software engineering. © 1984-2012 IEEE.},
author_keywords={bots;  chatbots;  Slack;  software bots;  software development;  software engineering;  Software Technology},
document_type={Article},
source={Scopus},
}

@ARTICLE{Calvo2017689,
author={Calvo, D. and Quesada, L. and López, G. and Guerrero, L.A.},
title={Multiplatform Career Guidance System Using IBM Watson, Google home and telegram: A user experience and usability evaluation},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10586 LNCS},
pages={689-700},
doi={10.1007/978-3-319-67585-5_67},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031402665&doi=10.1007%2f978-3-319-67585-5_67&partnerID=40&md5=9edc714bc2e0da540f8913e1a05b9340},
affiliation={University of Costa Rica, San José, Costa Rica; Samtec Smart Platform Group, New Albany, IN, United States},
abstract={Even with the availability of several tests to provide clarity in choosing our career path, the decision remains a tough one to undertake. Most of the available tests are either monotonous, resulting in a tedious effort to go through them entirely, or are just plain boring. In this paper, however, we present a new and different approach to career guidance systems. We use Google home as a speech-based interface and Telegram as a text-based interface to generate a conversation between the users and a bot for career guidance. The idea is to provide an easy and friendly interface with an interactive user experience while gathering the required data to provide career guidance. To evaluate the system, we used the University of Costa Rica’s Computer Science and Informatics Department scenario. In this scenario, students must decide between three possible emphases: Software Engineering, Information Technologies, and Computer Science. A usability and user experience evaluation of the system was performed with the participation of 72 freshmen. © 2017, Springer International Publishing AG.},
author_keywords={Career guidance;  Conversational interface;  Google home;  IBM Watson;  Personality traits;  Telegram},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Gomes2017111,
author={Gomes, S. and Dias, J. and Martinho, C.},
title={Iterative parallel sampling RRT for racing car simulation},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10423 LNAI},
pages={111-122},
doi={10.1007/978-3-319-65340-2_10},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028983759&doi=10.1007%2f978-3-319-65340-2_10&partnerID=40&md5=2396c35280446fcb62b6cb4452654e51},
affiliation={INESC-ID and Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal},
abstract={Graphics Processing Units have evolved at a large pace, maintaining a processing power orders of magnitude higher than Central Processing Units. As a result, the interest of using the General-Purpose computing on Graphics Processing Units paradigm has grown. Nowadays, big effort is put to study probabilistic search algorithms like the Randomized Search Algorithms family, which have good time complexity, and thus can be adapted to massive search spaces. One of those algorithms is Rapidly Exploring Random Tree (RRT) which reveals good results when applied to high dimensional dynamical search spaces. This paper proposes a new variant of the RRT algorithm called Iterative Parallel Sampling RRT which explores the use of parallel computation in GPU to generate faster solutions. The algorithm was used to construct a CUDA accelerated bot for the TORCS open source racing game and tested against the plain RRT. Preliminary tests show lap time reductions of around 17% and the potential for reducing search times. © Springer International Publishing AG 2017.},
author_keywords={General-purpose computing on graphics processing units;  Planning;  Randomized search algorithms;  Rapidly-exploring random trees;  The open racing car simulator},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zennaro2017295,
author={Zennaro, M. and Rainone, M. and Pietrosemoli, E.},
title={Radio link planning made easy with a telegram bot},
journal={Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
year={2017},
volume={195 LNICST},
pages={295-304},
doi={10.1007/978-3-319-61949-1_31},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026780594&doi=10.1007%2f978-3-319-61949-1_31&partnerID=40&md5=ed50af410d1030df878f8a43f37984fe},
affiliation={ICTP Telecommunication/ICT4D Lab, Strada Costiera 11, Trieste, Italy; SolviTech, Udine, Italy},
abstract={Traditional radio planning tools present a steep learning curve. We present BotRf, a Telegram Bot that facilitates the process by guiding non-experts in assessing the feasibility of radio links. Built on open source tools, BotRf can run on any smartphone or PC using Telegram. Running it on a smartphone has the added value that the Bot can leverage the internal GPS to capture the current coordinates. BotRf can be used in low bandwidth environments as the generated data traffic is very limited. We present an example of its use in Venezuela. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2017.},
author_keywords={Bots;  Propagation models;  Radio frequency planning;  Simulator;  Telegram;  Terrain profiles},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Dias2017463,
author={Dias, J.P. and Pinto, J.P. and Cruz, J.M.},
title={A hands-on approach on botnets for behavior exploration},
journal={IoTBDS 2017 - Proceedings of the 2nd International Conference on Internet of Things, Big Data and Security},
year={2017},
pages={463-469},
doi={10.5220/0006392404630469},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025131796&doi=10.5220%2f0006392404630469&partnerID=40&md5=c2b3a241a51d4f0bb0b065d113496ebb},
affiliation={Articial Intelligence and Computer Science Laboratory, Faculdade de Engenharia da Universidade do Porto, Paranhos, Portugal; Faculdade de Engenharia da Universidade do Porto, Porto, Portugal},
abstract={A botnet consists of a network of computers that run a special software that allows a third-party to remotely control them. This characteristic presents a major issue regarding security in the Internet. Although common malicious software infect the network with almost immediate visible consequences, there are cases where that software acts stealthy without direct visible effects on the host machine. This is the normal case of botnets. However, not always the bot software is created and used for illicit purposes. There is a need for further exploring the concepts behind botnets and network security. For this purpose, this paper presents and discusses an educational tool that consists of an open-source botnet software kit with built-in functionalities. The tool enables anyone with some computer technical knowledge, to experiment and find out how botnets work and can be changed and adapted to a variety of useful applications, such as introducing and exemplifying security and distributed systems' concepts. Copyright © 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
author_keywords={Botnets;  Computer security;  Distributed systems},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Schatten2017359,
author={Schatten, M. and Okreaša Ðurić, B. and Tomičič, I. and Ivkovič, N.},
title={Automated MMORPG testing – An agent-based approach},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10349 LNCS},
pages={359-363},
doi={10.1007/978-3-319-59930-4_38},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021755847&doi=10.1007%2f978-3-319-59930-4_38&partnerID=40&md5=c6c0f4d52654563a36a8d3f20e624ccd},
affiliation={Artificial Intelligence Laboratory, Faculty of Organization and Informatics, University of Zagreb, Zagreb, Croatia},
abstract={A work-in-progress agent-based framework for automated testing of an open-source massively multi-player on-line role playing game (MMORPG) called The Mana World is presented. The implemented system, in its current state, allows for model-driven development of tests using a graphical user interface (GUI), implementation of automated artificial players (bots) and their use in testing the quests (player tasks) of the game. The system is implemented using Python, SPADE, SWI Prolog and AToM3. © Springer International Publishing AG 2017.},
author_keywords={Agents;  Artificial players;  Automated testing;  Bots;  MMORPG},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Schatten2017246,
author={Schatten, M. and Okreša Ðurić, B. and Tomičić, I. and Ivković, N.},
title={Agents as bots – An initial attempt towards model-driven MMORPG gameplay},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10349 LNCS},
pages={246-258},
doi={10.1007/978-3-319-59930-4_20},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021712181&doi=10.1007%2f978-3-319-59930-4_20&partnerID=40&md5=8495bf650b2a062fb70bddfe88893903},
affiliation={Artificial Intelligence Laboratory, Faculty of Organization and Informatics, University of Zagreb, Zagreb, Croatia},
abstract={Massively multi-player on-line role-playing games (MMO-RPGs) present a large-scale, digital environment that fosters organizational behaviour of players in which multi-agent systems (MASs) can be used for various purposes including but not limited to automated testing, bot detection or analysis of social player behaviour and human – artificial agent interaction. A work-in-progress model-driven MAS development environment for such games is presented. An open-source MMORPG called The Mana World (TMW) is used as an example scenario on which the various components of the system are tested. © Springer International Publishing AG 2017.},
author_keywords={Agent organizations;  Agents;  MMORPG;  Model-driven development},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Kowatsch2017485,
author={Kowatsch, T. and Volland, D. and Shih, I. and Rüegger, D. and Künzler, F. and Barata, F. and Filler, A. and Büchter, D. and Brogle, B. and Heldt, K. and Gindrat, P. and Farpour-Lambert, N. and L’Allemand, D.},
title={Design and evaluation of a mobile chat app for the open source behavioral health intervention platform mobilecoach},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10243 LNCS},
pages={485-489},
doi={10.1007/978-3-319-59144-5_36},
note={cited By 25},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020460132&doi=10.1007%2f978-3-319-59144-5_36&partnerID=40&md5=5d8107f269fac8dcbf86af2cb66fd2cd},
affiliation={Institute of Technology Management, University of St. Gallen, St. Gallen, Switzerland; Department of Management, Technology and Economics, ETH Zurich, Zurich, Switzerland; Energy Efficient Systems Group, University of Bamberg, Bamberg, Germany; Children’s Hospital of Eastern Switzerland, St. Gallen, Switzerland; Fondation SportSmile, Nyon, Switzerland; Department of Community Medicine, Primary Care and Emergency, University Hospital of Geneva/University of Geneva, Geneva, Switzerland},
abstract={The open source platform MobileCoach (mobile-coach.eu) has been used for various behavioral health interventions in the public health context. However, so far, MobileCoach is limited to text message-based interactions. That is, participants use error-prone and laborious text-input fields and have to bear the SMS costs. Moreover, MobileCoach does not provide a dedicated chat channel for individual requests beyond the processing capabilities of its chatbot. Intervention designers are also limited to text-based self-report data. In this paper, we thus present a mobile chat app with pre-defined answer options, a dedicated chat channel for patients and health professionals and sensor data integration for the MobileCoach platform. Results of a pretest (N = 11) and preliminary findings of a randomized controlled clinical trial (N = 14) with young patients, who participate in an intervention for the treatment of obesity, are promising with respect to the utility of the chat app. © Springer International Publishing AG 2017.},
author_keywords={Chat-based interaction;  Digital coaching;  Health intervention},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Gong201630,
author={Gong, J. and Wang, Z. and Su, Q. and Yang, W.},
title={Intrusion detection and forensic analysis for network security incidents},
journal={Huazhong Keji Daxue Xuebao (Ziran Kexue Ban)/Journal of Huazhong University of Science and Technology (Natural Science Edition)},
year={2016},
volume={44},
number={11},
pages={30-33},
doi={10.13245/j.hust.161107},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996920969&doi=10.13245%2fj.hust.161107&partnerID=40&md5=bbf8f1c3fa31111dfe219fe3c902d66e},
affiliation={School of Computer Science and Engineering, Southeast University, Nanjing, 211189, China},
abstract={To improve the efficiency of the security incident response, an intrusion detection and forensic analysis automation response model was designed and implemented. The model was based on the particular security event information, OpenFlow switches were used for packet filtering and forwarding, PF_RING ZC Zero-Copy tool was used to automatically collect packet traffic, and open source intrusion detection software Suricata and multi-feature associated redundancy elimination algorithm were used to complete network intrusion detection and redundance elimination of intrusion event. Bro system was combined with application layer protocol analysis to complete forensic analysis of network traffic, which could significantly reduce manual intervention. Various parts of the automated response model were analyzed in detail by bots detected experiment, the results show the effectiveness of the model for enhancing the efficiency of the security incident response. © 2016, Editorial Board of Journal of Huazhong University of Science and Technology. All right reserved.},
author_keywords={Emergency response;  Forensic analysis;  Intrusion detection;  Redundancy elimination;  Security incidents},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Kumar20166,
author={Kumar, S. and Sehgal, R.K. and Chamotra, S.},
title={A framework for botnet infection determination through multiple mechanisms applied on honeynet data},
journal={Proceedings - 2016 2nd International Conference on Computational Intelligence and Communication Technology, CICT 2016},
year={2016},
pages={6-13},
doi={10.1109/CICT.2016.12},
art_number={7546566},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987624276&doi=10.1109%2fCICT.2016.12&partnerID=40&md5=ef8401f33b12bb7e020e2b6773ee9c56},
affiliation={Cyber Security Technology Division, Centre for Development of Advanced Computing, Mohali, India},
abstract={Botnets are a class of internet attacks having different characteristics as compared to the normal internet attacks. One of the features that uniquely characterize a botnet attack is that «the infected machine (Bot) is being remotely controlled by an entity called »Botmaster«. The Botmaster remotely controls these infected systems through »Command and Control« servers (C&C). Over a period of time complexity of botnets has increased many folds. Advance techniques employed by botnets such as protocol encryption, complex botnet structure and multi stage infection propagation models have made the botnets detection a challenging problem. Hence there is a need of a botnet detection mechanism which is independent of C&C protocol, structure and the infection propagation model used by the botnet. In the work presented in this paper, the experiments have been performed for evaluating the strength of existing botnet detection techniques, and proposed an advance detection mechanism which uses a logical combination of existing open source solutions with Honeynet technologies and our own mechanisms for botnets detection. A test setup as a proof-of-concept of the proposed framework with the experimental results is presented in this paper. © 2016 IEEE.},
author_keywords={Botnets;  Honeynet;  Intrusion Detection System;  Malwares;  Network Security},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lin2016333,
author={Lin, B. and Zagalsky, A. and Storey, M.-A. and Serebrenik, A.},
title={Why developers are slacking off: Understanding how software teams use slack},
journal={Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW},
year={2016},
volume={26-February-2016},
pages={333-336},
doi={10.1145/2818052.2869117},
note={cited By 69},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963516631&doi=10.1145%2f2818052.2869117&partnerID=40&md5=e077e2b7b31159e4ddc9163adc17b9e7},
affiliation={Eindhoven University of Technology, Eindhoven, Netherlands; University of Victoria, Victoria, BC, Canada},
abstract={Slack is a modern communication platform for teams that is seeing wide and rapid adoption by software development teams. Slack not only facilitates team messaging and archiving, but it also supports a wide plethora of integrations to external services and bots. We have found that Slack and its integrations (i.e., bots) are playing an increasingly significant role in software development, replacing email in some cases and disrupting software development processes. To understand how Slack impacts development team dynamics, we designed an exploratory study to investigate how developers use Slack and how they benefit from it. We find that developers use Slack for personal, teamwide and community-wide purposes. Our research also reveals that developers use and create diverse integrations (called bots) to support their work. This study serves as the first step towards understanding the role of Slack in supporting software engineering.},
author_keywords={Bots;  Collaboration;  Slack;  Social media;  Software development},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Aresu2016128,
author={Aresu, M. and Ariu, D. and Ahmadi, M. and Maiorca, D. and Giacinto, G.},
title={Clustering android malware families by http traffic},
journal={2015 10th International Conference on Malicious and Unwanted Software, MALWARE 2015},
year={2016},
pages={128-135},
doi={10.1109/MALWARE.2015.7413693},
art_number={7413693},
note={cited By 22},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969786989&doi=10.1109%2fMALWARE.2015.7413693&partnerID=40&md5=1ce3476b6d6cdcfca015739ebc05eac6},
affiliation={Department of Electrical and Electronic Engineering, University of Cagliari, Piazza d'Armi, Cagliari, 09123, Italy},
abstract={Due to its popularity and open-source nature, Android is the mobile platform that has been targeted the most by malware that aim to steal personal information or to control the users' devices. More specifically, mobile botnets are malware that allow an attacker to remotely control the victims' devices through different channels like HTTP, thus creating malicious networks of bots. In this paper, we show how it is possible to effectively group mobile botnets families by analyzing the HTTP traffic they generate. To do so, we create malware clusters by looking at specific statistical information that are related to the HTTP traffic. This approach also allows us to extract signatures with which it is possible to precisely detect new malware that belong to the clustered families. Contrarily to x86 malware, we show that using fine-grained HTTP structural features do not increase detection performances. Finally, we point out how the HTTP information flow among mobile bots contains more information when compared to the one generated by desktop ones, allowing for a more precise detection of mobile threats. © 2015 IEEE.},
author_keywords={Androids;  Clustering algorithms;  Feature extraction;  Humanoid robots;  Malware;  Mobile communication;  Protocols},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Akbar20161204,
author={Akbar, A. and Basha, S.M. and Sattar, S.A.},
title={Leveraging the SIP load balancer to detect and mitigate DDos attacks},
journal={Proceedings of the 2015 International Conference on Green Computing and Internet of Things, ICGCIoT 2015},
year={2016},
pages={1204-1208},
doi={10.1109/ICGCIoT.2015.7380646},
art_number={7380646},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966680769&doi=10.1109%2fICGCIoT.2015.7380646&partnerID=40&md5=58ba53164056e7327b65a361575e382b},
affiliation={Jawaharlal Nehru Technological University, Hyderabad, Telangana, India; Al Habeeb College of Engineering and Technology, Telangana, 501503, India; Academic Studies at Royal Institute of Technology and Science, Hyderabad, Telangana, India},
abstract={SIP-based Voice Over IP(VoIP) network is becoming predominant in current and future communications. Distributed Denial of service attacks pose a serious threat to VOIP network security. SIP servers are victims of DDos attacks. The major aim of the DDos attacks is to avoid legitimate users to access resources of SIP servers. Distributed Denial of service attacks target the VOIP network by deploying bots at different locations by injecting malformed packets and even they halt the entire VOIP service causes degradation of QoS(Quality of Service). DDos attacks are easy to launch and quickly drain computational resources of VOIP network and nodes. Detecting DDos attacks is a challenging and extremely difficult due to its varying strategy and scope of attackers. Many DDos detection and prevention schemes are deployed in VOIP networks but they are not complete working in both realtime and offline modes. They are inefficient in detecting dynamic and low-rate DDos attacks and even fail when the attack is launched by simultaneously manipulating multiple SIP attributes. In this paper we propose a novel scheme based on Hellinger distance(HD) to detect low-rate and multi-attribute DDos attacks. Usually DDos detection and mitigations schemes are implemented in SIP proxy. But we leverage the SIP load balancer to fight against DDos by using existing load balancing features. We have implemented the proposed scheme by modifying leading open source kamailio SIP proxy server. We have evaluated our scheme by experimental test setup and found results are outperforming the existing DDos prevention schemes in terms of detection rate, system overhead and false-positive alarms. © 2015 IEEE.},
author_keywords={kamailio;  Overload Control;  server;  Session Initiation Protocol (SIP)},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Tian2016,
author={Tian, Y. and Zhu, Y.},
title={Better computer go player with neural network and long-term prediction},
journal={4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
year={2016},
note={cited By 27},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953106&partnerID=40&md5=6f8a8e4c35ef8dc15a87c8e137faf4bd},
affiliation={Facebook AI Research, Menlo Park, CA  94025, United States; Rutgers University, Facebook AI Research, United States},
abstract={Competing with top human players in the ancient game of Go has been a long-term goal of artificial intelligence. Go’s high branching factor makes traditional search techniques ineffective, even on leading-edge hardware, and Go’s evaluation function could change drastically with one stone change. Recent works [Maddison et al. (2015); Clark & Storkey (2015)] show that search is not strictly necessary for machine Go players. A pure pattern-matching approach, based on a Deep Convolutional Neural Network (DCNN) that predicts the next move, can perform as well as Monte Carlo Tree Search (MCTS)-based open source Go engines such as Pachi [Baudis & Gailly (2012)] if its search budget is limited. We extend this idea in our bot named darkforest, which relies on a DCNN designed for long-term predictions. Darkforest substantially improves the win rate for pattern-matching approaches against MCTS-based approaches, even with looser search budgets. Against human players, the newest versions, darkfores2, achieve a stable 3d level on KGS Go Server as a ranked bot, a substantial improvement upon the estimated 4k-5k ranks for DCNN reported in Clark & Storkey (2015) based on games against other machine players. Adding MCTS to darkfores2 creates a much stronger player named darkfmcts3: with 5000 rollouts, it beats Pachi with 10k rollouts in all 250 games; with 75k rollouts it achieves a stable 5d level in KGS server, on par with state-of-the-art Go AIs (e.g., Zen, DolBaram, CrazyStone) except for AlphaGo [Silver et al. (2016)]; with 110k rollouts, it won the 3rd place in January KGS Go Tournament. © ICLR 2016: San Juan, Puerto Rico. All Rights Reserved.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liu2016232,
author={Liu, K.-W. and Wan, J.-H. and Han, Z.-Z.},
title={Hazardous chemicals accident prediction based on accident state vector using multimodal data},
journal={Frontiers in Artificial Intelligence and Applications},
year={2016},
volume={293},
pages={232-240},
doi={10.3233/978-1-61499-722-1-232},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026899073&doi=10.3233%2f978-1-61499-722-1-232&partnerID=40&md5=2da0c775d011236724a20430d0afaae8},
affiliation={School of Geosciences, China University of Petroleum, Qingdao, 266580, China; Sinopec Safety Engineering Institute, No339, Songling Road, Qingdao, Shandong, 266071, China},
abstract={Hazardous chemicals industry is a high-risk industry, all kinds of explosions, fires, leaks and poisoning incidents is occurred occasio1nally. So it is particularly important to forecast for hazardous chemical accidents and develop appropriate safety measures. In view of the analysis and summary of previous methods, an improved Hazardous Chemicals Accident Prediction method is proposed based on accident state vector in this paper. It defines the accident state vector using Multi-modal Data such as authoritative data, accident report, webpage, image, video, speech, etc. The Multi-modal Data is collected by web crawler which is built by open-source tools. The web crawler is an Internet bot which systematically browses the known hazardous chemical accident website, for the purpose of collecting Multi-modal accident data. As mentioned before, the Multi-modal Data is Multi format. In order to define the accident state vector easily, we divide the Multi- modal data into three dimensions based on the principle of accident causes. Respectively is the human factors, physical state factors, environmental factors. According to the geometrical distribution characteristics of support vector, it can be selected from the incremental samples that the sample of support vectors most likely to become forming a boundary vector set by adopting vector distance preextraction method, on which support vector training and accident prediction model build. It ensures the validity of predictive models due to various factors of the cause of the accident are fully considered by the accident state vector and advantages of support vector machines in high-dimensional, multi-factor, large sample datasets machine learning are exhibited. Sample experimental verification from the mastered accident of hazardous chemicals has showed that hazardous chemical accident prediction method proposed in this paper can effectively accumulate accident history information, possess higher learning speed and be positive significance for the safe development of hazardous chemicals industry. © 2016 The authors and IOS Press. All rights reserved.},
author_keywords={Accident prediction;  Accident state vector;  Hazardous chemical accidents;  Support vector machine},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Fischer201636,
author={Fischer, M. and Menon, S. and Khatib, O.},
title={From bot to bot: Using a chat bot to synthesize robot motion},
journal={AAAI Fall Symposium - Technical Report},
year={2016},
volume={FS-16-01 - FS-16-05},
pages={36-41},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025805047&partnerID=40&md5=56722ae9603b540058691964955573ce},
affiliation={Department of Computer Science, Stanford University, Stanford, CA  94305, United States},
abstract={We present Bot to Bot, a system for developers to write voice controlled applications in a high-level language while retaining portability over a variety of different robot hardware platforms. In this paper we describe how Bot to Bot leverages advances in natural language processing and robotic control to take a user's voice command and translate it into a structured intent for the robot through the following intermediate representations: verbal bites, robot assembly, and robot control primitives. Our long-term goal is to find a verbal instruction set for human-robot interaction. We provide our software as open source to encourage future research. Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Kollanyi20164932,
author={Kollanyi, B.},
title={Where do bots come from? An analysis of bot codes shared on GitHub},
journal={International Journal of Communication},
year={2016},
volume={10},
pages={4932-4951},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996982602&partnerID=40&md5=99094865a2b9717b754ffbb414f1cb9d},
affiliation={Corvinus University of Budapest, Hungary},
abstract={An increasing amount of open source code is available on the Internet for quickly setting up and deploying bots on Twitter. This development of open-source Twitter bots signals the emergence of new political economies that redistribute agencies around technological actors, empowering both the writers of the bots and users who deploy a bot based on the shared code. However, we have no systematic knowledge about how these bots are produced or what role sharing and collaboration play in this process. This article examines the practice of writing and sharing bot codes on GitHub, currently the largest online code repository, by analyzing data about more than 4,000 public Twitter bot code repositories from 2008 to 2016. The data reveal an exponential growth in the number of Twitter bots and a strong dominance of U.S.-based bot developers. Based on data gathered from GitHub about the social aspect of programming on the platform, the article also discusses how developers collaborate and interact with one another on GitHub around bot codes. © 2016 Bence Kollanyi.},
author_keywords={Automation;  Bot;  GitHub;  Open source;  Programming;  Social media;  Twitter},
document_type={Article},
source={Scopus},
}

@ARTICLE{Karabiyik2016379,
author={Karabiyik, U. and Aggarwal, S.},
title={Advanced automated disk investigation toolkit},
journal={IFIP Advances in Information and Communication Technology},
year={2016},
volume={484},
pages={379-396},
doi={10.1007/978-3-319-46279-0_20},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990026622&doi=10.1007%2f978-3-319-46279-0_20&partnerID=40&md5=9e63fb1f653b488beb5069b1e049c319},
affiliation={Computer Science at Sam Houston State University, Huntsville, TX, United States; Florida State University, Tallahassee, FL, United States},
abstract={Open source software tools designed for disk analysis play a critical role in digital forensic investigations. The tools typically are onerous to use and rely on expertise in investigative techniques and disk structures. Previous research presented the design and initial development of a toolkit that can be used as an automated assistant in forensic investigations. This chapter builds on the previous work and presents an advanced automated disk investigation toolkit (AUDIT) that leverages a dynamic knowledge base and database. AUDIT has new reporting and inference functionality. It facilitates the investigative process by handling core information technology expertise, including the choice and operational sequence of tools and their configurations. The ability of AUDIT to serve as an intelligent digital assistant is evaluated using a series of tests that compare it against standard benchmark disk images and examine the support it provides to human investigators. © IFIP International Federation for Information Processing 2016.},
author_keywords={Digital forensics;  Disk investigation toolkit;  Expert systems},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Garcia-Sanchez2015284,
author={Garcia-Sanchez, P. and Tonda, A. and Mora, A.M. and Squillero, G. and Merelo, J.J.},
title={Towards automatic StarCraft strategy generation using genetic programming},
journal={2015 IEEE Conference on Computational Intelligence and Games, CIG 2015 - Proceedings},
year={2015},
pages={284-291},
doi={10.1109/CIG.2015.7317940},
art_number={7317940},
note={cited By 22},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964523826&doi=10.1109%2fCIG.2015.7317940&partnerID=40&md5=1531704d50cbd197957a48732aaee8c0},
affiliation={Department of Computer Architecture and Computer Technology, University of Granada, E-Granada, Spain; UMR 782 GMPA, INRA, Thiverval-Grignon, France; CAD Group, DAUIN Politecnico di Torino, Torino, Italy},
abstract={Among Real-Time Strategy games few titles have enjoyed the continued success of StarCraft. Many research lines aimed at developing Artificial Intelligences, or 'bots', capable of challenging human players, use StarCraft as a platform. Several characteristics make this game particularly appealing for researchers, such as: Asymmetric balanced factions, considerable complexity of the technology trees, large number of units with unique features, and potential for optimization both at the strategical and tactical level. In literature, various works exploit evolutionary computation to optimize particular aspects of the game, from squad formation to map exploration; but so far, no evolutionary approach has been applied to the development of a complete strategy from scratch. In this paper, we present the preliminary results of StarCraftGP, a framework able to evolve a complete strategy for StarCraft, from the building plan, to the composition of squads, up to the set of rules that define the bot's behavior during the game. The proposed approach generates strategies as C++ classes, that are then compiled and executed inside the OpprimoBot open-source framework. In a first set of runs, we demonstrate that StarCraftGP ultimately generates a competitive strategy for a Zerg bot, able to defeat several human-designed bots. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Köhl2015,
author={Köhl, K. and Gremmels, J.},
title={A software tool for the input and management of phenotypic data using personal digital assistants and other mobile devices},
journal={Plant Methods},
year={2015},
volume={11},
number={1},
doi={10.1186/s13007-015-0069-3},
art_number={25},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926669411&doi=10.1186%2fs13007-015-0069-3&partnerID=40&md5=91a9cecde9a62c81eb960493923a39b4},
affiliation={Max-Planck-Institute of Molecular Plant Physiology, Potsdam-Golm, 14424, Germany},
abstract={Background: Plant breeding and genetics demand fast, exact and reproducible phenotyping. Efficient statistical evaluation of phenotyping data requires standardised data storage ensuring long-term data availability while maintaining intellectual property rights. This is state of the art at phenomics centres, which, however, are unavailable for most scientists. For them we developed a simple and cost-efficient system, the Phenotyper, which employs mobile devices or personal digital assistants (PDA) for on-site data entry and open-source software for data management. Results: A graphical user interface (GUI) on a PDA replaces paper-based form sheet and data entry on a desktop. The user can define his phenotyping schemes in a web tool without in-depth knowledge of the system and thus adjust it more easily to new research aspects than in a classical laboratory information management system (LIMS). In the Phenotyper, schemes are built from controlled vocabulary gained from published ontologies. Vocabulary and schemes are stored in a database that also manages the user access. From the web page, schemes are downloaded as extended markup language (XML) files for the transfer to the PDA and the exchange between users. On the PDA, the GUI displays the schemes and stores data in comma separated value format and XML format. After manual quality control, data are uploaded via a web page to an independently hosted results database, in which data are stored in an entity-attribute-value structure to provide maximum flexibility. Datasets are linked to the original and curated data files stored on a file server. The ownership stamp, project affiliation and date stamp of a dataset are used to regulate data access, which is restricted to data belonging to the user or to his projects and data, for which the embargo period has ended. By export of standardised ASCII reports to long-term data storage facility, long-term accessibility allows searching, citing and use of raw data beyond the lifetime of the database. The Phenotyper is available to the scientific community for use and further development. Conclusions: The Phenotyper provides a well-structured, but flexible data acquisition and management structure for mobile on-site measurements for efficient evaluation and shared use of data. © Köhl and Gremmels; licensee BioMed Central.},
author_keywords={Controlled vocabulary;  Data management;  Field research;  Phenotyping;  Relational database},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Dhaya2015915,
author={Dhaya, R. and Poongodi, M.},
title={Detecting software vulnerabilities in android using static analysis},
journal={Proceedings of 2014 IEEE International Conference on Advanced Communication, Control and Computing Technologies, ICACCCT 2014},
year={2015},
pages={915-918},
doi={10.1109/ICACCCT.2014.7019227},
art_number={7019227},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923276476&doi=10.1109%2fICACCCT.2014.7019227&partnerID=40&md5=bab5fdcd22a41e0abad5ba39565c0e93},
affiliation={Dept. of CSE, Velammal Engg. College, Chennai, India},
abstract={Now a day's mobile devices like Smartphone, tablets and Personal Digital Assistants etc. were playing most essential part in our daily lives. A high-end mobile device performs the same functionality as computers. Android based smart phone has become more vulnerable, because of an open source operating system. Anyone can develop a new application and post it into android market. These types of applications were not verified by authorized company. So it may include malevolent applications it may be virus, spyware, worms, etc. which can cause system failure, wasting memory resources, corrupting data, stealing personal information and also increases the maintenance cost. Due to these reasons, the mobile phone security or mobile security is very essential one in mobile computing. In the existing system is not able to detect new viruses, due to the limitation of updated signatures. The proposed system aims to motivate static code analysis based malware detection using search based machine learning algorithm which is called N-gram analysis and it detects the unnoticed malicious characteristics or vulnerabilities in the mobile applications. © 2014 IEEE.},
author_keywords={Android;  CVSS;  Malware;  N-Gram;  Static Analysis;  SVM;  Vulnerability},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Burtsev2015122,
author={Burtsev, M. and Seliverstov, A. and Airapetyan, R. and Arkhipov, M. and Baymurzina, D. and Bushkov, N. and Gureenkova, O. and Khakhulin, T. and Kuratov, Y. and Kuznetsov, D. and Litinsky, A. and Logacheva, V. and Lymar, A. and Malykh, V. and Petrov, M. and Polulyakh, V. and Pugachev, L. and Sorokin, A. and Vikhreva, M. and Zaynutdinov, M.},
title={DeepPavlov: Open-Source library for dialogue systems},
journal={ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of System Demonstrations},
year={2015},
pages={122-127},
note={cited By 36},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063131835&partnerID=40&md5=eff46d9e2cb4443d0fd825f7b23bba14},
affiliation={Moscow Institute of Physics and Technology, 9 Institutskiy per., Dolgoprudny, 141701, Russian Federation},
abstract={Adoption of messaging communication and voice assistants has grown rapidly in the last years. This creates a demand for tools that speed up prototyping of featurerich dialogue systems. An open-source library DeepPavlov is tailored for development of conversational agents. The library prioritises efficiency, modularity, and extensibility with the goal to make it easier to develop dialogue systems from scratch and with limited data available. It supports modular as well as end-to-end approaches to implementation of conversational agents. Conversational agent consists of skills and every skill can be decomposed into components. Components are usually models which solve typical NLP tasks such as intent classification, named entity recognition or pre-trained word vectors. Sequence-to-sequence chit-chat skill, question answering skill or task-oriented skill can be assembled from components provided in the library. © 2018 Association for Computational Linguistics.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Burns2015,
author={Burns, B. and Samanta, B.},
title={Mechanical design and control calibration for an interactive animatronic system},
journal={ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)},
year={2015},
volume={4B-2015},
doi={10.1115/IMECE201552477},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982899200&doi=10.1115%2fIMECE201552477&partnerID=40&md5=b7b333a7fd2ecef6a9a8a4e8250312bd},
affiliation={Department of Mechanical Engineering, Georgia Southern University, Statesboro, GA, United States},
abstract={Animatronic figures provide key show effects in the entertainment and theme park industry by simulating life-like animations and sounds. There is a need for interactive, autonomous animatronic systems to create engaging and compelling experiences for the guests. The animatronic figures must identify the guests and recognize their status in dynamic interactions for enhanced acceptance and effectiveness as socially interactive agents, in the general framework of humanrobot interactions. The design and implementation of an interactive, autonomous animatronic system in form of a tabletop dragon and the comparisons of guest responses in its passive and interactive modes are presented in this work. The purpose of this research is to create a platform that may be used to validate autonomous, interactive behaviors in animatronics, utilizing both quantitative and qualitative analysis methods of guest response. The dragon capabilities include a four degreesof- freedom head, moving wings, tail, jaw, blinking eyes and sound effects. Human identification, using a depth camera (Carmine from PrimeSense), an open-source middleware (NITE from OpenNI), Java-based Processing and an Arduino microcontroller, has been implemented into the system in order to track a guest or guests, within the field of view of the camera. The details of design and fabrication of the dragon model, algorithm development for interactive autonomous behavior using a vision system, the experimental setup and implementation results under different conditions are presented. Copyright © 2015 by ASME.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Weinstock201558,
author={Weinstock, O.M.},
title={Online search in behavioral programming models},
journal={CEUR Workshop Proceedings},
year={2015},
volume={1503},
pages={58-63},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961377785&partnerID=40&md5=24a941200cb32c47e448152f84a13364},
affiliation={Department of Computer Science, Ben-Gurion University of the Negev, Israel},
abstract={We present a model based approach to Search Based Software Engineering (SBSE). The approach is based on the Behavioral Programming (BP) paradigm where independent aspects of behavior are woven at run time using a simple interaction protocol. We propose to extend the behavioral programming execution mechanism with on-line heuristic search in program state space that allows programmers to develop non-deterministic programs while relying on a "smart" event selection mechanism to resolve non-determinism in a way that maximizes a specified heuristic function. The paper presents a new library that we have developed in Java and in JavaScript, using Rhino, to facilitate the proposed modeling approach and programming style. We give examples, in the context of a StarCraft game bot built with the library, that demonstrate how the proposed programming idioms can simplify the code and help build robust reactive systems.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Islamgozhayev2015,
author={Islamgozhayev, T.U. and Mazhitov, Sh.S. and Zholmyrzayev, A.K. and Toishybek, E.T.},
title={IICT-bot: Educational robotic platform using omni-directional wheels with open source code and architecture},
journal={2015 International Siberian Conference on Control and Communications, SIBCON 2015 - Proceedings},
year={2015},
doi={10.1109/SIBCON.2015.7147079},
art_number={7147079},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941046530&doi=10.1109%2fSIBCON.2015.7147079&partnerID=40&md5=e3b6fbc1c8766b5f9308481077b8f28f},
affiliation={Laboratory of Pattern Recognition and Decision Making, Institute of Information and Computing Technologies, Almaty, Kazakhstan; Laboratory of Computing Systems, Institute of Information and Computing Technologies, Almaty, Kazakhstan; Laboratory of Mathematical and Computer Modeling, Institute of Information and Computing Technologies, Almaty, Kazakhstan},
abstract={Robotics as the discipline becomes popular subject in many universities and schools. A lot of vendors produce various types of robots for teaching robotics. But most of robots are vendor-dependent, without source code and expensive. Aim of this paper is the development of a robot platform, which can be used in teaching subjects as Robotics, Control Theory, Machine Vision, Object Recognition, and which can be bought by students or pupils and used for projects or competitions. To reach this aims we developed IICT-bot - cheap, flexible, fitted for outdoor usage, and multi-functional robotic platform using omni-directional wheels. IICT-bot is built on Arduino, which is popular hardware-platform with open architecture and easy-to-use API. © 2015 IEEE.},
author_keywords={Arduino;  IICT-bot;  mobile robot;  omni-directional wheels;  Robot platform;  wireless control},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Burns2015,
author={Burns, B. and Samanta, B.},
title={Design and implementation of an interactive animatronic for guest response analysis},
journal={Conference Proceedings - IEEE SOUTHEASTCON},
year={2015},
volume={2015-June},
number={June},
doi={10.1109/SECON.2015.7132899},
art_number={7132899},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938125346&doi=10.1109%2fSECON.2015.7132899&partnerID=40&md5=efe1d918fc84e08e2e0d573d21ad974d},
affiliation={Department of Mechanical Engineering, Georgia Southern University, Statesboro, United States},
abstract={Within entertainment applications, animatronics must be identified as human partners to establish status for dynamic interactions for enhanced acceptance and effectiveness as socially-interactive agents. This research covers the design and implementation for human identification using a depth camera (Carmine from PrimeSense), an open-source middleware (NITE from OpenNI), Java-based Processing and an Arduino microcontroller into an animatronic dragon. Using the data from depth camera, people are identified by approximating a person's skeletal information. Based on the movements of the individual, the program tracks a human body, or bodies, within the camera's field of view. Joint locations, in the tracked human, are isolated for specific usage by the program. Joints include the head, torso, shoulders, elbows, hands, knees and feet. The dragon capabilities include a four degrees-of-freedom neck, moving wings, tail, jaw, blinking eyes and sound effects. These outputs instigate a movement in the tracked human, which establishes the cycle of human to animatronic interactions. This animatronic creature design will allow for future research in the effectiveness of interactive elements in themed environments. © 2015 IEEE.},
author_keywords={Animatronics;  Arduino;  Depth Camera;  Dragon;  Human Tracking},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Steiner2014547,
author={Steiner, T.},
title={Bots vs. Wikipedians, anons vs. Logged-ins},
journal={WWW 2014 Companion - Proceedings of the 23rd International Conference on World Wide Web},
year={2014},
pages={547-548},
doi={10.1145/2567948.2576948},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990945039&doi=10.1145%2f2567948.2576948&partnerID=40&md5=bc8484f6af697d7e36aa8ec735460931},
affiliation={Google Germany GmbH, ABC-Str. 19, Hamburg, 20354, Germany; Université de Lyon, CNRS, LIRIS, UMR5205, Universite Lyon 1F-69622, France},
abstract={Wikipedia is a global crowdsourced encyclopedia that at time of writing is available in 287 languages. Wikidata is a likewise global crowdsourced knowledge base that pro- vides shared facts to be used by Wikipedias. In the con- Text of this research, we have developed an application and an underlying Application Programming Interface (API) ca- pable of monitoring realtime edit activity of all language versions of Wikipedia and Wikidata. This application al- lows us to easily analyze edits in order to answer questions such as Bots vs. Wikipedians, who edits more", Which is the most anonymously edited Wikipedia", or \Who are the bots and what do they edit". To the best of our knowledge, this is the FIrst time such an analysis could be done in real- Time for Wikidata and for really all Wikipedias|large and small. Our application is available publicly online at the URL http://wikipedia-edits.herokuapp.com/, its code has been open-sourced under the Apache 2.0 license. © Copyright 2014 by the International World Wide Web Conferences Steering Committee.},
author_keywords={Realtime monitoring;  Study;  Web app;  Wikidata;  Wikipedia},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Anand2014539,
author={Anand, A. and Nithya, M. and Sudarshan, T.S.B.},
title={Coordination of mobile robots with master-slave architecture for a service application},
journal={Proceedings of 2014 International Conference on Contemporary Computing and Informatics, IC3I 2014},
year={2014},
pages={539-543},
doi={10.1109/IC3I.2014.7019647},
art_number={7019647},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949922210&doi=10.1109%2fIC3I.2014.7019647&partnerID=40&md5=7bd365bf0ed9fc658cb158d650bb30e9},
affiliation={Amrita Robotics Research Center (ARRC), Amrita Vishwa Vidyapeetham, School of Engineering, Bangalore, Karnataka, India},
abstract={Swarm robotics is based on the characteristics displayed by the insects and their colony and is applied to solve real world problems utilizing multi-robot systems. Research in this field has demonstrated the ability of such robot systems to assemble, inspect, disperse, aggregate and follow trails. A set of mobile and self-sufficient robots which has very restricted capabilities can form intricate patterns in the environment they inhabit. The simple patterns can be used by the robots to achieve high level tasks. In the proposed work, a set of robots are coordinating to form a specific pattern around the object with step wise linear motion and are programmed to push the object from a source position to the destination in an obstacle free environment. Initially the robots are placed in known positions. ZigBee communication protocol is used for interaction among the robots. A single robot is chosen as a central coordinator and controls the movement of the rest of the robots in the swarm. Master bot decides on the path to be taken and also supplies the slave bots with the coordinates to be reached. The entire scenario has been simulated using the open source tool Player/Stage and the hardware implementation has been done using micromouse chassis set up and the Arduino Uno controller board. © 2014 IEEE.},
author_keywords={Pattern formation;  Player stage;  Swarm;  ZigBee},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Burns2014,
author={Burns, B. and Samanta, B.},
title={Human identification for human-robot interactions},
journal={ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)},
year={2014},
volume={4B},
doi={10.1115/IMECE2014-38496},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926442178&doi=10.1115%2fIMECE2014-38496&partnerID=40&md5=99c7e3f14402edddce24f5de7541a53b},
affiliation={Department of Mechanical Engineering, Georgia Southern University, Statesboro, GA, United States},
abstract={In co-robotics applications, the robots must identify human partners and recognize their status in dynamic interactions for enhanced acceptance and effectiveness as socially interactive agents. Using the data from depth cameras, people can be identified from a person's skeletal information. This paper presents the implementation of a human identification algorithm using a depth camera (Carmine from PrimeSense), an open-source middleware (NITE from OpenNI) with the Java-based Processing language and an Arduino microcontroller. This implementation and communication sets a framework for future applications of human-robot interactions. Based on the movements of the individual in the depth sensor's field of view, the program can be set to track a human skeleton or the closest pixel in the image. Joint locations in the tracked human can be isolated for specific usage by the program. Joints include the head, torso, shoulders, elbows, hands, knees and feet. Logic and calibration techniques were used to create systems such as a facial tracking pan and tilt servomotor mechanism. The control system presented here sets groundwork for future implementation into student built animatronic figures and mobile robot platforms such as Turtlebot. Copyright © 2014 by ASME.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Steiner2014F2,
author={Steiner, T.},
title={Bots vs. Wikipedians, Anons vs. Logged-ins (Redux): A global study of edit activity on Wikipedia and Wikidata},
journal={Proceedings of the 10th International Symposium on Open Collaboration, OpenSym 2014},
year={2014},
pages={F2},
doi={10.1145/2641580.2641613},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908648648&doi=10.1145%2f2641580.2641613&partnerID=40&md5=e5df781670f338f96a571b3e1c5d303b},
affiliation={Google Germany GmbH, ABC-Str. 19, Hamburg, 20354, Germany},
abstract={Wikipedia is a global crowdsourced encyclopedia that at time of writing is available in 287 languages. Wikidata is a likewise global crowdsourced knowledge base that provides shared facts to be used by Wikipedias. In the context of this research, we have developed an application and an underlying Application Programming Interface (API) capable of monitoring realtime edit activity of all language versions of Wikipedia and Wikidata. This application allows us to easily analyze edits in order to answer questions such as \Bots vs. Wikipedians, who edits more?", \Which is the most anonymously edited Wikipedia?", or \Who are the bots and what do they edit?". To the best of our knowledge, this is the first time such an analysis was done for Wikidata and for really all Wikipedias|large and small. According to our results, all Wikipedias and Wikidata together are edited by about 50% bots and by about 23% anonymous users. Wikidata alone accounts for about 48% of the totally observed edits. If we do not consider Wikidata, i.e., if we only look at all Wikipedias, about 15% of all edits are made by bots and 26% of all edits are made by anonymous users. Overall, we found a stabilizing number of 274 active bots during our observation period. Our application is available publicly online at the URL http://wikipedia-edits.herokuapp.com/, its code has been open-sourced under the Apache 2.0 license.},
author_keywords={CNRS Université Lyon 1;  F-69622;  LIRIS;  UMR5205;  Université de Lyon},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Devi20141309,
author={Devi, D.S. and Thilagavathy, K. and Vaghula Krishnan, S. and Harish, S. and Srinivasan, R.},
title={Integrating OTP authentication service in openstack},
journal={Advanced Materials Research},
year={2014},
volume={984-985},
pages={1309-1317},
doi={10.4028/www.scientific.net/AMR.984-985.1309},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905647763&doi=10.4028%2fwww.scientific.net%2fAMR.984-985.1309&partnerID=40&md5=8677ec7d7b36dfe8dec27d192d49cf94},
affiliation={Department of Computer Technology and Applications, Coimbatore Institute of Technology, Coimbatore, India; Department of Physics, Coimbatore Institute of Technology, Coimbatore, India},
abstract={Cloud Computing is being intended to deliver information technology services based on internet on demand. The benefits of cloud technology are incomparable which takes the information technology into a new dimension. Organizations already invested for their own infrastructure are likely to set up private clouds to reap the benefits of cloud computing technologies. Cloud services are thriving by the open source software OpenStack. In this paper, we aim to introduce the largest open-source cloud operating system OpenStack with a new authentication mechanism. This paper tries to address the challenge of finding legitimate users by introducing One Time Password(OTP) as an authentication mechanism in OpenStack. Replay attacks can be defeated by using One Time Password. The OTP mechanism provides an extra level of protection which makes it extremely difficult for any potential intruder to abuse the recorded password that was already used to log into cloud service. The integration of OTP mechanism into OpenStack allows users to protect their credentials from unauthorized access. Also One Time Password is used to grant access to legitimate users into the cloud environment and to prevent access to malicious users bot attacks.With secured cloud environment users can enjoy lot many benefits of private cloud service. © (2014) Trans Tech Publications, Switzerland.},
author_keywords={Cloud computing;  One-time password;  Openstack cloud installation;  Private cloud setup;  Secured authentication},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{deLaat2014157,
author={de Laat, P.B.},
title={From open-source software to Wikipedia: 'Backgrounding' trust by collective monitoring and reputation tracking},
journal={Ethics and Information Technology},
year={2014},
volume={16},
number={2},
pages={157-169},
doi={10.1007/s10676-014-9342-9},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901386128&doi=10.1007%2fs10676-014-9342-9&partnerID=40&md5=e4a0160951c270ab6bcaf5861bd93a84},
affiliation={Department of Computer Science, University of Groningen, Groningen, Netherlands},
abstract={Open-content communities that focus on co-creation without requirements for entry have to face the issue of institutional trust in contributors. This research investigates the various ways in which these communities manage this issue. It is shown that communities of open-source software-continue to-rely mainly on hierarchy (reserving write-access for higher echelons), which substitutes (the need for) trust. Encyclopedic communities, though, largely avoid this solution. In the particular case of Wikipedia, which is confronted with persistent vandalism, another arrangement has been pioneered instead. Trust (i.e. full write-access) is 'backgrounded' by means of a permanent mobilization of Wikipedians to monitor incoming edits. Computational approaches have been developed for the purpose, yielding both sophisticated monitoring tools that are used by human patrollers, and bots that operate autonomously. Measures of reputation are also under investigation within Wikipedia; their incorporation in monitoring efforts, as an indicator of the trustworthiness of editors, is envisaged. These collective monitoring efforts are interpreted as focusing on avoiding possible damage being inflicted on Wikipedian spaces, thereby being allowed to keep the discretionary powers of editing intact for all users. Further, the essential differences between backgrounding and substituting trust are elaborated. Finally it is argued that the Wikipedian monitoring of new edits, especially by its heavy reliance on computational tools, raises a number of moral questions that need to be answered urgently. © 2014 Springer Science+Business Media Dordrecht.},
author_keywords={Bots;  Open-source software;  Reputation;  Trust;  Vandalism;  Wikipedia},
document_type={Article},
source={Scopus},
}

@ARTICLE{Garaizar2014430,
author={Garaizar, P. and Reips, U.-D.},
title={Build your own social network laboratory with Social Lab: A tool for research in social media},
journal={Behavior Research Methods},
year={2014},
volume={46},
number={2},
pages={430-438},
doi={10.3758/s13428-013-0385-3},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901379129&doi=10.3758%2fs13428-013-0385-3&partnerID=40&md5=f303c8c6d2b8fc10d4cf0677efd10c31},
affiliation={Deusto Institute of Technology (DeustoTech), Universidad de Deusto, Avda. Universidades 24, 48007 Bilbao, Spain; Ikerbasque, Basque Foundation for Science, Bilbao, Spain},
abstract={Social networking has surpassed e-mail and instant messaging as the dominant form of online communication (Meeker, Devitt, & Wu, 2010). Currently, all large social networks are proprietary, making it difficult to impossible for researchers to make changes to such networks for the purpose of study design and access to user-generated data from the networks. To address this issue, the authors have developed and present Social Lab, an Internet-based free and open-source social network software system available from http://www.sociallab.es. Having full availability of navigation and communication data in Social Lab allows researchers to investigate behavior in social media on an individual and group level. Automated artificial users ("bots") are available to the researcher to simulate and stimulate social networking situations. These bots respond dynamically to situations as they unfold. The bots can easily be configured with scripts and can be used to experimentally manipulate social networking situations in Social Lab. Examples for setting up, configuring, and using Social Lab as a tool for research in social media are provided. © 2013 Psychonomic Society, Inc.},
author_keywords={Internet science;  Internet-based research;  Open-source software;  Social engineering;  Social media;  Social networking sites},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wilcox2013,
author={Wilcox, B. and Wilcox, S.},
title={Making it real: Loebner-winning chatbot design [Haciéndolo realidad: Ganador del premio loebner del diseño chatbot]},
journal={Arbor},
year={2013},
volume={189},
number={764},
doi={10.3989/arbor.2013.764n6009},
art_number={a086},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893508037&doi=10.3989%2farbor.2013.764n6009&partnerID=40&md5=740877412fd5acb94379af080a3b5cc4},
abstract={For the last three years, our chatbots have come in 1st twice and 2nd once in the Loebner Prize Contest, with a different persona each year (Suzette, Rosette, Angela). Suzette even fooled a human judge. A world-class chatbot should tell the story of its life, have a consistent personality, and respond emotionally. It takes a lot of script. And it takes a powerful engine designed to support natural language processing in a variety of ways and make it relatively easy to author all that script. This paper briefly discusses ChatScript, the open-source Natural Language scripting language and engine running our bots. Then it looks at how we construct chatbots and what we have learned. © 2013 CSIC.},
author_keywords={Artificial Intelligence;  Chat;  Chatbot;  ChatScript;  Conversation;  Loebner;  Natural Language},
document_type={Article},
source={Scopus},
}

@ARTICLE{Santos-Pérez2013610,
author={Santos-Pérez, M. and González-Parada, E. and Cano-García, J.M.},
title={Mobile embodied conversational agent for task specific applications},
journal={IEEE Transactions on Consumer Electronics},
year={2013},
volume={59},
number={3},
pages={610-614},
doi={10.1109/TCE.2013.6626246},
art_number={6626246},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886571495&doi=10.1109%2fTCE.2013.6626246&partnerID=40&md5=48f0734b9b1232f4fa59be8acc34d987},
affiliation={University of Malaga, 29071 Malaga, Spain},
abstract={In the recent years major efforts have been made to promote the use of virtual assistants on mobile devices. But in most cases these assistants can only manage a limited and predetermined set of applications. Other limitation that makes difficult the adoption of this technology is the need for a data connection. Thus, this paper introduces the use of an Embodied Conversational Agent (ECA) as an assistant for task-specific applications. The proposed ECA is based on open-source components and runs entirely on the mobile device. The system design was validated by conducting tests to measure the latency and energy consumption. © 2013 IEEE.},
author_keywords={Control Systems;  Embodied Conversational Agents;  Home Automation;  NaturalLanguage Interaction},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Qu2013,
author={Qu, B. and Pammi, S. and Niewiadomski, R. and Chollet, G.},
title={Estimation of FAPs and intensities of AUs based on real-time face tracking},
journal={ACM International Conference Proceeding Series},
year={2013},
doi={10.1145/2491599.2491612},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879812570&doi=10.1145%2f2491599.2491612&partnerID=40&md5=3b5257b7db9897a6d13667cef5bc3cd3},
affiliation={Télécom ParisTech, Paris, France},
abstract={Imitation of natural facial behavior in real-time is still challenging when it comes to natural behavior such as laughter and nonverbal expressions. This paper explains our ongoing work on methodologies and tools for estimating Facial Animation Parameters (FAPs) and intensities of Action Units (AUs) in order to imitate lifelike facial expressions with an MPEG-4 complaint Embodied Conversational Agent (ECA) - The GRETA agent (Bevacqua et al. 2007). Firstly, we investigate available open source tools for better facial landmark localization. Secondly, FAPs and intensities of AUs are estimated based on facial landmarks computed with an open source face tracker tool. Finally, the paper discusses our ongoing work to investigate better re-synthesis technology among FAP-based and AU-based synthesis technologies using perceptual studies on: (i) naturalness in synthesized facial expressions; (ii) similarity perceived by the subjects when compared to original user's behavior. © 2012 Authors.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Nakaguro201391,
author={Nakaguro, Y. and Dailey, M.N. and Marukatat, S. and Makhanov, S.S.},
title={Defeating line-noise CAPTCHAs with multiple quadratic snakes},
journal={Computers and Security},
year={2013},
volume={37},
pages={91-110},
doi={10.1016/j.cose.2013.05.003},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879054091&doi=10.1016%2fj.cose.2013.05.003&partnerID=40&md5=0435b896f86e7e0205d29a0d36ca3e85},
affiliation={Sirindhorn International Institute of Technology, Thammasat University, Thailand; Computer Science and Information Management, Asian Institute of Technology, Thailand; National Electronics and Computer Technology Center, Thailand},
abstract={Optical character recognition (OCR) is one of the fundamental problems in artificial intelligence and image processing, but recent progress in OCR represents a security challenge for Web sites that throttle requests with image based CAPTCHAs (Completely Automated Public Turing Tests to Tell Computers and Humans Apart). A CAPTCHA is challenge-response test placed within web forms to determine whether the user is human. Unfortunately, algorithms capable of solving image based CAPTCHAs can be used to create spam accounts and design malicious denial of service (DoS) attacks, causing financial and social damage. The problem of defeating digital image CAPTCHAs is thus twofold. On the one hand, it is an important problem in artificial intelligence and image processing. On the other hand, publicly available CAPTCHAs that are not tested against state of the art machine recognition algorithms may make the systems vulnerable to attack by software bots. This paper considers a very important subclass of text CAPTCHAs, those characterized by salt and pepper noise combined with line (curve) noise. Thus far, attacks on CAPTCHAs with this type of noise have used relatively simple image processing methods with some success, but state-of-the-art segmentation methods have not been fully exploited. In this paper, we propose and benchmark two strong segmentation methods. The first method is a modification of a multiple quadratic snake proposed for road extraction from satellite images. The second competing method is a boundary tracing routine available in the OpenCV open source library. A first numerical experiment indicates excellent accuracy for both methods. A second experiment on human recognition shows that the CAPTCHAs used in the study are already near the threshold of being too hard for humans. Finally, a third numerical experiment presents a more difficult set of CAPTCHAs with the addition of anti-binarization methods. The snake-based method is shown to be more resilient to anti-binarization schemes than boundary tracing and state-of-the art projection-based attacks on CAPTCHAs. Since CAPTCHAs corrupted by small line noise are shown to be difficult for humans and relatively easy for our algorithm, CAPTCHA designers should introduce more challenging distortions into their CAPTCHAs, lest the security of systems based on them be compromised. © 2013 Elsevier Ltd. All rights reserved.},
author_keywords={CAPTCHA;  GVF snake;  OCR;  OpenCV;  Segmentation},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Santos-Perez201370,
author={Santos-Perez, M. and Gonzalez-Parada, E. and Cano-Garcia, J.M.},
title={ECA-based control interface on Android for home automation system},
journal={Digest of Technical Papers - IEEE International Conference on Consumer Electronics},
year={2013},
pages={70-71},
doi={10.1109/ICCE.2013.6486799},
art_number={6486799},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876390616&doi=10.1109%2fICCE.2013.6486799&partnerID=40&md5=d52908a6b28c0051b9c78281e0638e23},
affiliation={School of Telecommunications Engineering, University of Malaga, 29071 Malaga, Spain},
abstract={Historically, Embodied Conversational Agents (ECAs) have been used as virtual assistants that make easier the access to information or help in performing complex tasks. Due to their high computational requirements ECAs are usually run on desktop computers, but with the recent development of hand-held devices both in hardware and software, it becames neccessary to move ECAs to that new mobile scenario. Thus, we propose an open-source based platform for developing ECA based interfaces on Android-equipped devices. We also present a prototype for controlling a home automation system. © 2013 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pappu201341,
author={Pappu, A. and Rudnicky, A.},
title={Deploying speech interfaces to the masses},
journal={International Conference on Intelligent User Interfaces, Proceedings IUI},
year={2013},
pages={41-42},
doi={10.1145/2451176.2451189},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875830749&doi=10.1145%2f2451176.2451189&partnerID=40&md5=24498bfa6af702a11cb59bf80bf10529},
affiliation={Language Technologies Institute, Carnegie Mellon University, United States},
abstract={Speech systems are typically deployed either over phones, e.g. IVR agents, or on embodied agents, e.g. domestic robots. Most of these systems are limited to a particular platform i.e., only accessible by phone or in situated interactions. This limits scalability and potential domain of operation. Our goal is to make speech interfaces more widely available, and we are proposing a new approach for deploying such interfaces on the internet along with traditional platforms. In this work, we describe a lightweight speech interface architecture built on top of Freeswitch, an open source softswitch platform. A softswitch enables us to provide users with access over several types of channels (phone, VOIP, etc.) as well as support multiple users at the same time. We demonstrate two dialog applications developed using this approach: 1) Virtual Chauffeur: a voice based virtual driving experience and 2) Talkie: a speech-based chat bot.},
author_keywords={Phone apps;  Speech interfaces;  VOIP apps;  Web apps},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Olney2013137,
author={Olney, A.M. and Hays, P. and Cade, W.L.},
title={XNAgent: Authoring embodied conversational agents for tutor-user interfaces},
journal={CEUR Workshop Proceedings},
year={2013},
volume={1009},
pages={137-145},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924940410&partnerID=40&md5=6f65b45ab233dd435f93374c541b5e80},
affiliation={Institute for Intelligent Systems, Department of Psychology, 365 Innovation Drive, Memphis, TN  38152, United States},
abstract={Embodied conversational agents are virtual characters that engage users in conversation with appropriate speech, gesture, and facial expression. The high cost of developing embodied conversational agents has led to a recent increase in open source agent platforms. In this paper, we present XNAgent, an open source platform for embodied conversational agents based on the XNA Framework. By leveraging the high-level class structure of the XNA Framework, XNAgent provides a compact implementation that is suitable both as a starting point for the development of a more advanced system and as a teaching tool for AI curricula. In this paper we describe how we created an embodied conversational agent in XNA using skeletal and morph animation, motion capture, and event-driven animation and how this process can facilitate the use of embodied conversational agents in the Generalized Intelligent Framework for Tutoring.},
author_keywords={Agent;  Conversation;  ECA;  GIFT;  HCI;  Interface;  Tutoring;  XNA},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Vikram201355,
author={Vikram, S. and Yang, C. and Gu, G.},
title={NOMAD: Towards non-intrusive moving-target defense against web bots},
journal={2013 IEEE Conference on Communications and Network Security, CNS 2013},
year={2013},
pages={55-63},
doi={10.1109/CNS.2013.6682692},
art_number={6682692},
note={cited By 31},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893633536&doi=10.1109%2fCNS.2013.6682692&partnerID=40&md5=cace3a2e2d39bc0b6237f2fc1b77d7fc},
affiliation={SUCCESS Lab., Texas A and M University, United States},
abstract={Web bots, such as XRumer, Magic Submitter and SENuke, have been widely used by attackers to perform illicit activities, such as massively registering accounts, sending spam, and automating web-based games. Although the technique of CAPTCHA has been widely used to defend against web bots, it requires users to solve some explicit challenges, which is typically interactive and intrusive, resulting in decreased usability. In this paper, we design a novel, non-intrusive moving-target defense system, NOMAD, to complement existing solutions. NOMAD prevents web bots from automating web resource access by randomizing HTML elements while not affecting normal users. Specifically, to prevent web bots uniquely identifying HTML elements for later automation, NOMAD randomizes name/id parameter values of HTML elements in each HTTP form page. We evaluate NOMAD against five powerful state-of-the-art web bots on several popular open source web platforms. According to our evaluation, NOMAD can prevent all these web bots with a relatively low overhead. © 2013 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Yampolskiy201248,
author={Yampolskiy, R.V. and Gavrilova, M.L.},
title={Artimetrics: Biometrics for artificial entities},
journal={IEEE Robotics and Automation Magazine},
year={2012},
volume={19},
number={4},
pages={48-58},
doi={10.1109/MRA.2012.2201574},
art_number={6377475},
note={cited By 30},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871391882&doi=10.1109%2fMRA.2012.2201574&partnerID=40&md5=3d4a66aa96032cda20cf7f51fd16edd2},
affiliation={Department of Computer Engineering and Computer Science, Speed School of Engineering, University of Louisville, Louisville, KY, United States; University of Calgary, Calgary, AB, Canada},
abstract={Domestic and industrial robots, intelligent software agents, virtual-world avatars, and other artificial entities are being created and deployed in our society for various routine and hazardous tasks, as well as for entertainment and companionship. Over the past ten years or so, primarily in response to the growing security threats and financial fraud, it has become necessary to accurately authenticate the identities of human beings using biometrics. For similar reasons, it may become essential to determine the identities of nonbiological entities. Trust and security issues associated with the large-scale deployment of military soldier-robots [55], robot museum guides [22], software office assistants [24], humanlike biped robots [67], office robots [5], domestic and industrial androids [93], [76], bots [85], robots with humanlike faces [60], virtual-world avatars [109], and thousands of other man-made entities require the development of methods for a decentralized, affordable, automatic, fast, secure, reliable, and accurate means of authenticating these artificial agents. The approach has to be decentralized to allow authority-free authentication important for open-source and collaborative societies. To address these concerns, we proposed [117], [120], [119], [38] the concept of artimetricsa field of study that identifies, classifies, and authenticates robots, software, and virtual reality agents. In this article, unless otherwise qualified, the term robot refers to both embodied robots (industrial, mobile, tele, personal, military, and service) and virtual robots or avatars, focusing specifically on those that have a human morphology. © 1994-2011 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Costa2012329,
author={Costa, F. and Silva, J.N. and Veiga, L. and Ferreira, P.},
title={Large-scale volunteer computing over the internet},
journal={Journal of Internet Services and Applications},
year={2012},
volume={3},
number={3},
pages={329-346},
doi={10.1007/s13174-012-0072-0},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888618350&doi=10.1007%2fs13174-012-0072-0&partnerID=40&md5=ab15e4ff2e6c9f7e8b7e169569a5b246},
affiliation={Distributed Systems Group, INESC-ID, Technical University of Lisbon, R. Alves Redol, 9, 1000-029 Lisboa, Portugal},
abstract={Cycle sharing over the Internet has increased in popularity during the last decade, with increasingly powerful machines being made available to existing projects. In this paper, we present GiGi-MR, a framework that allows nonexpert users to run CPU-intensive jobs on top of volunteer resources over the Internet. GiGi-MR has several distinctive features: it allows non-expert users to easily partition their jobs in several parallel tasks; such Bag-of-Tasks (BoT) are executed in parallel as a set of MapReduce applications; the volunteer resources that provide the best match for the tasks being executed are chosen (using attenuated bloom filters); it provides a portable checkpointing fault-tolerance mechanism based on virtualization; it does not rely exclusively on a central server (or servers) at all times (thus minimizing the bottleneck effect); it deals with malicious participants (possibly byzantine) using an efficient partial replication mechanism to validate the results obtained; and it is compatible with BOINC (one of the most popular open-source software platforms for computing using volunteered resources). We describe GiGi-MR's architecture and evaluate its performance by executing several MapReduce applications on a wide area testbed. Furthermore, we use micro-benchmarks to assess each one of GiGi-MR's components independently. The system's overhead is minimal. When compared to an unmodified volunteer computing system, GiGi-MR obtains a performance increase of over 60% in application turnaround time, while reducing the bandwidth used by an order of magnitude. © The Brazilian Computer Society 2012.},
author_keywords={Adaptive middleware;  Distributed systems;  Map reduce;  Volunteer computing},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Keegan2012153,
author={Keegan, M. and Boyle, R.D. and Dee, H.M.},
title={Turi: Chatbot software for schools in the Turing Centenary},
journal={ACM International Conference Proceeding Series},
year={2012},
pages={153-154},
doi={10.1145/2481449.2481488},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878468276&doi=10.1145%2f2481449.2481488&partnerID=40&md5=be665c542e94fbdfd7b76bd8da630490},
affiliation={Computer Science, Aberystwyth University, Penglais, Aberystwyth SY23 3DB, United Kingdom},
abstract={We describe a workshop designed for 11-19 year-olds that considers the nature of intelligence and introduces the Turing test in various ways. Chatbots as mimics of intelligence are considered at length. Pupils are invited to use our system Turi in which they can build and test their own chatbot. The materials are free, open source and available for all to download [1]. Copyright © 2012 ACM.},
author_keywords={Alan turing;  Artificial intelligence;  Chatbots;  Computer science education},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bubeck2012609,
author={Bubeck, A. and Weisshardt, F. and Sing, T. and Reiser, U. and Hägele, M. and Verl, A.},
title={Implementing best practices for systems integration and distributed software development in service robotics - The Care-O-bot®robot family},
journal={2012 IEEE/SICE International Symposium on System Integration, SII 2012},
year={2012},
pages={609-614},
doi={10.1109/SII.2012.6427386},
art_number={6427386},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874236966&doi=10.1109%2fSII.2012.6427386&partnerID=40&md5=6544d1a80141fe8705098c27c905e486},
abstract={To date, the complex and diverse demands on robotic software can only be handled by large teams which are often distributed geographically, with each team working on a specific aspect of the robot's functionality. The distributed nature of development and differences in the configuration of standard robot platforms impose particular challenges on the process of system integration. To address these challenges, this paper describes the application of best practices in software engineering to the developer community of the Care-O-bot ®robot family: strictly defined developer roles, management of platform dependencies by Separation of Concerns, and automated testing. The concrete implementation of these concepts in the development process is demonstrated. By analyzing development activities over the last months we can validate the impact of the concepts in the distributed community. © 2012 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pieterse2012,
author={Pieterse, H. and Olivier, M.S.},
title={Android botnets on the rise: Trends and characteristics},
journal={2012 Information Security for South Africa - Proceedings of the ISSA 2012 Conference},
year={2012},
doi={10.1109/ISSA.2012.6320432},
art_number={6320432},
note={cited By 56},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869222883&doi=10.1109%2fISSA.2012.6320432&partnerID=40&md5=01fce81025108ec39d623625423798ba},
affiliation={Defence, Peace, Safety and Security, Council for Scientific and Industrial Research, Pretoria, South Africa; Department of Computer Science, University of Pretoria, Pretoria, South Africa},
abstract={Smartphones are the latest technology trend of the 21st century. Today's social expectation of always staying connected and the need for an increase in productivity are the reasons for the increase in smartphone usage. One of the leaders of the smartphone evolution is Google's Android Operating System (OS). The openness of the design and the ease of customizing are the aspects that are placing Android ahead of the other smartphone OSs. Such popularity has not only led to an increase in Android usage but also to the rise of Android malware. Although such malware is not having a significant impact on the popularity of Android smartphones, it is however creating new possibilities for threats. One such threat is the impact of botnets on Android smartphones. Recently, malware has surfaced that revealed specific characteristics relating to traditional botnet activities. Malware such as Geinimi, Pjapps, DroidDream, and RootSmart all display traditional botnet functionalities. These malicious applications show that Android botnets is a reality. From a security perspective it is important to understand the underlying structure of an Android botnet. This paper evaluates Android malware with the purpose of identifying specific trends and characteristics relating to botnet behaviour. The botnet trends and characteristics are detected by a comprehensive literature study of well-known Android malware applications. The identified characteristics are then further explored in terms of the Android Botnet Development Model and the Android Botnet Discovery Process. The common identified trends and characteristics aid the understanding of Android botnet activities as well as the possible discovery of an Android bot. © 2012 IEEE.},
author_keywords={Android;  application;  botnet;  characteristics;  malware;  trends},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Suoranta201270,
author={Suoranta, S. and Andrade, A. and Aura, T.},
title={Strong authentication with mobile phone},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2012},
volume={7483 LNCS},
pages={70-85},
doi={10.1007/978-3-642-33383-5_5},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866983129&doi=10.1007%2f978-3-642-33383-5_5&partnerID=40&md5=f091409670b467e96f519b300533ba49},
affiliation={Aalto University, Department of Computer Science and Engineering, Espoo, Finland},
abstract={As critical services and personal information are moving to the online world, password as the only user authentication method is no longer acceptable. The capacity of the human memory does not scale to the ever larger number of ever stronger passwords needed for these services. Single sign-on (SSO) systems help users cope with password fatigue, but SSO systems still mostly lack support for strong two-factor authentication. At the same time, the users have adopted mobile phones as personal digital assistants that are used both for accessing online services and for managing personal information. The phones increasingly include mobile trusted computing technology that can be used for hardware-based storage of user credentials. Thus, it is rather obvious that the mobile phones should be used as authentication tokens for critical online services. In this paper, we show that existing open-source software platforms and commonly available mobile devices can be used to implement strong authentication for an SSO system. We use the Internet-enabled mobile phone as a secure token in a federated single sign-on environment. More specifically, we extend the Shibboleth SSO identity provider and build an authentication client based on a Nokia hardware security module. Our system design is modular, and both the SSO solution and the hardware-based security module in the phone can be replaced with other similar technologies. In comparison to most commercially available strong authentication services, our system is open in the sense that it does not depend on a specific credential issuer or identity provider. Thus, it can be deployed by any organization without signing contracts with or paying fees to a third party. No modifications need to be made to the client web browser or to the online service providers. We conclude that it is possible to implement strong personal authentication for an open-source SSO system with low start-up and operating costs and gradual deployment. © 2012 Springer-Verlag.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yu2012,
author={Yu, S.-Y. and Hammerla, N. and Yan, J. and Andras, P.},
title={A statistical aimbot detection method for online FPS games},
journal={Proceedings of the International Joint Conference on Neural Networks},
year={2012},
doi={10.1109/IJCNN.2012.6252489},
art_number={6252489},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865072838&doi=10.1109%2fIJCNN.2012.6252489&partnerID=40&md5=5b5b32e58c44a33a4a6ce63197b61147},
affiliation={School of Computing Science, Newcastle University, United Kingdom},
abstract={First Person Shooter (FPS) is a popular genre in online gaming, unfortunately not everyone plays the game fairly, and this hinders the growth of the industry. The aiming robot (aimbot) is a common cheating mechanism employed in this genre, it differs from many other common online bots in that there is a human operating alongside the bot, and thus the in-game data exhibit both human and bot-like behaviour. The aimbot users can aim much better than the average player. However, there are also a large number of highly skilled players who can aim much better than the average player, some of these players have in the past been banned from servers due to false accusations from their peers. Therefore, it would be interesting to find out if and where the honest player's and the bot user's behaviour differ. In this paper we investigate the difference between the aiming abilities of aimbot users and honest human players. We introduce two novel features and have conducted an experiment using a modified open source FPS game. Our data shows that there is significant difference between behaviours of honest players and aimbot users. We propose a voting scheme to improve aimbot detection in FPS based on distribution matching, and have achieved approximately 93% in both True positive and True negative rates with one of our features. © 2012 IEEE.},
author_keywords={Cheating Detection;  Computer Games;  Distribution Comparison;  First Person Shooters;  Game Bots;  Statistical Analysis;  Voting Scheme},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Allison201295,
author={Allison, D.},
title={Chatbots in the library: Is it time?},
journal={Library Hi Tech},
year={2012},
volume={30},
number={1},
pages={95-107},
doi={10.1108/07378831211213238},
note={cited By 25},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857763429&doi=10.1108%2f07378831211213238&partnerID=40&md5=f4e135a2d97e9dafcbfd9bed5edfb6f0},
affiliation={University of Nebraska-Lincoln, Lincoln, Nebraska, United States},
abstract={This paper aims to describe a pilot at the University of Nebraska-Lincoln for a chatbot that answers questions about the library and library resources. The chatbot was developed using a SQL database to store the question and answers using artificial intelligence mark-up language metadata. The user interface was built using PHP, adapted from Program-O. The open source PHP program was modified to support better display and the launching of URLs within the chatbot screen. Database content was created by “mining” library websites for information, and analyzing chat logs. The chatbot answers questions from a variety of users from around the world. It has attracted an unexpected number of social chatters, which required some additional metadata to accommodate personal chatting and to guide questions back to the intent of the project. The majority of questions are directional or factual questions that Pixel can handle. The database proved to be practical to build and revise as library resources and personnel changed. The chatbot provides a 24 hour, seven day a week service that is consistent, can be enhanced as resources, services, or staff change, and provides a playful interface that engages users. It replaces complicated navigation systems and scrolling through search results with more targeted answers, and has the ability to refer questions to librarians. Although chatbots have been around for several decades, there is a scarcity of reports in published library literature about their use in libraries. © 2012, Emerald Group Publishing Limited},
author_keywords={Artificial intelligence;  Chatbot;  Libraries;  Library facilities;  Library users;  Reference},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Haug20121,
author={Haug, S.A. and Weisshardt, F. and Verl, A.},
title={Automatic camera and kinematic calibration of a complex service robot},
journal={Informatik aktuell},
year={2012},
pages={1-9},
doi={10.1007/978-3-642-32217-4_1},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890050362&doi=10.1007%2f978-3-642-32217-4_1&partnerID=40&md5=c990f22019e9135ad951e3c3dcf0fc2c},
affiliation={Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Robot and Assistive Systems - Service Robot Applications, Nobelstr. 12, 70569 Stuttgart, Germany},
abstract={Service robots operate in unstructured environments where precise and reliable calibration of vision and manipulation components is essential for successful and safe operation. So far the calibration of the service robot Care-O-bot® 3 covering only the camera sensors is not precise enough for manipulation of small objects and involves many manual error-prone steps. In an evolving research context there is constant need for recalibration and therefore a complete and precise yet quick and easy to use calibration procedure is desired. We propose an automated calibration process covering the cameras and kinematic components of a service robot and present an open-source implementation for Care-O-bot® 3. © 2012 Springer-Verlag Berlin Heidelberg.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Giraldo201276,
author={Giraldo, C.A. and Florian-Gaviria, B. and Bacca-Cortes, E.B. and Gómez, F. and Muñoz, F.},
title={A programming environment having three levels of complexity for mobile robotics [Entorno de programación con tres niveles de complejidad para robótica móvil]},
journal={Ingenieria e Investigacion},
year={2012},
volume={32},
number={3},
pages={76-82},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873726007&partnerID=40&md5=0a93579873fe86082df589b1e636d1e8},
affiliation={ATOS International, Spain; EISC, Universidad del Valle, Colombia; EIEE, Universidad del Valle, Colombia; Universidad del Valle, Colombia},
abstract={This paper presents a programming environment for supporting learning in STEM, particularly mobile robotic learning. It was designed to maintain progressive learning for people with and without previous knowledge of programming and/or robotics. The environment was multi-platform and built with open source tools. Perception, mobility, communication, navigation and collaborative behaviour functionalities can be programmed for different mobile robots. A learner is able to programme robots using different programming languages and editor interfaces: graphic programming interface (basic level), XML-based meta-language (intermediate level) or ANSI C language (advanced level). The environment supports programme translation transparently into different languages for learners or explicitly on learners' demand. Learners can access proposed challenges and learning interfaces by examples. The envi-ronment was designed to allow characteristics such as extensibility, adaptive interfaces, persistence and low software/hardware coupling. Functionality tests were performed to prove programming environment specifications. UV-BOT mobile robots were used in these tests.},
author_keywords={Meta-language;  Mobile robot;  Programming environment;  STEM},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Mendonça2011185,
author={Mendonça, L. and Santos, H.},
title={Botnet detection: A numerical and heuristic analysis},
journal={10th European Conference on Information Warfare and Security 2011, ECIW 2011},
year={2011},
pages={185-193},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872929702&partnerID=40&md5=c80c28b5485ba4a21adca74c0566a790},
affiliation={Universidade do Minho, Braga, Portugal},
abstract={Internet cyber criminality has changed its ways since the old days where attacks were greatly motivated by recognition and glory. A new era of cyber criminals are on the move. Real armies of robots (bots) swarm the internet perpetrating precise, objective and coordinated attacks on individuals and organizations. Many of these bots are now coordinated by real cybercrime organizations in an almost open-source driven development, which results in the proliferation of many bot variants with refined capabilities and increased detection complexity. Economical and reputation damages are difficult to quantify but the scale is widening. It's up to one's own imagination to figure out how much was lost in April of 2007 when Estonia suffered the well known distributed attack on its internet countrywide infrastructure. Among the techniques available to mitigate this threat, botnet detection emerges as a relevant solution. This technology has also evolved in recent years but it is still far from a definitive solution. New techniques, constantly appearing, in areas such as host infection, deployment, maintenance, control and dissimulation of bots are constantly changing the detection vectors thought and developed. In that way, research and implementation of anomaly-based botnet detection systems is fundamental to pinpoint and track the continuously changing botnets and clones, which are impossible to identify by simple signature-based systems. This paper presents the studies and tests made to define an effective set of traffic parameters capable of modeling both normal and abnormal activity of networks, focusing in botnet activity detection through behavior, numerical and heuristic modeling. Different types of botnets (IRC, P2P, HTTP, fast-flux among others) are initially analyzed followed by the study of some existing detection techniques and tools like Honeynet, Botsniffer and Botminner. Following this initial study, numerical and heuristic aspects of both normal and bot traffic are investigated. Finally, a set of traffic parameters is proposed aiming fast and precise botnet detection, with low false positive rate.},
author_keywords={Anomaly-based;  Behavior;  Botnet detection;  Heuristics;  Numerical},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kubi2011,
author={Kubi, A.K. and Saleem, S. and Popov, O.},
title={Evaluation of some tools for extracting e-evidence from mobile devices},
journal={2011 5th International Conference on Application of Information and Communication Technologies, AICT 2011},
year={2011},
doi={10.1109/ICAICT.2011.6110999},
art_number={6110999},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855948507&doi=10.1109%2fICAICT.2011.6110999&partnerID=40&md5=b2317c79257fc9fc67a3e27b0d6a7943},
affiliation={Department of Computer and Systems Sciences, Stockholm University, Forum 100, Isafjordsgatan 39, SE- 16440 Kista, Sweden},
abstract={In a digital world, even illegal behaviour and/or crimes may be termed as digital. This world is increasing becoming mobile, where the basic computation and communication entities are Small Scale Digital Devices (SSDDs or S2D2s) such as ordinary mobile phones, personal digital assistants, smart phones and tablets. The need to recover data, which might refer to unlawful and unethical activities gave rise to the discipline of mobile forensics, which has become an integral part of digital forensics. Consequently, in the last few years there is an abundance of mobile forensics tools, both commercial and open-source ones, whose vendors and developers make various assertions about the capabilities and the performance of their tools. The complexity and the diversity of both mobile devices and mobile forensics tools, coupled with the volatile nature of the digital evidence and the legal requirements of admissibility makes it difficult for forensics investigators to select the right tool. Hence, we have evaluated UFED Physical Pro 1.1.3.8 and XRY 5.0 following "Smartphone Tool Specifications Standard" developed by NIST, in order to start developing a framework for evaluating and referencing the "goodness" of the mobile forensic tools. The experiments and the results of the research against the core smart phone tool specifications and their associated test findings are presented in such a way that it should make it easier for the prospective mobile forensic examiner select the most adequate tool for a specific case. © 2011 IEEE.},
author_keywords={Digital Forensics;  e-Evidence;  Mobile Device Forensics and tools;  Reliability Assurance Level},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chen2011157,
author={Chen, S.-W. and Yang, C.-H. and Liu, C.-T.},
title={Design and implementation of live SD acquisition tool in Android smart phone},
journal={Proceedings - 2011 5th International Conference on Genetic and Evolutionary Computing, ICGEC 2011},
year={2011},
pages={157-162},
doi={10.1109/ICGEC.2011.46},
art_number={6042741},
note={cited By 23},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80455163130&doi=10.1109%2fICGEC.2011.46&partnerID=40&md5=992e2bc388022f46acbc606407d17c46},
affiliation={Graduate Institute of Information and Computer Education, National Kaohsiung Normal University, Kaohsiung, Taiwan; Network and Multimedia Institute, Institute for Information Industry, Taiwan},
abstract={From the end of 2007 [1], the open-source characteristic of Android platform has been the most competitive one in the smart phone market. According to recent statistics from Gartner, Android's market share in February 2010 [2] is 3.9%, rises [3] to 17.2% in August in the same year, and reaches [4] 22.7% in February 2011, which only falls behind Nokia's by 14.9%. From its skyrocketing growth rate, it can be expected that Google's Android operating system would become the dominate mobile platform. However, high market share comes with problems. For instance, in March 2011, Lookout, an information security company shows DoridDream will make the Android phones become the media of Bot Network [5]. The ever-changing criminal conduct continuously challenges how well the present digital forensics could react. Data acquisition is an important part in mobile phone forensics. As the mobile forensic software becomes more mature and popular, most of them are now facing the same problem where the internal collecting tools must be installed in the mobile phones first so the data collecting could be started in turn. Whether this process is against the concept of protecting the original crime scene in forensics is questionable. A new concept called Live SD is therefore introduced in this work. It utilizes the concept of data recovery to perform physical data acquisition in Android smart phones. This data-acquisition methodology differs from the current ones in most mobile forensics software and can effectively perform the recovery of the deleted data. © 2011 IEEE.},
author_keywords={Android;  Forensic;  Live SD;  Recovery;  Smart phone},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Basso20111131,
author={Basso, S. and Servetti, A. and De Martin, J.C.},
title={The network neutrality bot architecture: A preliminary approach for self-monitoring of internet access QoS},
journal={Proceedings - IEEE Symposium on Computers and Communications},
year={2011},
pages={1131-1136},
doi={10.1109/ISCC.2011.5983857},
art_number={5983857},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052750983&doi=10.1109%2fISCC.2011.5983857&partnerID=40&md5=5f7e617595a07349680118595f57cbed},
affiliation={NEXA Center for Internet and Society, Dipartimento di Automatica e Informatica, Politecnico di Torino, Italy; Dipartimento di Automatica e Informatica, Politecnico di Torino, Italy},
abstract={The "network neutrality bot" (Neubot) is an evolving software architecture for distributed Internet access quality and network neutrality measurements. The core of this architecture is an open-source agent that ordinary users may install on their computers to gain a deeper understanding of their Internet connections. The agent periodically monitors the quality of service provided to the user, running background active transmission tests that emulate different application-level protocols. The results are then collected on a central server and made publicly available to allow constant monitoring of the state of the Internet by interested parties. In this article we describe how we enhanced Neubot architecture both to deploy a distributed broadband speed test and to allow the development of plug-in transmission tests. In addition, we start a preliminary discussion on the results we have collected in the first three months after the first public release of the software. © 2011 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Marzuki2011150,
author={Marzuki, A. and Baba, M.D.},
title={Downlink performance evaluation of multi-mode devices in WiMAX and WiFi environment},
journal={Proceedings - 2011 IEEE Control and System Graduate Research Colloquium, ICSGRC 2011},
year={2011},
pages={150-158},
doi={10.1109/ICSGRC.2011.5991848},
art_number={5991848},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052620550&doi=10.1109%2fICSGRC.2011.5991848&partnerID=40&md5=461b993fc9c8265adc5cc853ccf3ed78},
affiliation={Faculty of Electrical Engineering, University Technology MARA, Malaysia},
abstract={The attention on WiMAX and WiFi technologies are rapidly progressing and now it is common to find them not just in laptops and personal digital assistants (PDAs), but in equipment as mobile phones, parking meters, security cameras and home entertainment equipment. A combination of WiFi and WiMAX deployment, will offer more cost-effective solution than a sole WiMAX or WiFi implementation. Its technology is best meets the demand for personal broadband services. This project is focused on the performance evaluation of WiMAX and WiFi systems. It is conducted using open source simulator called NCTUns 6.0. Several scenarios have been created, to evaluate the coexistence of WiMAX and WiFi technology. The data of the simulation results have been gathered and the performance with the effects of transport layer protocol, send rates, packet sizes, distances, bandwidth and queue length were analyzed. Based on the results obtained, the performance of both WiMAX and WiFi technology are not affected due to distances variation but its performance can be improved by using of other parameter such as packet size, bandwidth and queue length. © 2011 IEEE.},
author_keywords={delay;  packet loss;  performance;  throughput;  WiFi;  WiMAX},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Michal201160,
author={Michal, D.S. and Etzkorn, L.},
title={A comparison of player/stage/gazebo and microsoft robotics developer studio},
journal={Proceedings of the Annual Southeast Conference},
year={2011},
pages={60-66},
doi={10.1145/2016039.2016062},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052371356&doi=10.1145%2f2016039.2016062&partnerID=40&md5=fd2ebf9fcb97e2fd8af466b9e6b6dfbb},
affiliation={Computer Science Department, College of Science, University of Alabama, Huntsville, AL, United States},
abstract={Robotic development environments are a key technology for enabling the rapid advancement of the state of robotics. This paper compares two prominent robotic development environments to examine the limitations in the current state of the art. The first is Player/Stage/Gazebo which is a well established open source project. The second is Microsoft Robotics Developer Studio, a fairly new offering from a major player in the software industry. The comparison was done in two ways: 1) by examining the documented features and 2) examining usability experience gained while implementing two common mobile autonomous robotic tasks, wandering and foraging. The tasks were executed in simulation and on a 914 PC-BOT from White Box Robotics. Quantitative results were generated using a set of well defined feature and usability criteria. These results were then further analyzed by a qualitative analysis of the entire process it took to implement both tasks. © 2011 ACM.},
author_keywords={microsoft robotics developer studio;  Player/Stage/Gazebo;  robotic development environments},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Čereković2011143,
author={Čereković, A. and Pandžić, I.S.},
title={Multimodal behavior realization for embodied conversational agents},
journal={Multimedia Tools and Applications},
year={2011},
volume={54},
number={1},
pages={143-164},
doi={10.1007/s11042-010-0530-2},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959492055&doi=10.1007%2fs11042-010-0530-2&partnerID=40&md5=bfbc97a70d3127e0d3ea9fd2295d20e1},
affiliation={Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia},
abstract={Applications with intelligent conversational virtual humans, called Embodied Conversational Agents (ECAs), seek to bring human-like abilities into machines and establish natural human-computer interaction. In this paper we discuss realization of ECA multimodal behaviors which include speech and nonverbal behaviors. We devise RealActor, an open-source, multi-platform animation system for real-time multimodal behavior realization for ECAs. The system employs a novel solution for synchronizing gestures and speech using neural networks. It also employs an adaptive face animation model based on Facial Action Coding System (FACS) to synthesize face expressions. Our aim is to provide a generic animation system which can help researchers create believable and expressive ECAs. © 2010 Springer Science+Business Media, LLC.},
author_keywords={Character animation system;  Multimodal behavior realization;  Virtual characters},
document_type={Article},
source={Scopus},
}

@ARTICLE{Frantzén2011696,
author={Frantzén, M. and Ng, A.H.C. and Moore, P.},
title={A simulation-based scheduling system for real-time optimization and decision making support*},
journal={Robotics and Computer-Integrated Manufacturing},
year={2011},
volume={27},
number={4},
pages={696-705},
doi={10.1016/j.rcim.2010.12.006},
note={cited By 49},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955656034&doi=10.1016%2fj.rcim.2010.12.006&partnerID=40&md5=947764cc2a90a9c275b4aea373440687},
affiliation={Virtual Systems Research Centre, University of Skövde, Skövde SE-541 48, Sweden; Computing Sciences and Engineering, De Montfort University Leicester, LE1 9BH, United Kingdom},
abstract={This paper presents an industrial application of simulation-based optimization (SBO) in the scheduling and real-time rescheduling of a complex machining line in an automotive manufacturer in Sweden. Apart from generating schedules that are robust and adaptive, the scheduler must be able to carry out rescheduling in real time in order to cope with the system uncertainty effectively. A real-time scheduling system is therefore needed to support not only the work of the production planner but also the operators on the shop floor by re-generating feasible schedules when required. This paper describes such a real-time scheduling system, which is in essence a SBO system integrated with the shop floor database system. The scheduling system, called OPTIMISE scheduling system (OSS), uses real-time data from the production line and sends back expert suggestions directly to the operators through Personal Digital Assistants (PDAs). The user interface helps in generating new schedules and enables the users to easily monitor the production progress through visualization of production status and allows them to forecast and display target performance measures. Initial results from this industrial application have shown that such a novel scheduling system can help both in improving the line throughput efficiently and simultaneously supporting real-time decision making. © 2011 Elsevier Ltd.},
author_keywords={Scheduling;  Scheduling system;  Simulation;  Simulation-based optimization},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Naone201162,
author={Naone, E.},
title={Managing users by the million},
journal={Technology Review},
year={2011},
volume={114},
number={4},
pages={62-63},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960091091&partnerID=40&md5=ec6d3d8dcd5fd2af64afb3ab749f12d7},
abstract={A successful social networking site is one which has mastered how to store, secure, and quickly access and analyze the data. A study shows that Twitter's users were generating 12 terabytes a day, which adds up to four petabytes a year, or the equivalent of 83,000 Blu-ray video disks. Twitter uses an open-source database called Cassandra that is designed to work at large scales, with processing tasks distributed across a variety of relatively cheap servers. Social networks analyze the personal information provided by users to offer advertisers closely targeted commercial placement, a business that is worth billions of dollars per year and growing. The social-gaming network Zynga tracks sites that host hacks, bots, and cheats and monitors users suspected of bad behavior. Facebook has also introduced the option of texting a pass code to a user's phone when that person's account is accessed from a new computer, preventing unauthorized access to an account if a password is compromised.},
document_type={Short Survey},
source={Scopus},
}

@ARTICLE{Santos-Pérez2011109,
author={Santos-Pérez, M. and González-Parada, E. and Cano-García, J.M.},
title={AVATAR: An open source architecture for embodied conversational agents in smart environments},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2011},
volume={6693 LNCS},
pages={109-115},
doi={10.1007/978-3-642-21303-8_15},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958231380&doi=10.1007%2f978-3-642-21303-8_15&partnerID=40&md5=1797d3858a932c4ddb2067318b021dd3},
affiliation={Electronic Technology Department, School of Telecommunications Engineering, University of Malaga, 29071 Malaga, Spain},
abstract={Due to a growing older population, researchers and industry are paying more attention to the needs of this group of people. Ambient Intelligence (AmI) aims to help people in their daily lives, achieving a more natural interaction of users with an electronic home environment. Embodied Conversational Agents (ECAs) arise as a natural interface between humans and AmI. Our contribution is to present AVATAR: an architecture to develop ECAs based on open source tools and libraries. In the current prototype the virtual agent acts as a natural control interface of the home automation system. In addition, we provide the details to allow its use by Spanish speakers. © 2011 Springer-Verlag.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Rodriguez2011,
author={Rodriguez, D. and Lu, K. and Aceros, C.},
title={SIRLAB-NETSIG integration for environmental surveillance monitoring in wireless mesh sensor networks},
journal={2011 IEEE 2nd Latin American Symposium on Circuits and Systems, LASCAS 2011 - Conference Proceedings},
year={2011},
doi={10.1109/LASCAS.2011.5750270},
art_number={5750270},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955985740&doi=10.1109%2fLASCAS.2011.5750270&partnerID=40&md5=a7e855221be9a41c989e46e824ab5cf7},
affiliation={Department of Electrical and Computer Engineering, University of Puerto Rico, Mayaguez Campus, Puerto Rico},
abstract={This paper presents a framework for integrating, in a unified manner (a single architecture), distributed signal processing and wireless mesh sensor network operations for environmental surveillance monitoring applications. The distributed signal processing operations center on the use of time-frequency tools for the analysis of bioacoustic signals and their representations. The wireless mesh sensor network operations center on the efficient transfer of information content from a source to a user through wireless communications optimization techniques under a versatile service oriented paradigm. An open source computational modeling framework, named SIRLAB, was developed to address time-frequency signal analysis and representation in a distributed signal processing, wireless mesh sensor network, environment. An embedded computing module, termed NETSIG, was developed to integrate wireless mesh network routing, coding, and security tasks with adaptive, large-scale, high-bandwidth, signal processing tasks. The integrated SIRLAB-NETSIG concept was tested in the laboratory, with user interface visualization applications being developed on portable digital assistants utilized as network clients. Frame rates close to 30 frames per second where achieved for some user interface visualization operations in a wireless mesh cloud testbed. © 2011 IEEE.},
author_keywords={Bioacoustics;  distributed signal processing;  NETSIG;  Service oriented mesh cloud;  SIRLAB},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Rossi2011820,
author={Rossi, P.G. and Carletti, S.},
title={MAPIT: A pedagogical-relational ITS},
journal={Procedia Computer Science},
year={2011},
volume={3},
pages={820-826},
doi={10.1016/j.procs.2010.12.135},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952494532&doi=10.1016%2fj.procs.2010.12.135&partnerID=40&md5=e98c2135bcce2c6e825fa3564898c656},
affiliation={Università Degli Studi di Macerata, Faculty of Education, P. Bertelli, Macerata, 62100, Italy},
abstract={The majority of Intelligent Tutoring System architectures are focused on supporting learners through content retrieval or in one or more given subject matters; examples of this can be found in Baghera [1], MyClass, Andes [2], Gramy, Advanced Geometry Tutor [7]. The implementation of such architectures are time-consuming and are generally not interoperable with other domains [3]. The presented research describes the experimentation of a Open Source, LMS enhanced with elements of AI aiming at supporting online teachers' and tutors' work by using a KB specific to relational and pedagogical aspects, not connected to a specific subject matter. Such implementation needs to be provided of an authoring tool easily and readily usable by tutors and teachers of different subjects and with medium level IT training. Starting point of our investigation has been a preliminary analysis of machine-mediated, human-human interactions (MM-HHI) and communications by using the Teachers' thinking approach [4] [5] [6]. We considered messages exchanged between teachers/tutors and online students in three post-graduate, online courses running at the University of Macerata during 2008 - 2010 by the Faculty of Education. The study showed that about 30% of messages concerned structured information that could be straightforwardly retrieved by an artificial agent; almost all remaining messages were instead deeply bound to student's learning path or required a significant input by the teacher/tutor, while the residual part of messages could - to some extents - be delegated to an intelligent agent having access to students' tracking data in order to display visual information to users or trigger alarms to tutors. The investigation carried out prompted us for the deployment of an Open Source chat-bot system that would retrieve information already coded into the courses or originated by students through the analysis of their activity logs; the chat-bot agent uses this structured information in order to answer students' most common questions hence relieving teachers and tutors from doing this repetitive task. The system is being implemented on a OLAT ver. 6.3 LMS loosely coupled to a JADE-based Multi Agent System in charge of processing user tracking data and running the ALICE chat-bot integrated with the platform messaging system. © 2010 Published by Elsevier Ltd.},
author_keywords={Chat-bot;  Intelligent Tutoring System;  Learning management system;  Multi Agent System;  Teachers' thinking;  Tracking data},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chu2011211,
author={Chu, H.-C. and Deng, D.-J. and Chao, H.-C.},
title={The digital forensics of portable electronic communication devices based on a Skype im session of a pocket PC for NGC},
journal={Wireless Communications and Mobile Computing},
year={2011},
volume={11},
number={2},
pages={211-225},
doi={10.1002/wcm.954},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951999328&doi=10.1002%2fwcm.954&partnerID=40&md5=f24ac6989107093cf1f8d17525cd9fb1},
affiliation={Department of Information Management/International Business, Tunghai University, Taiwan; Department of Computer Science and Information Engineering, National Changhua University of Education, Taiwan; Institute of Computer Science and Information Engineering, Department of Electronic Engineering, National ILan University, I-Lan, Taiwan},
abstract={Portable electronic communication devices can be used for many purposes and they are capable of integrating with ubiquitous computing (UC) infrastructures to carry on mobile multimedia communications. As those devices become prevalent, they incur potential network security threatening to organizations. Nowadays, the Skype is the most popular P2P VoIP application program, which is being used by millions of global users to place IP phone calls, transfer files, or communicate via instant messaging (IM). This phenomenon already generates imminent network security issues that are indispensable to digital forensics researchers or the law enforcement agencies worldwide. Cellular phones, smart phones, and personal digital assistants (PDAs) are the representative ones of those devices and there are some open sources or commercial software toolkits that can be utilized to proceed the forensics investigation concerning the electronic crimes in next generation communications (NGCs). A case review was conducted to illustrate the hidden digital trails within the PDA from the Registry of the Windows Mobile and volatile data in the RAM to discover the possible network security leakage scenarios that resulted in the vandalism of intangible digital assets of the organization. Copyright © 2010 John Wiley & Sons, Ltd.},
author_keywords={mobile computing;  network forensics;  next generation communications;  portable electronic communication device forensics;  Skype instant messaging},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Recktenwald2011,
author={Recktenwald, G.W. and Hall, D.E.},
title={Using Arduino as a platform for programming, design and measurement in a freshman engineering course},
journal={ASEE Annual Conference and Exposition, Conference Proceedings},
year={2011},
page_count={23},
note={cited By 36},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029092677&partnerID=40&md5=0aba699b32d7ee4af55ef7a81c3a54e1},
affiliation={Mechanical and Materials Engineering Department, Portland State University, United States; Department of Mechanical Engineering, Louisiana Tech University, United States},
abstract={Arduino is a compact, inexpensive, open-source electronics prototyping platform built around an Atmel AVR microcontroller. The features, cost, and small size makes Arduino a potent tool teaching as well as practical device use in engineering projects. This paper reports on adapting the Living with the Lab (LWTL) curriculum to the Arduino platform. LWTL was developed with the Boe-Bot mobile robotics platform and the Basic Stamp microcontroller. The Arduino is more modern and has better technical capabilities, but there are fewer educational resources for the Arduino than there are for the Boe-Bot. The updated curriculum was successfully implemented at two universities. End-of-term surveys indicate that students had a positive experience of the course, especially the hands-on exercises. However, students were not as positive about the current state of instructional support for Arduino programming. The Arduino remains a viable and preferable platform. Recommendations for improvement of curricular materials for the Arduino are made. © 2011 American Society for Engineering Education.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Li2011127,
author={Li, B. and Zhang, J. and Dempster, A.G. and Rizos, C.},
title={Open source GNSS reference server for Assisted-Global Navigation Satellite Systems},
journal={Journal of Navigation},
year={2011},
volume={64},
number={1},
pages={127-139},
doi={10.1017/S037346331000038X},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650322286&doi=10.1017%2fS037346331000038X&partnerID=40&md5=a9d60186376c0c6bda6c241ac3c62274},
affiliation={School of Surveying and Spatial Information Systems, University of New South Wales, Australia},
abstract={Assisted-Global Navigation Satellite Systems (A-GNSS), or Assisted-Global Positioning Systems (A-GPS) in particular, are now commonly accepted as an effective way to reduce the time-to-first-fix (TTFF) in GNSS-unfriendly environments, e.g. in areas of weak GNSS signals. Today's location-based service (LBS) devices such as GPS-enabled mobile phones and personal digital assistants (PDA) rely on A-GPS; however, such commercial devices are equipped with an integrated A-GPS chip that makes customisation very difficult. The Open Source GNSS Reference Server (OSGRS) provided by the University of New South Wales is an open source Java application that can generate the necessary data for A-GPS clients. The GNSS Reference Interface Protocol (GRIP), based on extensible mark-up language (XML), is employed as the OSGRS interface protocol. This paper describes the current status of OSGRS: a client simulator is available open-source; client software which supports four different types of A-GPS-enabled receivers has been developed and used to test OSGRS. The performance of the OSGRS is analysed based on intensive tests. The challenges for OSGRS and future work are also discussed. © The Royal Institute of Navigation 2010.},
author_keywords={A-GNSS;  A-GPS;  GRIP;  OSGRS},
document_type={Article},
source={Scopus},
}

@ARTICLE{Rempis2010121,
author={Rempis, C. and Thomas, V. and Bachmann, F. and Pasemann, F.},
title={NERD neurodynamics and evolutionary robotics development kit},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2010},
volume={6472 LNAI},
pages={121-132},
doi={10.1007/978-3-642-17319-6_14},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650278850&doi=10.1007%2f978-3-642-17319-6_14&partnerID=40&md5=6d139ced359eb20ed590129af3cb6fe1},
affiliation={Institute of Cognitive Science, University of Osnabrück, Germany},
abstract={The aim of Evolutionary Robotics is to develop neural systems for behavior control of autonomous robots. For non-trivial behaviors or non-trivial machines the implementation effort for suitably specialized simulators and evolution environments is often very high. The Neurodynamics and Evolutionary Robotics Development Kit (NERD), presented in this article, is a free open-source framework to rapidly implement such applications. It includes separate libraries (1) for the simulation of arbitrary robots in dynamic environments, allowing the exchange of underlying physics engines, (2) the simulation, manipulation and analysis of recurrent neural networks for behavior control, and (3) an extensible evolution framework with a number of neuro-evolution algorithms. NERD comes with a set of applications that can be used directly for many evolutionary robotics experiments. Simulation scenarios and specific extensions can be defined via XML, scripts and custom plug-ins. The NERD kit is available at nerd.x-bot.org under the GPL license. © 2010 Springer-Verlag Berlin Heidelberg.},
author_keywords={Evolutionary Robotics;  Neuro-evolution;  Simulation},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Lefranc2010387,
author={Lefranc, H. and Núñez, R. and Steventon, J.},
title={New technologies for long-term biodiversity monitoring: Data quality and real-time availability},
journal={Conservation Monitoring in Freshwater Habitats A Practical Guide and Case Studies},
year={2010},
pages={387-397},
doi={10.1007/978-1-4020-9278-7_32},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900719701&doi=10.1007%2f978-1-4020-9278-7_32&partnerID=40&md5=818bd44d5c94fbc025e2ed76b715db37},
affiliation={Natural Processes Monitoring Team, Doñana Biological Station, CSIC, Seville, Spain; Advanced Technology Systems, SATEC, Seville, Spain; Steventon Consulting, Redmond, WA 98052, United States},
abstract={Information on biodiversity and ecosystems is essential for governments, and for the scientific and educational communities. Furthering access to this information is of vital importance in the face of the rapid decline of biological diversity. The object of this chapter to describe the solution developed to facilitate the process of data collection and the use of long-term monitoring information by the Natural Processes Monitoring Team (Equipo de Seguimiento de Procesos Naturales, ESPN) of the Doñana Natural Park. The basic design enabled the use of Personal Digital Assistants in a network, with all databases migrating to a single server. New technologies have the potential to revolutionise the process of data gathering. One of the most revolutionary of these new technologies is the free software CyberTracker. This program as an ideal tool for the normalisation and harmonisation of data acquisition protocols that guarantees the quality and quasi-real time availability of data for the final user. © Springer Science+Business Media B.V. 2010.},
author_keywords={biodiversity;  CyberTracker;  long-term monitoring;  New technologies;  real-time},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Weisshardt20101115,
author={Weisshardt, F. and Reiser, U. and Parlitz, C. and Verl, A.},
title={Making high-Tech service robot platforms available},
journal={Joint 41st International Symposium on Robotics and 6th German Conference on Robotics 2010, ISR/ROBOTIK 2010},
year={2010},
volume={2},
pages={1115-1120},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855373659&partnerID=40&md5=86d3e13bbb665f9f3e8d266897b305cf},
affiliation={Fraunhofer IPA, Robot Systems, Stuttgart, Germany; SCHUNK GmbH and Co. KG, Lauffen, Germany},
abstract={The development of reliable, robust and capable service robot platforms is expensive and time consuming. On the other hand, stable hardware is a prerequisite to be able to concentrate on the targeted research area. This paper proposes a strategy to make such high-end service robot platforms available as research platform, by means of the example of Care-O-bot® 3 developed at Fraunhofer IPA. Several methods to provide robotic hardware for research are introduced, starting from the maintenance of a common open-source repository, to the making available of simulation models of the hardware components and the possibility of remote access via a web-interface. It is shown, that Care-O-bot® 3 is particularly suited as research platform through the modular structure of its hardware components. Thus, a very flexible set-up for Care-O-bot® 3 is possible, making it easy to adapt to the specific requirements of different robotic research fields.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mayer201035,
author={Mayer, N.M. and Lu, L.-W. and Hung, Y.-M. and Wu, H. and Chang, Y.-C.},
title={Using U-Bot for RoboCup@home},
journal={Proceedings of the SICE Annual Conference},
year={2010},
pages={35-36},
art_number={5602488},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649251632&partnerID=40&md5=712c5f42f2fea6316826b3716497ba62},
affiliation={National Chung Cheng University, Chia-Yi, Taiwan},
abstract={In 2006 the RoboCup@home league was founded as part of the RoboCup competition[1]. Different from other robot competitions the venue is placed in an everyday human environment, where the robot has to perform a set of service tasks. Basing on the mobile U-Bot platform manufactured by the Taiwanese Industrial Technology Research Institute (ITRI) we design an integrated mobile robot in order to participate at this competition. One principle of our team is to use only open source software. © 2010 SICE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Rossi200976,
author={Rossi, P.G. and Carletti, S. and Bonurai, D.},
title={A platform-independent tracking and monitoring toolkit},
journal={AAAI Fall Symposium - Technical Report},
year={2009},
volume={FS-09-02},
pages={76-80},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954235083&partnerID=40&md5=e135ec3dd78856731654c899c24332f1},
affiliation={Università degli Studi di Macerata, Italy},
abstract={Issues concerning students involved with online learning paths, that need to be faced by e-Tutors on their day-to-day activity, most often than not fall into known pedagogical patterns - that are problems and difficulties already occurred in the past and dealt with. These pedagogical patterns belong to e-Tutors' know-how and experience and their resolution are frequently a matter of activating routine processes or giving pre-factored answers; nevertheless statistical data indicates that these issues consume a considerable slice of tutors' time. While a portion of the scientific community is still devoting much effort in developing artificial tutoring systems - by deploying AI/MAS-enabled technologies - the solution being investigated by our team focuses on enhancing already-available, open source LMS by implementing a general-purpose tracking and monitoring toolkit able to support e-Tutors in recognizing and dealing with pedagogical patterns stored into a decentralised Knowledge Base. The system architecture is designed to house multiple platforms (only one adapter interface needs to be written for each LMS) and is able to perform real-time, as well as scheduled, data collection by means of Jade-based agents and schedulers. Information obtained from the processed data is then returned to the platform via web services and specific interfaces (instant messaging chatbot). The first deployed prototype is currently being experimented in adult higher education learning paths and is able to track student activity, forum readings and writings and offers a basic chat-based help interface. Our aim is to turn a standard LMS into a knowledge aggregator where information about its users, its contents and interactions between the two can be mined via Knowledge Services; resulting data could then be used to refine users' and groups' profiles, to monitor learners' deviance from expected learning path, and ultimately to adjust the applied pedagogical model. Copyright © 2009, Association for the Advancement of Artificial Intelligence. All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Moriarty2009439,
author={Moriarty, C. and Gonzalez, A.J.},
title={Learning human behavior from observation for gaming applications},
journal={Proceedings of the 22nd International Florida Artificial Intelligence Research Society Conference, FLAIRS-22},
year={2009},
pages={439-444},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350500053&partnerID=40&md5=4c1d97e793efb073be6b4efeb0dcf231},
affiliation={Intelligent Systems Laboratory, School of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL 32816-2450, United States},
abstract={The gaming industry has reached a point where improving graphics has only a small effect on how much a player will enjoy a game. The focus has turned to adding more humanlike characteristics into computer game agents. Machine learning techniques are scarcely being used in games, although they do offer powerful means for creating humanlike behaviors in agents. The first person shooter (FPS), Quake 2, is an open source game that offers a multi-agent environment in which to create game agents (bots). The work described in this paper seeks to combine neural networks with a modeling paradigm known as context based reasoning (CxBR) to create a contextual game observation (CONGO) system that produces humanlike Quake 2 bots. A default level of intelligence is instilled into the bots through contextual scripts to prevent the bot from being trained to be completely useless. The results show that the humanness and entertainment value as compared to a traditional scripted bot have improved, although, CONGO bots usually ranked only slightly above a novice skill level. Overall, CONGO offers the gaming community a mode of game play that has promising entertainment value. Copyright © 2009, Assocation for the Advancement of ArtdicaI Intelligence (www.aaai.org). All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bickmore2009425,
author={Bickmore, T. and Schulman, D. and Shaw, G.},
title={DTask and litebody: Open source, standards-based tools for building web-deployed embodied conversational agents},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2009},
volume={5773 LNAI},
pages={425-431},
doi={10.1007/978-3-642-04380-2_46},
note={cited By 22},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350385358&doi=10.1007%2f978-3-642-04380-2_46&partnerID=40&md5=c4e64240fe0e20a058c08d8f4e71fa09},
affiliation={Northeastern University, College of Computer and Information Science, 360 Huntington Ave, WVH202, Boston, MA 02115, United States},
abstract={Two tools for developing embodied conversational agents and deploying them over the world-wide web to standard web browsers are presented. DTask is a hierarchical task decomposition-based dialogue planner, based on the CEA-2018 task description language standard. LiteBody is an extensible, web-based BML renderer that runs in most contemporary web browsers with no additional software and provides a conversational virtual agent with a range of conversational nonverbal behavior adequate for many user-agent interaction applications. Together, these tools provide a complete platform for deploying web-based conversational agents, and are actively being used on two health counseling applications. © 2009 Springer Berlin Heidelberg.},
author_keywords={Behavior markup language;  Dialogue planning;  Embodied conversational agent;  Open source;  Relational agent},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Yu2009532,
author={Yu, P. and de Courten, M. and Pan, E. and Galea, G. and Pryor, J.},
title={The development and evaluation of a PDA-based method for public health surveillance data collection in developing countries},
journal={International Journal of Medical Informatics},
year={2009},
volume={78},
number={8},
pages={532-542},
doi={10.1016/j.ijmedinf.2009.03.002},
note={cited By 64},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349211448&doi=10.1016%2fj.ijmedinf.2009.03.002&partnerID=40&md5=c16e8711028da13576bd4c32b1d64780},
affiliation={School of Information Systems and Technology, University of Wollongong, Wollongong, 2522, Australia; Department of Epidemiology and Preventive Medicine, Monash University, The Alfred, Commercial Road, Melbourne, Vic. 3004, Australia; Royal Prince Alfred Hospital, Sydney, Australia; Health Promotion, World Health Organization, Geneva, Switzerland; Fiji School of Medicine, Fiji},
abstract={Background and purpose: EpiData and Epi Info are often used together by public health agencies around the world, particularly in developing countries, to meet their needs of low-cost public health data management; however, the current open source data management technology lacks a mobile component to meet the needs of mobile public health data collectors. The goal of this project is to explore the opportunity of filling this gap through developing and trial of a personal digital assistant (PDA) based data collection/entry system. It evaluated whether such a system could increase efficiency and reduce data transcription errors for public surveillance data collection in developing countries represented by Fiji. Methods: A generic PDA-based data collection software eSTEPS was developed. The software and the data collected using it directly interfaces with EpiData. A field trial was conducted to test the viability of public health surveillance data collection using eSTEPS. The design was a randomised, controlled trial with cross-over design. 120 participants recruited from the Fiji School of Medicine were randomly assigned to be interviewed by one of six interviewers in one of the two ways: (1) paper-based survey followed by PDA survey and (2) PDA survey followed by paper-based survey. Data quality was measured by error rates (logical range errors/inconsistencies, skip errors, missing values, date or time field errors and incorrect data type). Work flow and cost were evaluated in three stages of the survey process: (1) preparation of data collection instrument, (2) data collection and (3) data entry, validation and cleaning. User acceptance was also evaluated in the two groups of participants: (1) data collectors and (2) survey participants. Results: None of the errors presented in 20.8% of the paper questionnaires was found in the data set collected using PDA. Sixty-two percent of the participants perceived that the PDA-based questionnaire took less time to complete. Data entry, validation and cleaning for the PDA-based data collection from 120 participants took a total of 1.5 h, a 93.26% reduction of time from 20.5 h required using paper and pen. The cost is also significantly reduced with PDA-based protocol. Both data collectors and participants prefer to use PDA instead of paper for data collection. The trial results prove that eSTEPS is a feasible solution for public health surveillance data collection in the field. Several deficiencies of the software were also identified and would be addressed in the next version. Conclusion: eSTEPS offers the potential to meet the need for an effective mobile public health data collection tool for use in the field. The eSTEPS field trial proves that PDA was more efficient than paper for public health survey data collection. It also significantly reduced errors in data entry. The later benefit was derived from the software providing its users with the flexibility of building their own constraints to control the data type, range and logic of data entry. © 2009 Elsevier Ireland Ltd. All rights reserved.},
author_keywords={Cost-benefit analysis;  Data collection;  Handheld computer;  Paper;  PDA;  Public health;  Randomised controlled trial},
document_type={Article},
source={Scopus},
}

@ARTICLE{Soupionis200925,
author={Soupionis, Y. and Tountas, G. and Gritzalis, D.},
title={Audio CAPTCHA for SIP-based VoIP},
journal={IFIP Advances in Information and Communication Technology},
year={2009},
volume={297},
pages={25-38},
doi={10.1007/978-3-642-01244-0_3},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-83455241546&doi=10.1007%2f978-3-642-01244-0_3&partnerID=40&md5=fbda126d24426e6b8ddca5c1515facb8},
affiliation={Information Security and Critical Infrastructure Protection Research Group Dept. of Informatics, University of Economics and Business, Athens, Greece},
abstract={Voice over IP (VoIP) introduces new ways of communication, while utilizing existing data networks to provide inexpensive voice communications worldwide as a promising alternative to the traditional PSTN telephony. SPam over Internet Telephony (SPIT) is one potential source of future annoyance in VoIP. A common way to launch a SPIT attack is the use of an automated procedure (bot), which generates calls and produces audio advertisements. In this paper, our goal is to design appropriate CAPTCHA to fight such bots. We focus on and develop audio CAPTCHA, as the audio format is more suitable for VoIP environments and we implement it in a SIP-based VoIP environment. Furthermore, we suggest and evaluate the specific attributes that audio CAPTCHA should incorporate in order to be effective, and test it against an open source bot implementation. © IFIP International Federation for Information Processing 2009.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Nowack2008,
author={Nowack, B.},
title={SPARQLBot: The Semantic Web command line (Scripting challenge submission)},
journal={CEUR Workshop Proceedings},
year={2008},
volume={368},
page_count={2},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885210700&partnerID=40&md5=3689b79b281965ae5aed3f8ea55bf62c},
affiliation={Semsol, Bielefelder Str. 5, 40468 Düsseldorf, Germany},
abstract={SPARQLBot is an RDF-driven agent that loads structured information from the Web and reacts to user-defined questions and commands via an IRC interface. The bot is implemented using a small number of PHP scripts and ARC, an open-source PHP/MySQL-based RDF system for storage and query functionality.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Rodríguez2008193,
author={Rodríguez, E. and Burguillo, J.C. and Rodríguez, D.A. and Mikic, F.A. and González-Moreno, J.C. and Novegil, V.},
title={Developing virtual teaching assistants for open e-learning platformsi},
journal={19th EAEEIE (European Association for Education in Electrical and Information Engineering) Annual Conference - Formal Proceedings},
year={2008},
pages={193-198},
doi={10.1109/EAEEIE.2008.4610185},
art_number={4610185},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-53149124442&doi=10.1109%2fEAEEIE.2008.4610185&partnerID=40&md5=10e76389ec25e01ac9918bacf22d4164},
affiliation={Departamento de Ingeniería Telemática, ETSET; Departamento de Informatics, ESEI; Departamento de Estatística e Investigacion Operativa, FCSC Universidad de Vigo, 36310-Vigo, Spain},
abstract={Integration of Artificial Intelligence (Al) techniques within Learning Management Systems (LMS) represent a little explored field of research. We use this paper to show how these techniques can help students as well as tutors across the learning process within an open source e-learning platform. Especially, we present T-BOT and Q-BOT, a couple of chatter bots capable of tutoring and evaluating students using open platforms as Moodle or Claroline. These bots are developed in Program E, a PHP-base interpreter, and can intemperate with the students through natural language thanks to an AIML brain. © 2008 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{DeMartin2008,
author={De Martin, J.C. and Glorioso, A.},
title={The neubot project: A collaborative approach to measuring internet neutrality},
journal={International Symposium on Technology and Society, Proceedings},
year={2008},
doi={10.1109/ISTAS.2008.4559763},
art_number={4559763},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-52049126806&doi=10.1109%2fISTAS.2008.4559763&partnerID=40&md5=48e3b089ece6e60389d1e9f370863a0e},
affiliation={NEXA Center for Internet and Society, DAUIN, Politecnico di Torino, Italy},
abstract={The Internet was designed to be neutral with respect to kinds of applications, senders and destinations. Such design choice made very fast packet switching possible, while preserving, at the same time, strong openness towards unforeseen uses of the Internet Protocol. The result has been an extraordinary outburst of innovation, as well as a level playing field for citizens, associations and companies worldwide. With the advent of "deep packet inspection" technology, however, fine-grained discrimination of Internet flows is now possible, be that for economic or other reasons. Collecting quantitative data on the behavior of telecommunications providers with respect to traffic discrimination thus becomes crucial, particularly at a time when policy changes are widely discussed. The "Network Neutrality Bot" (Neubot) project is based on a lightweight, open source computer program, the Neubot, that, downloaded and installed by Internet users, performs distributed measurements of the traffic characteristics of segments of the global Internet. The collected data will allow constant monitoring of the actual state of the Internet, enabling both a deeper understanding of such crucial infrastructure and a more reliable basis for discussing network neutrality policies. ©2008 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Me2008,
author={Me, G. and Rossi, M.},
title={Internal forensic acquisition for mobile equipments},
journal={IPDPS Miami 2008 - Proceedings of the 22nd IEEE International Parallel and Distributed Processing Symposium, Program and CD-ROM},
year={2008},
doi={10.1109/IPDPS.2008.4536557},
art_number={4536557},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-51049087072&doi=10.1109%2fIPDPS.2008.4536557&partnerID=40&md5=0d384b6b01ee604ae01974b8b37b903d},
affiliation={Dipartimento di Informatica, Sistemi e Produzione, Università di Roma Tor Vergata},
abstract={Several technologies and products have emerged in the market lately for Personal Digital Assistants and smartphone data forensic acquisition. The smartphone market is very huge and provides a great variety of manufacturers and models causing a strong heterogeneity of the tools adopted to retrieve smartphone contents in a forensically sound way: in fact, in most cases, the mobile devices manufacturers implement their own (proprietary) protocols on the proprietary cable-jack and the proprietary OSs, causing the forensic operators to be overwhelmed by the one-on-one tools for every single mobile device. This paper aims to propose a new methodology and a tool to acquire the data by using the removable memory cards (e.g. SD, mini SD, MMC etc). This approach could represent a breakthrough in the mobile forensics, since the developed tool could replace the plethora of the hardware tools currently used. In this paper, firstly, we will summarize the current seizure methodology and its related problems when applied to the mobile device scenario. Then, we will introduce an alternative methodology to seize and examine the data from internal memory, overcoming some problems of the traditional methodology. At the end, we will show some experimental results of this methodology, obtained from a real device. ©2008 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Blaya2008921,
author={Blaya, J.A. and Gomez, W. and Rodriguez, P. and Fraser, H.},
title={Cost and implementation analysis of a personal digital assistant system for laboratory data collection},
journal={International Journal of Tuberculosis and Lung Disease},
year={2008},
volume={12},
number={8},
pages={921-927},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-49149085266&partnerID=40&md5=9953211b7e0d4c5c22d71e9a7343a142},
affiliation={Partners in Health, Division of Health Sciences and Technology, Harvard Massachusetts Institute of Technology, Cambridge, MA, United States; Socios en Salud Sucursal Peru, Lima, Peru; Partners in Health, Division of Social Medicine and Health Inequalities, Brigham and Women's Hospital, Boston, MA, United States; Partners in Health, Electronic Medical Record Team, 641 Huntington Ave, Boston, MA 02115, United States},
abstract={SETTING: One hundred and twenty-six public health centers and laboratories in Lima, Peru, without internet. BACKGROUND: We have previously shown that a personal digital assistant (PDA) based system reduces data collection delays and errors for tuberculosis (TB) laboratory results when compared to a paper system. OBJECTIVE: To assess the data collection efficiency of each system and the resources required to develop, implement and transfer the PDA-based system to a resource-poor setting. DESIGN: Time-motion study of data collectors using the PDA-based and paper systems. Cost analysis of developing, implementing and transferring the PDA-based system to a local organization and their redeployment of the system. RESULTS: Work hours spent collecting and processing results decreased by 60% (P < 0.001). Users perceived this decrease to be 70% and had no technical problems they failed to fix. The total cost and time to develop and implement the intervention was US$26 092 and 22 weeks. The cost to extend the system to cover nine more districts was $1125 and to implement collecting patient weights was $4107. CONCLUSION: A PDA-based system drastically reduced the effort required to collect TB laboratory results from remote locations. With the framework described, open-source software and local development, organizations in resource-poor settings could reap the benefits of this technology. © 2008 The Union.},
author_keywords={Cost analysis;  Data collection;  Developing countries;  Handheld computer;  Personal digital assistant},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tolliver200827,
author={Tolliver, M.},
title={Un-documented code and the electronics industry},
journal={Electronics World},
year={2008},
volume={114},
number={1865},
pages={27-28},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-69649094584&partnerID=40&md5=a2a04cd393526ab1fcf6d01dc25ed06a},
abstract={Mark Tolliver, CEO of Palamida discusses the virtues of open-source software along with the pitfalls for modern firms trying to comply with customer demand with technological innovation. Fundamental to achieving these goals is the use of open source code, with readily available, cost-effective and outside of the lines of the normal software procurement process, open source code is at the nexus of all of today's software development. The most recognizable embedded open source project is embedded Linux, which denotes the use of Linux OS in an embedded system typically found in mobile phones, personal digital assistants and media players. The industry believes license to ensure the device programming with digital signatures that matched to release its source code for modification. The prevalence of open source has thought-provoking implications for the electronics industry.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Saukonoja200827,
author={Saukonoja, T. and Pasanen, T.A.},
title={Texas Hold'em game server for AI-developers},
journal={Proceedings of CGAMES 2008 - 13th International Conference on Computer Games: AI, Animation, Mobile, Educational and Serious Games},
year={2008},
pages={27-29},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906971984&partnerID=40&md5=bd069f25afada88241da3f6f85ffac92},
affiliation={Department of Computer Science, Gamics Laboratory, University of Helsinki, Finland},
abstract={This paper describes the architecture of our general open source game server. The game server comes with a builtin Texas Hold'em poker plug-in which also includes an AI-interface to help AI-developers to build their own poker bots. © 2008 The University of Wolverhampton.},
author_keywords={Artificial intelligence;  Game server;  Open source;  Texas Hold'em},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Thiebaux2008150,
author={Thiebaux, M. and Marsella, S. and Marshall, A.N. and Kallmann, M.},
title={SmartBody: Behavior realization for embodied conversational agents},
journal={Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
year={2008},
volume={1},
pages={150-157},
note={cited By 173},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899965042&partnerID=40&md5=e0a9adac0ca078bf133f33cc6c745d4a},
affiliation={USC Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA, 90292, United States; University of California, Merced, School of Engineering, 5200 N. Lake Road, Merced, CA 95343, United States},
abstract={Researchers demand much from their embodied conversational agents (ECAs), requiring them to be both life-like, as well as responsive to events in an interactive setting. We find that a flexible combination of animation approaches may be needed to satisfy these needs. In this paper we present SmartBody, an open source modular framework for animating ECAs in real time, based on the notion of hierarchically connected animation controllers. Controllers in SmartBody can employ arbitrary animation algorithms such as keyframe interpolation, motion capture or procedural animation. Controllers can also schedule or combine other controllers. We discuss our architecture in detail, including how we incorporate traditional approaches, and develop the notion of a controller as a reactive module within a generic framework, for realizing modular animation control. To illustrate the versatility of the architecture, we also discuss a range of applications that have used SmartBody success-fully. Copyright © 2008, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.},
author_keywords={Character animation;  Conversational characters;  Virtual humans},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hagelbäck20081641,
author={Hagelbäck, J. and Johansson, S.J.},
title={Demonstration of Multi-agent Potential Fields in Real-Time Strategy games},
journal={Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
year={2008},
volume={3},
pages={1641-1642},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899957682&partnerID=40&md5=f0f4c4e77fe79f7ae7a95e6b26a150af},
affiliation={Department of Software and Systems Engineering, Blekinge Institute of Technology, Box 520, SE-372 25, Ronneby, Sweden},
abstract={Bots for Real Time Strategy (Rts) games provide a rich challenge to implement. A bot controls a number of units that may have to navigate in a partially unknown environment, while at the same time search for enemies and coordinate attacks to fight them down. Potential fields is a technique originating from the area of robotics where it is used in controlling the navigation of robots in dynamic environments. Although attempts have been made to transfer the technology to the gaming sector, assumed problems with efficiency and high costs for implementation have made the industry reluctant to adopt it. Our demo shows the use of Multi-agent Potential Fields (Mapf) in an open source Rts game. We will demonstrate both the potential fields as such, and the coordination of the agents. Copyright © 2008, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.},
author_keywords={Artificial potential fields;  Multi-agent bot;  Orts;  RTS games},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{ArizaMontes200799,
author={Ariza Montes, J.A. and Morales Gutiérrez, A.C. and Romeo Molina, A.},
title={Breaking through barriers in new technological initiatives: Entrepreneurs in the context of free software},
journal={Cases on Information Technology Entrepreneurship},
year={2007},
pages={99-121},
doi={10.4018/978-1-59904-612-9.ch005},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900130006&doi=10.4018%2f978-1-59904-612-9.ch005&partnerID=40&md5=59121979683949e1b1af801f5c7157c2},
affiliation={School of Business and Economic Science, University of Córdoba, Spain; Blobject Founding Partner, Spain},
abstract={This work analyzes different factors in the entrepreneuring process in a company based in business opportunities advantages through the usage of free software in a technological context. Blobject connects opportunities for local development, usage of open source technologies, and new social trends in many consumers; tourists, in this case, as a example of respect for the environment and the desired "freedom and autonomy". This company offers different products and services using ecologic vehicles (electric energy), ease-to-use, such as GEM Cars -equipped with a touch screen computer- and Tours in Segways. The studied case shows the integration process from different technologies that connect through digital infrastructure. In this way, GEM cars use the GPS technology for location within a digital assistant, multimedia power (touch screen computer and audios and videos) to show the tourist opportunities in an specific place, and the needed adaptation for the language diversity. © 2008, IGI Global.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{NoAuthor2007,
title={Proceedings of the Fifteenth ACM International Conference},
journal={Proceedings of the ACM International Multimedia Conference and Exhibition},
year={2007},
page_count={1088},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-37849039522&partnerID=40&md5=afe88f6376926174c4198d6624c16557},
abstract={The proceedings contain 199 papers. The topics discussed include: programming web multimedia applications with Hop; advene: an open-source framework for integrating and visualising audiovisual metadata; GPCA, open source multimedia framework; Xface open source project and SMIL-Agent scripting Language for creating and animating embodied conversational agents; large scale semantic structures for image retrieval; realizing multimedia processes by combining intelligent content and semantic web services; active reading of audiovisual documents; a utility-driven framework for loss and encoding aware video adaptation; Ligne-Claire video encoding for power constrained mobile environments; display pre-filtering for multi-view video compression; towards the next-plateau - innovative multimedia research beyond TRECVID; QueST; querying music databases by a acoustic and textual features; and scalable music recommendation by search.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Balci20071013,
author={Balci, K. and Not, E. and Zancanaro, M. and Pianesi, F.},
title={Xface open source project and smil-agent scripting language for creating and animating embodied conversational agents},
journal={Proceedings of the ACM International Multimedia Conference and Exhibition},
year={2007},
pages={1013-1016},
doi={10.1145/1291233.1291453},
note={cited By 29},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-37849003802&doi=10.1145%2f1291233.1291453&partnerID=40&md5=4c508a5b5764a63381aad77be2c83772},
affiliation={FBK-irst, Via Sommarive, 18, I-38050 Trento, Italy},
abstract={Xface is a set of open source tools for creation of embodied conversational agents (ECAs) using MPEG4 and keyframe based rendering driven by SMIL-Agent scripting language. Xface Toolkit, coupled with SMIL-Agent scripting serves as a full 3D facial animation authoring package. Xface project is initiated by Cognitive and Communication Technologies (TCC) division of FBK-irst (formerly ITC-irst). The toolkit is written in ANSI C++, and is open source and platform independent.},
author_keywords={3D talking heads;  Embodied conversational agents;  MPEG4 facial animation;  Open source;  Scripting;  SMIL},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Thing2007229,
author={Thing, V.L.L. and Sloman, M. and Dulay, N.},
title={A survey of bots used for distributed denial of service attacks},
journal={IFIP International Federation for Information Processing},
year={2007},
volume={232},
pages={229-240},
doi={10.1007/978-0-387-72367-9_20},
note={cited By 41},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-36249008514&doi=10.1007%2f978-0-387-72367-9_20&partnerID=40&md5=8753b5581c7161cc552ab21481757a13},
affiliation={Department of Computing, Imperial College London, 180 Queen's Gate, London SW7 2AZ, United Kingdom},
abstract={In recent years, we have seen the arrival of Distributed Denial-of-Service (DDoS) open-source bot-based attack tools facilitating easy code enhancement, and so resulting in attack tools becoming more powerful. Developing new techniques for detecting and responding to the latest DDoS attacks often entails using attack traces to determine attack signatures and to test the techniques. However, obtaining actual attack traces is difficult, because the high-profile organizations that are typically attacked will not release monitored data as it may contain sensitive information. In this paper, we present a detailed study of the source code of the popular DDoS attack bots, Agobot, SDBot, RBot and Spybot to provide an in-depth understanding of the attacks in order to facilitate the design of more effective and efficient detection and mitigation techniques. © 2007 International Federation for Information Processing.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pomaska2007,
author={Pomaska, G.},
title={Ajax web scripting applied to interactive stereoscopic imaging},
journal={International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
year={2007},
volume={36},
number={5/C53},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053621775&partnerID=40&md5=c41d262ac30be806bf3185e36053b8aa},
affiliation={University of Applied Sciences Bielefeld, Faculty of Architecture and Civil Engineering, Artilleriestr. 9, Minden, D-32427, Germany},
abstract={Creating the illusion of depth in images was first invented 1838 by Sir Charles Wheatstone. It is today still a great experience to view high quality large format images with depth perception, exceptionally of virtual objects like reconstructions of the past or building projects. High quality presentation of computer graphics is provided by projection onto a transparent screen surface from behind. Image separation can be easily performed by polarisation filters in front of the projection lenses. It is necessary that the beholders carry polarized glasses. Interactive viewing in this context means, that the observer is able to select image pairs from the database, can zoom in and out, select the display details and sets the zero parallax to an arbitrary position. The selection must be simultaneously transferred to the second image of the stereoscopic pair. While each data projector is driven by its own computer, a PDA (personal digital assistant) is recommended to receive the instructions from the presenter or viewer. That network configuration requires amongst other software tools Bluetooth, to connect the PDA to a local computer network, and ActiveSync, to hold a continuous connection between the PDA and the host computer. Furthermore a Web server with PHP (hypertext pre processor) extension is running. Web browsers are acting as clients on both computers and the PDA as well. The challenge is now to write an application software that provides an interface on the PDA to set the adjustments and pushes the image information to the graphic cards of the host and the slave computer. To minimize the effort in software development, open source software components are largely applied to this system. We take advantages from Mozilla Firefox Web browser and Apache Web server. This paper introduces the application of AJAX (asynchronous JavaScript and XML) Web scripting in connectivity with PHP and delineates the infrastructure of network components connected to a working presentation environment, that serves a screen surface of about 100 inch diagonal. High quality stereoscopic colour images are presented at daylight conditions also, due to the BlackScreen RP technology. © 2007 International Society for Photogrammetry and Remote Sensing. All rights reserved.},
author_keywords={CAD;  Cultural Heritage;  Education;  Internet/Web;  System},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ziefle2007307,
author={Ziefle, M. and Schroeder, U. and Strenk, J. and Michel, T.},
title={How younger and older adults master the usage of hyperlinks in small screen devices},
journal={Conference on Human Factors in Computing Systems - Proceedings},
year={2007},
pages={307-316},
doi={10.1145/1240624.1240676},
note={cited By 40},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-35348814469&doi=10.1145%2f1240624.1240676&partnerID=40&md5=ec55a69d5b62c9bd762dd1b7c346c1c6},
affiliation={Department of Psychology, RWTH Aachen University, Jaegerstrasse 17-19, 52056 Aachen, Germany; Department of Computer Science, RWTH Aachen University, Ahornstrasse 55, 52074 Aachen, Germany},
abstract={In this paper we describe an experiment, in which we examined older and younger adults when interacting with a simulated PDA (personal digital assistant). Independent variables were users' age (young vs. older) and device interface (hyperlink vs. no hyperlink). Dependent variables were the effectiveness and efficiency of menu navigation. To understand how user characteristics influence performance, spatial ability, verbal memory, computer expertise and technical self-confidence were determined. Technology experienced young and older adults (benchmark testing) took part. They had to solve four tasks either with hyperlink interface or without hyperlinks in the interface. The method to collect, to automatically analyze and to structure the data according to interaction sequences and presumed user intentions is a novel approach supported by the open source software tool Clever [12]. The tool is briefly described; more details can be found in [23]. Results revealed that hyperlink interfaces showed overall higher effectiveness. However, the impact of hyperlinks for efficiency was age-related. Younger adults strongly benefit from having hyperlinks. The contrary was the case for older adults, who showed higher menu disorientation when using hyperlinks. © Copyright 2007 ACM.},
author_keywords={Aging;  Cognitive user characteristics;  Hyperlinks;  Navigation performance;  Qualitative user data analysis;  Small screen devices},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Armold2006376,
author={Armold, A.D. and Hyla, B.M. and Rowe, N.C.},
title={Automatically building an information-security vulnerability database},
journal={Proceedings of the 2006 IEEE Workshop on Information Assurance},
year={2006},
volume={2006},
pages={376-377},
art_number={1652119},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845935024&partnerID=40&md5=bdca49d1a8bbed287d37e0b3e11fac34},
affiliation={Code CS/Rp, U.S. Naval Postgraduate School, 833 Dyer Road, Monterey, CA 93943, United States},
abstract={Our goal was to collect data from the myriad computer vulnerability notices that exist on the World Wide Web and to mine it for interesting information and patterns. Surprisingly, no single database currently brings together all the various kinds of data from the vulnerability sites. Of particular interest to us was author and discoverer information since this provides valuable information about who is active in information security and occasionally might indicate the authors of exploits; current databases do not connect this to other relevant information. We found that the searchable parameters of the existing vulnerability databases were limited and inconsistent. Consequently, it is very difficult to get complete information about computer vulnerabilities by searching Web sites. Our approach was to bring together this information into a composite database. We did automated data collection from the existing Web vulnerability databases by creating Web bots that traversed Web sites and retrieved selected information from them, then imported the collected Web data into a relational database. A browser provides Web-based access to this database. [1] and [2] shows how such information can be used to build models of attacks in the form of graphs, trees, and finite-state machines, and thereby develop methods for system protection. We first wanted to use the Carnegie-Mellon US-CERT database (www.kb.cert.org/vuls) of 22,716 vulnerabilities from 1995. However, it is not downloadable online. So we took records from the Common Vulnerability and Exposure (CVE) database (cve.mitre.org) with 15,000 entries, 11,000 entries from Secunia (www.secunia.com), 1,500 entries from US-CERT Vulnerability Notes Database (www.kb.cert.org/vuls) and 15,000 from SecurityFocus, more a newsgroup reporting vulnerabilities (www.securityfocus.com/bid). The National Vulnerability Database (NVD) (nvd.nist.gov) contained mostly the same information as the CVE database in an XML format, and the Open Source Vulnerabilities Database (www.osvdb.org) appeared to duplicate most of the other information, so we did not use their data. Each database had its weaknesses. The US-CERT database could not be downloaded as a whole, only in small groups of records; the CVE database did not list discoverers or reporters of vulnerabilities; the Secunia and SecurityFocus databases did not contain data on all vulnerability alerts and candidates, and their vulnerability descriptions were often cryptic. Using ideas from [3], we created bots that collected information from the Web sources. These used crafted links to access forms pages and then processed the results in Java. Only the CVE database provided an easy means to download their database. The US-CERT Vulnerability Notes Database does not allow bots to search the database except by vulnerability number, and this appears randomly assigned from 1000 to 999999; so we manually grabbed the 54 pages of information containing vulnerability identifiers and iteratively searched for those with a bot. The Secunia database could be indexed by entry number ranging from 1 to 13000 with some omissions, so we just retrieved all 13000, getting blank pages for the omissions; however, some entries had no numbers and could not be found this way. Finally, we retrieved the SecurityFocus database pages in the same manner as Secunia, again getting some blank pages for nonexistent numbers. For each of these databases we analyzed the formats to develop ways to extract and organize the data on the page. We created a relational database using PostgreSQL, using character fields for each of the pieces of information extracted from the websites. Each site had a separate table for its data of 4000-15000 records. Text had to be cleaned up in a number of ways before entering it into this database, including conversion from HTML to strings, from strings to SQL char fields, from SQL char fields to strings, and from strings to HTML. There were also many small problems with non-English, Unicode, and punctuation characters, as well as the handling of a few large text entries. We created a Java servlet for free-text keyword search on the database. It can search on vulnerability name, author, CVE number, or affected system. These keyword searches are then coded into SQL and passed to the database. Selections, projections, and joins are made on our tables as necessary to produce the results. Currently, results are returned as tables, one for each of the selected source sites (Figure 1). Posing questions, like what percentage of vulnerability notices have a CVE number associated with them, involved some challenges in structuring the proper queries in SQL. These were fairly large tables and performing queries with join operations, such as finding data unique to one table, were prohibitively slow on a laptop computer. The CVE vulnerability numbers were quite helpful, since a vulnerability was often described quite differently by each organization. In seeking author or credit information, we found many entries of the Secunia site to state "no credit." Redesigning the Secunia bot to recursively search referenced advisories from those that provided no credit information reduced the number of "no credit" items from 40% to 15%. Interestingly, while the total number of vulnerabilities has been increasing since 1999, Mitre (the keeper of the CVE database) has labeled fewer candidate vulnerabilities (Figure 2). Another discovery was that the security-company data collection was not capturing the volume of vulnerabilities reported by the USCERT (Figure 3). Also of note is that individuals and private firms are critical to discovering vulnerabilities, since in both the Secunia and the SecurityFocus databases over 70% of the vulnerabilities were not found by the manufacturer of the software or hardware. Though not complete, this project has achieved most of its goals in collecting, storing, and accessing the computer-vulnerability database information from the Web. Even now, our system can provide some interesting data not easily gleaned from the Web. Comparisons between the commercial and the government sites will also prove interesting. Further development of the project would yield some answers about the timeliness of vendors in issuing resolution to problems, trends in systems vulnerabilities in contrast to competitors, identifying trends in authoring and submission of vulnerabilities, and measure how well the CVE naming convention for vulnerabilities is being used and applied. © 2006 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{vanderHam2006862,
author={van der Ham, J.J. and Dijkstra, F. and Travostino, F. and Andree, H.M.A. and de Laat, C.T.A.M.},
title={Using RDF to describe networks},
journal={Future Generation Computer Systems},
year={2006},
volume={22},
number={8},
pages={862-867},
doi={10.1016/j.future.2006.03.022},
note={cited By 43},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33744915786&doi=10.1016%2fj.future.2006.03.022&partnerID=40&md5=9d7d04aef8df95c0a4dbbe6d47461161},
affiliation={Advanced Internet Research Group, Universiteit van Amsterdam, Kruislaan 403, 1098 SJ Amsterdam, Netherlands; Nortel Labs, Boston, MA, United States},
abstract={Conventions such as iGrid 2005 and SuperComputing show that there is increasing demand for more service options on networks. For such networks, large teams of experts are needed to configure and manage them. In order to make the full potential of hybrid networks available to the ordinary user, the complexity must be reduced. This paper presents the idea of the Network Description Language (NDL), which builds on Semantic Web techniques to create a distributed Topology Knowledge Base (TKB). The TKB can provide a collection of reachability graphs, showing connectivity rules among physical and/or virtual entities. Latching onto the Semantic Web provides network management with a new breed of tools-bots, compilers, browsers, both commercial off-the-shelf (COTS) and open source. The approach appears to be applicable to the Global Lambda Integrated Facility (GLIF) as well as other experimental communities. © 2006 Jeroen van der Ham.},
author_keywords={Hybrid networks;  Network descriptions;  Resource Description Framework;  Semantic Web},
document_type={Article},
source={Scopus},
}

@ARTICLE{Carlisle200616,
author={Carlisle, M.C.},
title={Ada 2005 on .NET and mobile and embedded devices},
journal={CrossTalk},
year={2006},
volume={19},
number={8},
pages={16-19},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33747131819&partnerID=40&md5=f72743d93c37fdba892ac03d43fa7855},
affiliation={U.S. Air Force Academy, United States; Department of Computer Science, STE 6G101, U.S. Air Force Academy, 2354 Fairchild DR, Colorado Springs, CO 80840-6234, United States},
abstract={Ada is well known for supporting good software engineering practices and for interfacing cleanly with other languages; these features have only gotten better with Ada 2005. The A# project is an open-source implementation of Ada 2005 for Microsoft's .NET Framework. Using A#, programmers can combine Ada code with reusable .NET components, including modules written in C#, as well as legacy component object model components and Win32 Dynamically Linked Libraries. This allows leveraging both the software engineering advantages of Ada and the large amount of reusable libraries written for .NET. Additionally, A# targets portable digital assistants and other mobile and embedded devices.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Muñetón2006243,
author={Muñetón, A.F. and Saldarriaga, J.M. and De J.Montoya, A. and Aristizábal, D.L.},
title={Sensor network applications: A module for monitoring and remote control of physical variables using mobile devices},
journal={Advances in Computer, Information, and Systems Sciences, and Engineering - Proceedings of IETA 2005, TeNe 2005, EIAE 2005},
year={2006},
pages={243-245},
doi={10.1007/1-4020-5261-8_38},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877958696&doi=10.1007%2f1-4020-5261-8_38&partnerID=40&md5=9be655783cb5842dea89d34e362546f2},
affiliation={Scientific and Industrial Instrumentation Group, Universidad Nacional de Colombia Sede Medellin, Autopista Norte, Carrera 65, Medellín-Colombia, Colombia},
abstract={A module was developed to monitor and to control physical variables by means of mobile devices like a cellular telephone or PDA (Personal Digital Assistant). This one is made up of two parts: an application client accessible from a mobile device and an application Web in charge to manage requests of the application client. This last one, in interaction with the application Web via Internet, allows to visualize the state of the physical variables and to activate or to deactivate control systems with the purpose of altering one or more of these variables. The module was developed in the language OO Java combining platforms J2ME and J2EE for the application client and Web respectively. In addition the methodology of software engineering Un-method of the School of Systems of the National University of Colombia - Host Medellin was used. © 2006 Springer.},
author_keywords={Control;  J2EE;  J2ME;  Java;  Language OO;  Mobile device;  Monitoring;  Physical variables},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Martignano20063066,
author={Martignano, M.},
title={Use of speech technologies in space operations},
journal={AIAA 57th International Astronautical Congress, IAC 2006},
year={2006},
volume={5},
pages={3066-3072},
doi={10.2514/6.iac-06-b4.4.07},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-41149160736&doi=10.2514%2f6.iac-06-b4.4.07&partnerID=40&md5=b70220990c714e751b8798feecd4cdd6},
affiliation={SERCO FM B.V., C/o ESTEC, Noordwijk, Netherlands},
abstract={This paper presents some prototype implementations where solutions based on the speech standards and on open source software have been applied to the space field. Two special cases are analyzed in detail: crew and ground procedure execution and the handling of emergency situations in case of depressurization. In developing and analyzing these prototype implementations special attention has been paid to the computing platforms available on the International Space Station, i.e. laptops and personal digital assistants (PDAs).},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Aaraj2006,
author={Aaraj, N. and Ravi, S. and Raghunathan, A. and Jha, N.K.},
title={Architectures for efficient face authentication in embedded systems},
journal={Proceedings -Design, Automation and Test in Europe, DATE},
year={2006},
volume={2},
doi={10.1109/date.2006.244155},
art_number={1657105},
note={cited By 15},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-34047139956&doi=10.1109%2fdate.2006.244155&partnerID=40&md5=65a053edbe7c5bc413b83de7dbd79a4e},
affiliation={Department of Electrical Engineering, Princeton University, Princeton, NJ 08544, United States; NEC Laboratories America, Princeton, NJ 08540, United States},
abstract={Biometrics represent a promising approach for reliable and secure user authentication. However, they have not yet been widely adopted in embedded systems, particularly in resource-constrained devices such as cell phones and personal digital assistants (PDAs). In this paper, we investigate the challenges involved in using face-based biometrics for authenticating a user to an embedded system. To enable high authentication accuracy, we consider robust face verifiers based on principal component analysis/linear discriminant analysis (PCA-LDA) algorithms and Bayesian classifiers, and their combined use (multi-modal biometrics). Since embedded systems are severely constrained in their processing capabilities, algorithms that provide sufficient accuracy tend to be computationally expensive, leading to unacceptable authentication times. On the other hand, achieving acceptable performance often comes at the cost of degradation in the quality of results. Our work aims at developing embedded processing architectures that improve face verification speed with minimal hardware requirements, and without any compromise in verification accuracy. We analyze the computational characteristics of face verifiers when running on an embedded processor, and systematically identify opportunities for accelerating their execution. We then present a range of targeted hardware and software enhancements that include the use of fixed-point arithmetic, various code optimizations, application-specific custom instructions and co-processors, and parallel processing capabilities in multi-processor systems-on-chip (SoCs). We evaluated the proposed architectures in the context of open-source face verification algorithms running on a commercial embedded processor (xtensa from Tensilica). Our work shows that fast, in-system verification is possible even in the context of many resource-constrained embedded systems. We also demonstrate that high authentication accuracy can be achieved with minimum hardware overheads, while requiring no modifications to the core face verification algorithms.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Nakata2006123,
author={Nakata, N. and Oowaki, K. and Fukuda, K. and Suzuki, N.},
title={RadXOOPS: Interactive radiology education using open source e-learning content management server and low cost portable client devices},
journal={International Journal of Computer Assisted Radiology and Surgery},
year={2006},
volume={1},
number={SUPPL. 7},
pages={123-124},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748962555&partnerID=40&md5=cfc4d9da3cccc91e720c80d0dd7adc75},
affiliation={Department of Radiology, Jikei University, School of Medicine, Japan; Institute of High Dimensional Medical Imaging, Jikei University, School of Medicine, Japan},
abstract={We have built our original intranet web application network for radiology education: RadXOOPS using open source content management system (CMS), and mobile clients such as wireless game players, personal digital assistants, laptop personal computers We installed some modules of CMS including RSNA MIRC exportable teaching flies, Wiki for radiologists, and XoopsHP e-learning module. In this paper, we evaluate the educational feasibility of our web-based education system and discuss the novel communication methodology of medical education in diagnostic radiology using open source CMS. We conclude that our next generation web-based application system had advantages of attractive merits, time-saving and, low costs, compared with conventional paper-based education system of diagnostic radiology.},
author_keywords={Content management system;  e-Learning;  Open source software},
document_type={Article},
source={Scopus},
}

@ARTICLE{Beck200625,
author={Beck, H.W. and Albrigo, L.G. and Kim, S.},
title={DISC citrus planning and scheduling program},
journal={Acta Horticulturae},
year={2006},
volume={707},
pages={25-32},
doi={10.17660/ActaHortic.2006.707.2},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745751859&doi=10.17660%2fActaHortic.2006.707.2&partnerID=40&md5=c97ac72b39f65cbf21d462873ecd2853},
affiliation={Agricultural and Biological Engineering Department, University of Florida, Gainesville, FL 32611, United States; Citrus Research and Education Center, University of Florida, Lake Alfred, FL 33850, United States},
abstract={A program to assist production managers in planning and scheduling citrus operations has been developed as part of the DISC project (Decision Information Systems for Citrus) at the University of Florida. The program integrates a phenology-based planning system with citrus production record keeping. The interface incorporates time-lines and a geographic information system (GIS) for temporal and spatial analysis. The program covers 12 production areas including pesticide applications, fertilizers, herbicides, irrigation, tree removal/reset, mowing, hedging and topping, cold protection, drainage maintenance, equipment maintenance, and young tree care. Production managers can schedule future operations (budget), determine weekly and daily operations (recommendations/ worksheets) and record actual operations for historic analysis. The phenology model predicts bloom dates and other events around which production operations can be scheduled for optimal timing. The planning and scheduling program acts as a framework for additional decision support systems including fungicide spray residue estimation, irrigation scheduling, fertilizer best management practices (BMPs), and rootstock/cultivar selection. A grove observation program that runs on a hand-held computer (personal digital assistant or PDA) also integrates with the planning and scheduling module to facilitate record keeping of pest outbreaks. The program interfaces with accounting software to facilitate communications between the production and business aspects of grove management. Finally, we present new approaches and directions to software engineering used in the project.},
author_keywords={Citrus production management;  Decision support system;  Planning and scheduling},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bonneaud200522,
author={Bonneaud, S. and Ripoche, G. and Sansonnet, J.-P.},
title={Toward an empirical schema-based model of interaction for embedded conversational agents},
journal={AISB'05 Convention:Proceedings of the Joint Symposium on Virtual Social Agents: Social Presence Cues for Virtual Humanoids Empathic Interaction with Synthetic Characters Mind Minding Agents},
year={2005},
pages={22-28},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858984951&partnerID=40&md5=a9665d38d6421c34c462fdd981fad81b},
affiliation={LIMSI-CNRS, Université Paris XI, France; GSLIS, University of Illinois, Urbana-Champaign, United States},
abstract={In this paper, we argue that Embedded Conversational Agents (ECAs) need cognitive credibility to usefully participate in mixed communities. One critical aspect of this credibility has to do with the argumentative capacity of ECAs. We believe that socio-cognitive models of interaction can provide a helpful foundation that agents can use to represent, manipulate, and reason about "what is going on" in a collective in order to better engage in ongoing interactions. Furthermore, because people interact in a large proportion using natural language, it is critical that agents be able to directly process language and construct their model from it. We propose a way to build such a model based on empirical data, by extracting and representing patterns of interaction from large archives of online distributed collectives such as the Free/Open-Source Software project Mozilla.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Travostino2005463,
author={Travostino, F.},
title={Using the semantic web to automate the operation of a hybrid internetwork},
journal={2nd International Conference on Broadband Networks, BROADNETS 2005},
year={2005},
volume={2005},
pages={463-471},
doi={10.1109/ICBN.2005.1589769},
art_number={1589769},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847056262&doi=10.1109%2fICBN.2005.1589769&partnerID=40&md5=9a0fdd89ba53ec9850fadc255701551d},
affiliation={Nortel Labs., Boston, MA, United States},
abstract={In hybrid Internetworks, the plurality of service options and compositions poses several cross-layer operational challenges. The graving popularity of such Internetworks among researchers and advanced users - many of which are Grid users - warrants a complexity relief effort in support of the Internetworks' continued scalability, all the way to planet scale. This paper proposes the use of Semantic Web techniques to automate the processing of networking meta-data in a hybrid Internetwork, with the two-fold outcome of raising the degree of confidence in the Internetwork and lowering its operating costs. By virtue of latching onto the Semantic Web curve, a new breed of power tools - bots, compilers, browsers - will be delivering on the aforementioned outcomes, while fully leveraging COTS and open source building blocks. Furthermore, the investment in the Semantic Web is thought to future proof a hybrid Internetwork and readies it for times when service metrics other than connectivity (e.g., resiliency, protocol transparency, security etc.) will be evaluated end-to-end. The approach appears to be applicable to the Global Lambda Integrated Facility (GLIF) as well as other advanced, experimental communities. © 2005 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Susilo2005661,
author={Susilo, W. and Ang, R.J. and McDonald, C.A.G. and Huang, J.},
title={Personal firewall for pocket PC 2003: Design & implementation},
journal={Proceedings - International Conference on Advanced Information Networking and Applications, AINA},
year={2005},
volume={2},
pages={661-666},
doi={10.1109/AINA.2005.279},
art_number={1423771},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33744484560&doi=10.1109%2fAINA.2005.279&partnerID=40&md5=00f8b8c62ea2d954f6f3eff8c0f353e8},
affiliation={University of Wollongong, Australia},
abstract={Personal Digital Assistants (PDAs)are widely used and becoming indispensable tools of everyday life. Wired or wireless connection enables PDA users to connect to the Internet from any place, making security an extremely important issue in a pervasive computing environment. This paper investigates how to build a personal firewall for PDAs running Pocket PC 2003. This personal firewall allows the PDA user to perform access control based on a user-defined policy, and hence provides a security perimeter between the public network and the PDA. We provide a complete technical detail on how the firewall can be built in a Pocket PC 2003 device. Ti the best of our knowledge, this is the first design and implementation of personal firewalls for Pocket PC 2003 device which is explicit, open source and successfully implemented in any Pocket PC 2003 compatible devices, including HP iPaq H5550 and XDA2 0 2 smartphone. © 2005 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sansonnet2005111,
author={Sansonnet, J.-P. and Martin, J.-C. and Leguern, K.},
title={A software engineering approach combining rational and conversational agents for the design of assistance applications},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2005},
volume={3661 LNAI},
pages={111-119},
doi={10.1007/11550617_10},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646053833&doi=10.1007%2f11550617_10&partnerID=40&md5=89085ba8185594c78fb1c221908b8d7f},
affiliation={LIMSI-CNRS, BP 133, 91403 Orsay Cedex, France},
abstract={A Conversational Agent can be useful for providing assistance to naïve users on how to use a graphical interface. Such an assistant requires three features: understanding users' requests, reasoning, and intuitive output. In this paper we introduce the DAFT-LEA architecture for enabling assistant agents to reply to questions asked by naive users about the structure and functioning of graphical interlaces. This architecture integrates via a unified software engineering approach a linguistic parser for the understanding the user's requests, a rational agent for the reasoning about the graphical application, and a 2D cartoon like agenl for the multimodal output. We describe how it has been applied to three different assistance application contexts, and how it was incrementally defined via the collection of a corpus of users' requests for assistance. Such an approach can be useful for the design of other assistance applications since it enables a clear separation between the original graphical application, its abstract DAFT model and the linguistic processing of users' requests. © Springer-Verlag Berlin Heidelberg 2005.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Balci2005208,
author={Balci, K.},
title={XfaceEd: Authoring tool for embodied conversational agents},
journal={Proceedings of the Seventh International Conference on Multimodal Interfaces, ICMI'05},
year={2005},
pages={208-213},
doi={10.1145/1088463.1088500},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-32344447341&doi=10.1145%2f1088463.1088500&partnerID=40&md5=276c610c9dc9af82521e3ad6c9d330fb},
affiliation={ITC-irst, Cognitive and Communication Technologies Division, Trento, Italy},
abstract={In this paper, XfaceEd, our open source, platform independent tool for authoring 3D embodied conversational agents (ECAs) is presented. Following MPEG-4 Facial Animation (FA) standard, XfaceEd provides an easy to use interface to generate MPEG-4 ready ECAs from static 3D models. Users can set MPEG-4 Facial Definition Points (FDP) and Facial Animation Parameter Units (FAPU), define the zone of influence of each feature point and how this influence is propagated among the neighboring vertices. As an alternative to MPEG-4, one can also specify morph targets for different categories such as visemes, emotions and expressions, in order to achieve facial animation using the keyframe interpolation technique. Morph targets from different categories are blended to create more lifelike behaviour. Results can be previewed and parameters can be tweaked real time within the application for fine tuning. Changes made take into effect immediately, which in turn ensures rapid production. The final output is a configuration file XML format and can be interpreted by XfacePlayer or other applications for easy authoring of embodied conversational agents for multimodal environments. Copyright 2005 ACM.},
author_keywords={3D facial animation;  Embodied Conversational Agents;  MPEG-4;  Open Source;  Talking heads},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Shanks200553,
author={Shanks, B.},
title={WikiGateway: A library for interoperability and accelerated wiki development},
journal={WikiSym 2005 - Conference Proceedings of the 2005 International Symposium on Wikis},
year={2005},
pages={53-66},
doi={10.1145/1104973.1104979},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-31844432135&doi=10.1145%2f1104973.1104979&partnerID=40&md5=bba6b5dde8d8da0990ad6a35d54f9e27},
affiliation={Computational Neurobiology, University of California San Diego, San Diego, CA 92093, United States},
abstract={WikiGateway is an open-source suite of tools for automated interaction with wikis: Python and Perl modules with functions like getPage, putPage, getRecentChanges, and more. A mechanism to add DAV, Atom, or XMLRPC capabilities to any supported wiki server. A command-line tool with functionality similar to the Perl and Python modules. Demo applications built on top of these tools include a wiki copy command, a spam-cleaning bot, and a tool to recursively upload text files inside a directory structure as wiki pages. All WikiGateway tools are compatible with a number of different wild engines. Developers can use WikiGateway to hide the differences between wiki engines and build applications which interoperate with many different wiki engines. Copyright 2005 ACM.},
author_keywords={Atom;  Client-side wiki;  Interoperability;  Interwiki;  Middleware;  WebDAV;  Wiki;  Wiki XMLRPC;  WikiClient;  WikiGateway;  WikiRPCInterface},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Price20051506,
author={Price, M.},
title={Can hand-held computers improve adherence to guidelines? A (Palm) Pilot study of family doctors in British Columbia.},
journal={Canadian family physician Médecin de famille canadien},
year={2005},
volume={51},
pages={1506-1507},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748754725&partnerID=40&md5=78e445f3b67b2a7a9ed21db54c1b81e0},
affiliation={Department of Family Practice, University of British Columbia, Vancouver},
abstract={OBJECTIVE: To examine whether Palm Prevention, a free software tool for Palm OS personal digital assistants (PDAs) that provides quick access to preventive guidelines in a patient-specific manner at the point of care, improved adherence to five preventive measures in primary care. DESIGN: Prospective intervention pilot study. SETTING: Vancouver, BC, and surrounding area. PARTICIPANTS: Eight general practitioners. INTERVENTIONS: Each physician used Palm Prevention for five preventive measures during routine preventive health visits with 10 patients (n = 80). Charts of consenting patients were reviewed for documentation of recommended maneuvers. MAIN OUTCOME MEASURES: Rates of adherence to five evidence-based guidelines selected from the Canadian and American task forces on preventive care and incorporated into Palm Prevention. RESULTS: Intervention and control physicians were similar in their familiarity with and use of PDAs, and they recruited similar patients for the study. Intervention and control groups had similar rates of screening for hypertension. Intervention improved adherence to the remaining four guidelines: cervical cancer screening increased 22% (only absolute increases are reported); hyperlipidemia screening increased 30%; colorectal cancer screening increased 27%; and prophylaxis with acetylsalicylic acid in high-risk patients increased 38%. Participants were surveyed after the study; all reported that they found the software helpful and would continue using Palm Prevention. Usage statistics showed that study participants used the tool outside the trial: users entered between 28 and 68 unique patients into the program during the 2-month intervention. CONCLUSION: This pilot study suggests PDAs are useful in improving preventive care and facilitating translation of knowledge into practice. This was particularly apparent with newer guidelines.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Balci2005263,
author={Balci, K.},
title={Xface: Open source toolkit for creating 3D faces of an embodied conversational agent},
journal={Lecture Notes in Computer Science},
year={2005},
volume={3638},
pages={263-266},
doi={10.1007/11536482_25},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-26944464199&doi=10.1007%2f11536482_25&partnerID=40&md5=240dbfd1f5fd476cafb84030772ce57d},
affiliation={ITC-irst, Trento, Italy},
abstract={Xface, the new version of our open source, platform independent toolkit for developing 3D embodied conversational agents is presented. The toolkit currently incorporates four pieces of software. The core Xface library is for developers who want to embed 3D facial animation to their applications. XfaceEd editor provides an easy to use interface to generate MPEG-4 ready meshes from static 3D models. Xface-Player is a sample application that demonstrates the toolkit in action and XfaceClient is used as the communication controller over network. © Springer-Verlag Berlin Heidelberg 2005.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Burge2004181,
author={Burge, M.},
title={Pervasive computing in the undergraduate curriculum},
journal={SIGCSE Bulletin (Association for Computing Machinery, Special Interest Group on Computer Science Education)},
year={2004},
volume={36},
number={1},
pages={181-182},
doi={10.1145/1028174.971366},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646851749&doi=10.1145%2f1028174.971366&partnerID=40&md5=d89b5fde3f135379a70e3617500e8249},
affiliation={School of Computing, Armstrong Atlantic State University, Savannah, GA, United States},
abstract={How do you prepare students today, to work on the most widely available computing platforms of tomorrow? Programmable cell phones and personal digital assistants (PDAs) have already become more numerous then PCs. With their small size and mobility, these devices present both new opportunities and unique software engineering challenges like small memory models, cross-platform development, state machines, and wireless networking. You will learn how to use the Java Micro Edition (J2ME) to easily develop labs based on arcade and logic games that will motivate and excite your students. In this session we will present the initial results of a NSF CCLI project to develop materials for Handheld and Ubiquitous Computing in the Undergraduate Curriculum.},
author_keywords={Handheld;  J2ME;  Mobile Computing;  Palm OS;  Pervasive Computing},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Fritsch2004621,
author={Fritsch, D. and Kada, M.},
title={Visualisation using game engines},
journal={International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
year={2004},
volume={35},
pages={621-625},
note={cited By 25},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043288283&partnerID=40&md5=45b00c478beec02361c0c7f21ff91f99},
affiliation={Institute for Photogrammetry (IFP), University of Stuttgart, Geschwister-Scholl-Strasse 24D, Stuttgart, D-70174, Germany},
abstract={Geographic Information Systems (GIS) and Computer Aided Facility Management-Systems (CAFM) are currently undergoing the transition to storing and processing real 3D geospatial data. Applications for this type of data are, among others, location based services, navigation systems and the planning of large-scale construction projects. For presentation purposes and especially when working in the field, powerful visualisation systems are needed that are also capable of running on mobile devices like notebooks, personal digital assistants (PDA) or even cell phones. In such application areas, the free movement of the viewer’s position and the interaction with the data are of great importance. Real-time visualisation of 3D geospatial data is already well established and also commercially successful in the entertainment industry, namely in the market of 3D video games. The development of software in this field is very cost-intensive, so that the packages are often used for several game products and are therefore universally applicable to a certain extend. These so-called game engines include not only visualisation functionality, but also offer physics, sound, network, artificial intelligence and graphical user interfaces to handle user in- and output. As certain portions or sometimes even the whole engine are released as open source software, these engines can be extended to build more serious applications at very little costs. The paper shows how these game engines can be used to create interactive 3D applications that present texture-mapped geospatial data. The integration of 3D data into such systems is discussed. Functionality like thematic queries can be implemented by extending the internal data structures and by modification of the game’s accompanying dynamic link libraries. © 2014 ISPRS. All Rights Reserved.},
author_keywords={GIS;  Modelling;  Real-time;  Virtual reality;  Visualisation},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Seffah2004287,
author={Seffah, A. and Forbrig, P. and Javahery, H.},
title={Multi-devices "multiple" user interfaces: Development models and research opportunities},
journal={Journal of Systems and Software},
year={2004},
volume={73},
number={2},
pages={287-300},
doi={10.1016/j.jss.2003.09.017},
note={cited By 29},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-3242716013&doi=10.1016%2fj.jss.2003.09.017&partnerID=40&md5=7ee7652cb212a67317d6e8025d6b1ab8},
affiliation={Hum.-Centered Software Eng. Group, Department of Computer Science, Concordia University, 1455 de Maisonneuve Blvd. West, Montreal, Que. H3G 1M8, Canada; Software Engineering Group, Department of Computer Science, D-18051 Rostock University, Albert-Einstein-Str 21, Germany},
abstract={Today, Internet-based appliances can allow a user to interact with the server-side services and information using different kinds of computing platforms including traditional office desktops, palmtops, as well as a large variety of wireless devices including mobile telephones, Personal Digital Assistants, and Pocket Computers. This technological context imposes new challenges in user interface software engineering, as it must run on different computing platforms accommodating the capabilities of various devices and the different contexts of use. Challenges are triggered also because of the universal access requirements for a diversity of users. The existing approaches of designing a single user interface using one computing platform do not adequately address the challenges of diversity, cross-platform consistency, universal accessibility and integration. Therefore, there is an urgent need for a new integrative framework for modeling, designing and evaluating multi-device user interfaces for the emerging generation of interactive systems. This paper begins by describing a set of constraints and characteristics intrinsic to multi-device user interfaces, and then by examining the impacts of these constraints on the specification, design and validation processes. Then, it discusses the research opportunities in important topics relevant to multi-device user interface development, including task and model-based, pattern-driven and device-independent development. We will highlight how research in these topics can contribute to the emergence of an integrative framework for Multiple-User Interface design and validation. © 2003 Elsevier Inc. All rights reserved.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Miyashita20031139,
author={Miyashita, N. and Nakaya, K. and Ui, K. and Matunaga, S.},
title={Internet and XML-based extensible and low-cost ground station system},
journal={54th International Astronautical Congress of the International Astronautical Federation (IAF), the International Academy of Astronautics and the International Institute of Space Law},
year={2003},
volume={3},
pages={1139-1144},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-22144483071&partnerID=40&md5=dee834922c99bc735362ed68bc388f06},
affiliation={Tokyo Institute of Technology, Department of Mechanical and Aerospace Engineering, 2-12-1 O-okayama, Meguro-ku, Tokyo, 152-8552, Japan},
abstract={Universities and space agencies of the world have been developing the small satellites in recent years. We Tokyo Institute of Technology, Laboratory for the Space Systems (LSS) also developed 10 cm cubic-shaped small satellite "CUTE-I" since 1999. On 30th June, 2003, we threw CUTE-I into the orbit using the Russian rocket "ROCKOT". CUTE-I has been active on orbit from the launch date to now and executing its missions and experiments. Simultaneously we have developed the ground station system for CUTE-I ground operation. This ground station system is developed by the latest Internet technology, [1]Extensible Markup Language (XML) technology, and Open Source Systems. By adopting these technologies, this system is superior to system extensibility, data processing and data exhibiting, and low-cost. By using this system, we can read the satellite telemetry, satellite orbital information, orbital map, and so on using general web browser, cellular phone, and Personal Digital Assistant (PDA). In this paper, we describe proposal and actual development of the Internet and XML-based ground station system. Copyright © 2003 by the International Astronautical Federation. All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Vuorimaa20021094,
author={Vuorimaa, P. and Ropponen, T. and Von Knorring, N. and Honkala, M.},
title={A Java based XML browser for consumer devices},
journal={Proceedings of the ACM Symposium on Applied Computing},
year={2002},
pages={1094-1099},
doi={10.1145/509004.509007},
note={cited By 25},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036036937&doi=10.1145%2f509004.509007&partnerID=40&md5=8598af222fbfe83e3d144106a26994df},
affiliation={Telecomm. Software Multimedia Lab., Helsinki University of Technology, P.O. Box 5400, FI-02015 HUT, Finland},
abstract={Next generation consumer devices will all have an Internet connection. Thus, one vision is that the future multimedia services will be browser based. Extensible Markup Language (XML) is the most likely markup language. In this paper, we introduce a Java based XML browser called X-Smiles. It is intended for consumer devices and supports multimedia services. The main advantage of the X-Smiles browser is that it supports most of the XML related specifications. Different XML based languages can be mixed freely in applications. In addition, the X-Smiles has special user interfaces for different kinds of devices (e.g., digital television, personal digital assistants, and mobile phones). These user interfaces can be used as so called virtual prototypes of the real devices. The X-Smiles browser is available as open source at http://www.x-smiles.org.},
author_keywords={Multimedia;  SMIL;  SVG;  XML;  XSL FO},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Phan20011367,
author={Phan, T. and Xu, K. and Guy, R. and Bagrodia, R.},
title={Handoff of application sessions across time and space},
journal={IEEE International Conference on Communications},
year={2001},
volume={5},
pages={1367-1372},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034850869&partnerID=40&md5=9153ee9b30481df3aa1cf5f20267a566},
affiliation={Parallel Computing Laboratory, Computer Science Department, University of California, Los Angeles, CA 90095, United States},
abstract={Personal computing on mobile platforms such as laptops and personal digital assistants, rather than in a traditional desktop environment, is becoming increasingly more common. In this paper we address the issue of application session transfer for uninterrupted data access across this diverse range of platforms. This work is part of the iMASH project, a multi-year, multi-discipline collaborative effort focused on enabling mobile client platforms and incorporating them into existing legacy networked systems for use by medical practitioners. We have developed a tiered architecture that includes a middleware server layer positioned between existing application servers and multiple clients to make session transfer transparent to the user. Any client application executing our Middleware-Aware Remote Code library can save and restore its session by interacting with a middleware server. As a proof of concept, we have implemented the transfer of bookmarks, history, web cache, and user preferences with the Mozilla open source web browser. From this effort we have established baseline performance metrics and have found that the overhead is within reasonable bounds of just a few seconds of latency.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mohrenschildt19981022,
author={Mohrenschildt, Martin V. and Peters, Dennis K.},
title={Draw-Bot: A project for teaching software engineering},
journal={Proceedings - Frontiers in Education Conference},
year={1998},
volume={3},
pages={1022-1027},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032319716&partnerID=40&md5=0ece14793097eb8732e93b004936b2ed},
affiliation={McMaster Univ, Hamilton, Canada},
abstract={We present a course project which was successfully used to teach software design principles to third year computer engineering students. The goal of the project is to program a robot to trace a shortest path through a maze. The students, organized in teams of five, have to follow the classical steps of software development and prepare interface, design and testing documents. Having a project that requires controlling a device to complete a clear task generates enthusiasm in the students and helps them to understand the principles taught in the course.},
document_type={Conference Paper},
source={Scopus},
}
